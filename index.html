<!DOCTYPE html>



  


<html class="theme-next muse use-motion" lang="zh">
<head><meta name="generator" content="Hexo 3.9.0">
  <meta charset="UTF-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
<meta name="theme-color" content="#222">









<meta http-equiv="Cache-Control" content="no-transform">
<meta http-equiv="Cache-Control" content="no-siteapp">
















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css">







<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css">

<link href="/css/main.css?v=5.1.4" rel="stylesheet" type="text/css">


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/jojo_median.ico?v=5.1.4">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/jojo_small.ico?v=5.1.4">


  <link rel="mask-icon" href="/images/jojo_small.ico?v=5.1.4" color="#222">





  <meta name="keywords" content="Hello, Jiaxin">










<meta name="description" content="Head first to the Truth as Synaptics.">
<meta property="og:type" content="website">
<meta property="og:title" content="fooSynaptic">
<meta property="og:url" content="http://yoursite.com/index.html">
<meta property="og:site_name" content="fooSynaptic">
<meta property="og:description" content="Head first to the Truth as Synaptics.">
<meta property="og:locale" content="zh">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="fooSynaptic">
<meta name="twitter:description" content="Head first to the Truth as Synaptics.">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Muse',
    version: '5.1.4',
    sidebar: {"position":"left","display":"post","offset":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: '0',
      author: 'Author'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="http://yoursite.com/">





  <title>fooSynaptic</title>
  








</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh">

  
  
    
  

  <div class="container sidebar-position-left 
  page-home">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">fooSynaptic</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle">Any problem, please email me, my address -- ordinar@sjtu.edu.cn</p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br>
            
            Home
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br>
            
            Archives
          </a>
        </li>
      

      
    </ul>
  

  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            
  <section id="posts" class="posts-expand">
    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2019/10/31/nlp/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="jiaxin hu">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="fooSynaptic">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/10/31/nlp/" itemprop="url">NLP学习笔记之——读香侬科技李级为《出入NLP领域的一些小建议》文章</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2019-10-31T17:31:53+08:00">
                2019-10-31
              </time>
            

            

            
          </span>

          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/2019/10/31/nlp/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count ds-thread-count" data-thread-key="2019/10/31/nlp/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>涉及到的书籍和学习材料</p>
<ul>
<li>Speech and Language Processing</li>
<li>Introduction to infromation retrieval</li>
<li>吴恩达的机器学习</li>
<li>Pattern recognition and Machine learning</li>
</ul>
<p>1.了解NLP的最基本的知识</p>
<ul>
<li><p>Ngram<br>ngram模型中蕴含了概率语言模型的假设，同时也是一个n-1阶的马尔科夫假设，也就是一个词出现的概率只和它前面n-1个词相关<br>p(w_k|w1…k-1) = count(w(k-n+1…k)) / count(w(k-n+1…k-1))</p>
</li>
<li><p>Bert 里面训练LM的随机替换能够使得训练结果变得更好地原因：<br>斯坦福的吴恩达组的ziang Xie的Data Noising as Smoothing in Neurala Network Language Models就首次提出了此方法，并且给了理论解释，这种random的替换其实本质上属于language model里面基于interpolation的平滑方式。</p>
</li>
</ul>
<p>2.了解早点经典的NLP模型以及论文</p>
<ul>
<li>机器翻译中的IBM模型大概是干嘛的<br>对于每个词有一个alignment的list，目标函数为P(a|src, tgt)，表示以平行翻译语料作为条件，找到它对齐的概率。<br>参数估计的方法就是EM算法，通过概率模型中寻找最大似然估计或者最大后验估计的算法。概率模型中有无法观测的隐形变量，em算法经过两个步骤交替进行计算，第一步是计算期望，利用对隐藏变量的现有估计值（起始位随机初始化），计算其最大似然估计值；第二步是最大后验概率，最大后验概率通过求得最大似然的目标来估计参数，然后新股寄出来的参数用于下一个计算期望的步骤，不断迭代进行。<br>IBMmodel中的隐变量就是句子中词语的对齐信息a；<br>所以<br>P(a|src, tgt)<br>= P(a, src|tgt) / P(src|tgt)<br>P(src|tgt) 重点<br>= P(src, a|tgt)</li>
</ul>
<ul>
<li><p>神经机器翻译中正向翻译和反向翻译预测的target要一致对齐，这个是通过双向attention的约束项来实现的。</p>
</li>
<li><p>处理对话系统的无聊回复<br>用反向概率做rerank可以进一步提高检索的结果。在早期的统计机器翻译中（phrase-base MT）需要对一个大的N-best list用MERT做reranking，反向概率（given target， the p of source）是reranking中feature的重要标志。</p>
</li>
<li><p>诞生于神经网络机器翻译的attention，其实就是IBM模型的神经网络版本。</p>
</li>
</ul>
<ol start="3">
<li>了解机器学习的基本模型</li>
</ol>
<ul>
<li><p>EM算法是什么<br>参数估计的方法就是EM算法，通过概率模型中寻找最大似然估计或者最大后验估计的算法。概率模型中有无法观测的隐形变量，em算法经过两个步骤交替进行计算，第一步是计算期望，利用对隐藏变量的现有估计值（起始位随机初始化），计算其最大似然估计值；第二步是最大后验概率，最大后验概率通过求得最大似然的目标来估计参数，然后新股寄出来的参数用于下一个计算期望的步骤，不断迭代进行。</p>
</li>
<li><p>什么是variational inference</p>
</li>
<li><p>如何理解CRF</p>
</li>
<li><p>Dropout </p>
</li>
<li><p>SGD, momentum, adaboost, adagrad, adam</p>
</li>
</ul>
<ol start="4">
<li>多看NLP其他子领域的论文</li>
</ol>
<ul>
<li>MT, information extracition, parsing, ragging, sentiment analysis, machine reading comprehension.</li>
</ul>
<ol start="5">
<li>了解CV和data mining领域的基本重大进展</li>
</ol>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2019/10/04/当我们把目光放在机器阅读理解，我们的期望到底是什么？/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="jiaxin hu">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="fooSynaptic">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/10/04/当我们把目光放在机器阅读理解，我们的期望到底是什么？/" itemprop="url">当我们把目光放在机器阅读理解，我们的期望到底是什么？</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2019-10-04T07:41:50+08:00">
                2019-10-04
              </time>
            

            

            
          </span>

          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/2019/10/04/当我们把目光放在机器阅读理解，我们的期望到底是什么？/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count ds-thread-count" data-thread-key="2019/10/04/当我们把目光放在机器阅读理解，我们的期望到底是什么？/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>=========<br>转载请注明出处<br>=========<br><strong><em>机器阅读理解不是一个end2end的任务，当你把目光看向了机器阅读理解，你需要非常的谨慎，自己的问题是否定义的足够清晰</em></strong></p>
<p>好了我想我们首先还是要先介绍一下机器阅读理解这个任务，在学术圈这是一个端到端的任务，并且总体可以分成两类：</p>
<ul>
<li>开放领域的机器阅读理解，这个被google用于搜索技术中。</li>
<li>针对于文档库的机器阅读理解，这个传统都是用检索系统，现在由于深度学习非常火热，所以大家都拿阅读理解的考试试题的模拟这部分任务。</li>
</ul>
<p>两者从技术原理上并没有太大的分歧，只是第一种稍难，第二种虽然说开放数据上被各种刷新SOTA（state of the art），但是远达不到公共对于深度学习能够理解文本信息的程度。<br>那么具体来看机器阅读理解经历了一个什么样的发展历程呢？</p>
<pre><code>最著名的早期作品之一是 Lehnert ( 1977 ) 中详细描述的 QUALM。基于脚本和计划框架，Lehnert ( 1977 ) 设计了一个问答的理论，并且专注于语用问题和故事上下文在问答中的重要性，来作为对人类阅读理解的建模 ( Schank and Abelson， 1977 )。这个早期工作为语言理解设置了一个强大的愿景，但是当时构建的实际系统非常小，仅限于手工编码的脚本，并且很难推广到更广泛的领域。

由于问题的复杂性，这方面的研究在20世纪80年代和90年代大多被忽视。在20世纪90年代末，人们对阅读理解的兴趣有了一些小小的复苏，例如 Hirschman 等人 ( 1999 ) 创建了一个阅读理解数据集，以及随后在 ANLP/NAACL 2000年举办了一个关于阅读理解测试作为基于计算机的理解系统评估的研讨会。数据集包括60个用于开发的故事和60个用于测试的三至六年级的故事，附有一些简单的 who，what，when，where，why 这样的简单问题。它只需要系统返回包含正确答案的句子。这一阶段开发的系统主要是基于规则的词包方法。例如 DEEP READ 系统 ( Hirschman et al. 1999 ) 中进行词干分析、语义类识别和代词解析等浅层语言处理，或者像是 QUARC 系统 ( Riloff and THElen，2000 ) 中手动生成基于词汇和语义对应的规则或者是以上两个的组合体 ( Charnizak et al.， 2000 )。这些系统在检索正确句子时达到了30%-40%的准确率。</code></pre><p><a href="https://mp.weixin.qq.com/s/2gUhlgIaL_Qi0M8iPbWMkA" target="_blank" rel="noopener">ref</a><br>早期的工作者看到这个任务，首选的就是系统，这很符合直觉也和本文的观点一致，不管是设计qa问答机器人还是文本检索系统，其本身必定是一个系统，需要一定的特征设计和结合数据的程序设计。</p>
<p>那么现在基于深度学习设计的阅读理解模型是如何做的呢？<br>涉及到深度学习模型的MRC就一定要介绍SQUAD这个数据集了，在早期span detection这个数据f1已经刷到了超过90%，但是大家任然对包括Bert在内的这些机器阅读理解模型不抱太大期望能够做到理解文本，所以现在也已经推出了更新的SQUAD2。。。<br>根据笔者的经验，机器阅读理解这个任务，在深度学习里面经历了这么几个过程<br>denote： q和c分别对应阅读理解中的问题和文本内容</p>
<ul>
<li>Match-LSTM 先把q和c分别经过双向的LSTM，再通过attention机制，得到c中每个词q里所有词的权重，得到新的q的向量</li>
<li>BIDAF 分别计算q到c和c到q的attention 权重，利用这个权重乘以q和c得到q-wise的c和c-wise的q，concat起来做fusion</li>
<li>R-net 利用了self-attention，这边文章在 May. 6, 2017，在transformer之后，很显然self-attention的借鉴打破了之前到处attend的局势</li>
<li>QA-net 利用了CNN，和self-attention一直cnn也能够捕捉到并行的词依赖特征，虽然不如self-attention那么棒，但是QAnet经过了精心设计的让他好transformer的encoder结构很像。</li>
<li>Bert bert开始刷榜</li>
</ul>
<hr>
<p>我们介绍的这些模型都不差，但是存在的问题也很明显，首先阅读理解这个任务分为好几个任务</p>
<ul>
<li>完形填空类型 ( Cloze style )：问题包含一个 placeholder ( 占位符 )。</li>
<li>多项选择类型 ( Multiple choice )：在这个类别下，正确答案从 k 个假设答案中选择 ( 比如：k=4 ) </li>
<li>范围预测类型 ( Span prediction )：这个类别也被称为抽取式问答 ( extractive question answering ) 并且答案必须是文本中的一个范围。因此，答案可以表示为( astart，aend )，其中 1 ≤ astart ≤ aend ≤ lp。并且答案对英语 pastart, . . . , paend。</li>
<li>自由形式回答类型 ( Free-form answer )：最后一种类型允许答案是任何形式的文本 ( 即，任意长度的单词序列 )，形式上：a ∈ V∗。</li>
</ul>
<p>那么现有的模型能够做的相对好的，只有完形填空和范围预测，前者是predict token，后者是CrossEntry(p-end,p-start)，我不知道读者现在脑海里想的是什么，我想到的就是检索，机器阅读理解就是更家复杂的文本检索，这既是当今机器阅读理解的全部，如果你期望他能够做一些推理的任务，比如帮你数多少个人，时间差，在当前是不可能完成的。<br>那么我们能够用检索来完成，为何不用传统的方法BM25？<br>事实上，BM25在这些任务上不会比机器阅读理解差太多，一个中规中矩的深度学习baseline不会比BM25加上更多的文本特征工程更好（仅限于范围预测），但是深度学习带来的优势是，他真的是在帮你做阅读理解，他会抛出一个短语，几个词，而不是像BM25那样给出一句一句话。<br>根据我的个人实验，我使用了self-attention+Match_lstm+BIDAF+pointer_network的结构实现了一个阅读理解模型，比BM25召回的文本序列要短非常多，但是BLEU和Rouge要比BM25高。<a href="https://github.com/fooSynaptic/transfromer_NN_Block/tree/master/transformer_RC" target="_blank" rel="noopener">ref</a></p>
<p>经验：</p>
<ul>
<li>把问题分类，如果问题中详细的问道数字，人名，记录这部分信息。</li>
<li>对文章进行命名实体识别，把能够对应上的实体特征，提高该部分词的权重。</li>
<li>用最长的匹配字符串去找到后面的内容<a href="https://github.com/fooSynaptic/exam/blob/master/Coding/LCS_string.py" target="_blank" rel="noopener">lcs_continue_string</a></li>
<li>数字和特殊字符一定要保留完整信息并且成词</li>
</ul>
<p>如果您仍然觉得机器阅读理解不够棒，不能满足您的需求，请重新定义您的问题，或者不要期望阅读理解为您做更多。</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2019/10/04/因果关系推断介绍/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="jiaxin hu">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="fooSynaptic">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/10/04/因果关系推断介绍/" itemprop="url">因果关系推断介绍</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2019-10-04T07:34:37+08:00">
                2019-10-04
              </time>
            

            

            
          </span>

          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/2019/10/04/因果关系推断介绍/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count ds-thread-count" data-thread-key="2019/10/04/因果关系推断介绍/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>咳咳，真正的科普写起来太费劲又有点枯燥，先给大家带来一些相关工具的文档可以上手，理论部分如果以后还是懒得写的话就去抄之前的论文（过分。<br>这篇文章的内容来自于“  Causal Inference with Graphical Models in R Package pcalg ”，如果有时间的话可以直接跳转阅读。<br>如果你在寻求尝试因果推断的结构学习算法，可以参考PC算法的python版本，<a href="https://github.com/fooSynaptic/py_pcalg" target="_blank" rel="noopener">fooSynaptic/py_pcalg</a>，rep中提供了PC算法的结构学习算法并且支持可视化。</p>
<p>有关贝叶斯网络的内容其实火起来是从图模型，结构方程到因果推断，因此如果很介意因果推断这个说法的话，那么其实可以讲其等价于两个部分：1.变量之间的图结构的学习；2.图结构中方向的推断（大部分人其实不认同因果关系能够从数据中推断出来，然而在因果推断的研究中默认研究的是非时序的观测数据）。</p>
<p>正文<br>在很多学科当中，去理解变量之间的cause-effect关系都是一个非常让人感兴趣的话题。一般的，实验科学都会通过在实验中干预特殊的因素来观察这种关系。但是在现实生活中，存在因为时间，费用以及伦理等限制是没有办法做实验来发现这一关系的。<br>所以数据科学家们对于从观测数据中推断出因果的信息这个问题很感兴趣，也产生了非常多有意义的研究结果。通过合理的假设（这个以后补充），类似像PC算法这种可以通过观测的数据来推断出因果的结构。这些结果能够告诉我们-我们感兴趣的一部分变量能不能够成为另外一部分变量的cause（forgive me）。但是他并不像结构方程那样能够告诉我们这个影响的效应有多强（除非部分funcitonal causal model）。因此有了IDA算法的出现，它能够在没有隐变量和选择变量的存在下通过观测数据来推断出因果效应的边界，它综合了PC算法和Judea pear的后门准则。并且IDA算法在大规模的生物系统中得到了证实。然而，让观测系统中不存在隐变量是一个非常强的假设，现实的情况往往没法满足这种情况，因此，作者将后门准则衍化成一些其他类型的图结构来描述满足马尔可夫等价类的DAGs（有向无环图）。<br>R package pcalg整合了这诸多算法，包括了PC，FCI，RFCI，GES和GIES以及IDA。这篇文章也是通过一些模拟数据来应用这些方法的调用。<br>先简单看一个例子来理解因果推断</p>
<p>在图中，左边是真实的因果结构，右边是PC算法计算推断出来的因果结构，他的变现形式是一个马尔可夫等价类的DAG，主要蕴含了条件独立性的信息。<br>如图中所示，在算法推断出来的因果结构中有单向和双向的箭头。单向的箭头代表着直接的有向因果效应。双向的箭头意味着对于PC算法来说无法去判断这个因果效应的方向应该是⬅️还是➡️。因此，在推断的结果当中，双向的箭头代表这因果关系的不确定性。这其中有一个非常重要的事实：普遍的，PC算法类似的算法无法从观测数据中得到一个单一的DAG，即便说这个数据量非常有限，因为存在的事实是多个DAGs可以描述相同的条件独立性信息。<br>然后我们重点介绍一下马尔可夫等价类：为什么是类其实也就是因为多个结构可以描述相同的条件概率（贝叶斯概率），举个例子——</p>
<p>花了15分钟做的图，office online真辣鸡<br>对于： a. A&lt;—— C ——&gt;B 和b. A——&gt; C ——&gt; B是一对马尔可夫等价类，因为对于<br>a:   有- P(C)P(A|C)P(B|C) 。<br>b：有- P(A)P(C|A)P(B|C) = P(C)P(A|C)P(B|C) 。<br>所以a等价于b。<br>马尔科夫等价类在贝叶斯概率的计算上是等价的，却有着完全不同的结构。对于如上的链式图有两种贝叶斯概率。</p>
<p>研究方法背景介绍：<br>一般的，贝叶斯网络图、模型常用来进行因果结构的推断，图模型可以被理解为从联合概率到有依赖关系的结构的一种映射关系。就好像是地图一样，如果你想要使用地图，那么你需要两个要素，第一，你需要一个物理位置的图包含了点和线的符号，第二，你需要合理的规则来对图上的符号来作出解释。从这个观点考虑就能够理解，虽然高速公路地图和电车轨道地图看起来非常相像，不过他们对于符号的解释规则会存在较大的差别，所以图模型可以被理解为一张地图。图模型中都包含了一张具备了点，线以及潜在的mark，比如说箭头或者环，并且，图模型都有一套解释自己的的规则。一般的，在统计学习中，图中的节点代表着随机变量，而边代表了某种依赖关系。<br>我们先考虑不存在隐变量的情况<br>一个例子，有向无环图-DAG模型，无环意味着从图中任何一个节点出发沿着边延伸都无法回到起始节点。先考虑一种简单的解释规则- d-separation。<br>Define D-separation：<br>如果在模型图中存在两个节点x和y，他们被一个node集合S所分隔-d-separated，那么相应的在集合S的存在下，两个随机变量Vx和Vy条件性相互独立。<br>denote： Vx \bot Vy  | S .<br>相应的，满足d-separation的变量分布被称之为faithful，并且在统计上也被证明了大部分的变量分布都是faithful的。所以in practice这个假设并不strong。<br>因为DAG模型可以编码条件独立性关系，PC算法利用这一关系来推断我们前面提到的因果关系。PC算法被证明能够重构潜在的DAG模型结构，这个算法依赖于马尔可夫等价类（some variable with some 联合分布）中的条件独立性关系。实际在算法中，条件独立性骨架通过一个条件独立性的统计检验来完成。在某些不存在隐变量的情况下，即便存在非常高纬度的随机变量（意味着可能会有非常稀疏的众多DAG模型）PC算法利用统计检验来进行条件独立性分析是有较好的计算效率。<br>PC算法伪代码<br>输入：一个代表图模型节点的随机变量集合V；条件独立性信息；统计检验显著性水平 \alpha 。<br>输出：部分的完备有向无环图CPDAG \tilde{G} ，分隔变量集合 \tilde{S} ，以及边的方向👈还是👉。<br>构造随机变量集合V的完全的联通图（所有节点相连接）。<br>利用显著性水平\alpha对相邻的统计变量集合进行条件独立性检验，如果存在条件性独立，就将两个变量之间的边去除掉。<br>确定V结构（确定方向）。<br>树立剩余的边。</p>
<p>=========<br>转载请注明出处<br>=========</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2019/10/04/矩阵分解之一：Truncate-SVD-和random-SVD/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="jiaxin hu">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="fooSynaptic">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/10/04/矩阵分解之一：Truncate-SVD-和random-SVD/" itemprop="url">矩阵分解之一：Truncate SVD 和random SVD</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2019-10-04T07:32:18+08:00">
                2019-10-04
              </time>
            

            

            
          </span>

          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/2019/10/04/矩阵分解之一：Truncate-SVD-和random-SVD/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count ds-thread-count" data-thread-key="2019/10/04/矩阵分解之一：Truncate-SVD-和random-SVD/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>最近看了一点矩阵分解的论文发现了一些好玩的东西，所以会准备总结几篇矩阵分解的文章，标题图来自facebook research。</p>
<p>奇异值分解相对于矩阵分解的问题<br>每个学过线性代数的人都不会对奇异值分解感到陌生，因为SVD广泛地应用于统计学，信号处理以及机器学习当中。形式上来看，一个维度为 m × n的实数矩阵的奇异值分列可以表示为A = U Σ Vᵀ；其中U代表的是一个维度为m × m的正交奇异向量矩阵，∑代表着奇异值的对角矩阵，最后一项是一个n × n的正交奇异向量矩阵。<br>在矩阵分解这个问题上，奇异值分解提供的策略是计算一个相对于A更低秩的近似矩阵Aᵣ，意味着r&lt;m, n， 并且要使得||Aᵣ – A||最小。那么对于A = U Σ Vᵀtruncate SVD的策略是：<br>对于对角矩阵上面的奇异值进行降序排序；<br>在对角矩阵∑上面取前r个奇异值，相对应的在左右两边的奇异向量矩阵上面也取相对于的r列，最后分别得到了Σᵣ，Uᵣ， Vᵣ。<br>将Aᵣ = Uᵣ Σᵣ Vᵣᵀ作为最终矩阵分解的产物。<br>上述过程可以用如下的示意图来表示：</p>
<p>这样，通过SVD就可以成功的完成矩阵降维的过程。我们从矩阵分解来到了很相近的另外一个主题——降维，作为降维届的代表技术——PCA，而矩阵的奇异值分解能够直接得到矩阵通过PCA的投影空间。对于一个协变量矩阵X为 m × p（m为观测）的观测特征矩阵，计算一个p × l 的矩阵W和一个 l × l 的对角矩阵Λ，能够使得 Xᵀ X ≈ W Λ Wᵀ。这样地近似可以将原先的观测矩阵投影到一个维度为l的空间从而达到降维。有一种精简的PCA算法计算的形式是通过直接近似一个低秩的协变量矩阵X ≈ Uᵣ Σᵣ Vᵣᵀ，然后乘上转置，最终因为左奇异向量矩阵正交而直接得到投影的向量空间。<br> Xᵀ X ≈ (Uᵣ Σᵣ Vᵣᵀ)ᵀ (Uᵣ Σᵣ Vᵣᵀ) = Vᵣ Σᵣ² Vᵣᵀ<br>如上最终的对角矩阵就是新的投影空间。<br>但是truncate SVD有一些缺点（通过上述和PCA的论述其实可以得到这个缺点是传统降维技术共有的）：<br>实际的工业环境中，矩阵的维度是巨大的，并且数据往往是缺失，不准确的；当不准确的输入限制了输出的精确性时，仅仅依靠这些实际的数据只会白白浪费计算资源。<br>传统的降维技术是不支持并行计算的，如果你熟悉工业数据你就应该知道这一点有多么可怕。</p>
<p>到这里我们就要进入这篇文章的转折点引出我们的主角了——Randomized SVD<br>它相对于truncate SVD的优势有这么几点：<br>很稳定。<br>它的性能并不依赖于局部的特征。<br>大量的矩阵乘法过程，可以利用GPU并行计算，所以它比truncate SVD更快。<br>相比于直接从理论上阐述randomized SVD，我想更直接一点，直接参考它的实现过程能够让我们更快地理解。<br>首先我们需要定义一个方法来找到一个正交矩阵，这个矩阵的范围近似于观测矩阵的范围（这个和我们上面的思路很像，一个更小的矩阵），这里我们会用到一些传统的LU和QR分解。</p>
<h1 id="在这里的LU和QR分解起的是规范子的作用，QR相对LU更慢但是更准确，所以QR规范放在最后一层。"><a href="#在这里的LU和QR分解起的是规范子的作用，QR相对LU更慢但是更准确，所以QR规范放在最后一层。" class="headerlink" title="在这里的LU和QR分解起的是规范子的作用，QR相对LU更慢但是更准确，所以QR规范放在最后一层。"></a>在这里的LU和QR分解起的是规范子的作用，QR相对LU更慢但是更准确，所以QR规范放在最后一层。</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">randomized_range_finder</span><span class="params">(A, size, n_iter=<span class="number">5</span>)</span>:</span></span><br><span class="line">    Q = np.random.normal(size=(A.shape[<span class="number">1</span>], size))</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(n_iter):</span><br><span class="line">        Q, _ = linalg.lu(A @ Q, permute_l=<span class="literal">True</span>)</span><br><span class="line">        Q, _ = linalg.lu(A.T @ Q, permute_l=<span class="literal">True</span>)</span><br><span class="line">        </span><br><span class="line">    Q, _ = linalg.qr(A @ Q, mode=<span class="string">'economic'</span>)</span><br><span class="line">    <span class="keyword">return</span> Q</span><br></pre></td></tr></table></figure>

<p>现在我们能够得到了观测矩阵范围的近似Q，我们利用Q来得到最终的近似结果：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">randomized_svd</span><span class="params">(M, n_components, n_oversamples=<span class="number">10</span>, n_iter=<span class="number">4</span>)</span>:</span></span><br><span class="line">    <span class="comment">#这里n_random就是truncate SVD中的r</span></span><br><span class="line">    n_random = n_components + n_oversamples</span><br><span class="line">    </span><br><span class="line">    Q = randomized_range_finder(M, n_random, n_iter)</span><br><span class="line">    </span><br><span class="line">    <span class="comment">#把原始观测投影到(k + p)维度空间</span></span><br><span class="line">    B = Q.T @ M</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 对B进行奇异值分解</span></span><br><span class="line">    Uhat, s, V = linalg.svd(B, full_matrices=<span class="literal">False</span>)</span><br><span class="line">    <span class="keyword">del</span> B</span><br><span class="line">    U = Q @ Uhat</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> U[:, :n_components], s[:n_components], V[:n_components, :]</span><br></pre></td></tr></table></figure>

<p>没有看懂？好吧让我们来讲讲这个原理，randomize SVD对于矩阵分解能够作为一种通用的算法，简单讲分成两步，<br>第一步是求原始矩阵范围的近似Q，这个过程中通过对一个随机初始化的小维度矩阵Q不断地进行和原矩阵相乘然后分解，最终得到一个稳定的向量矩阵，为什么不取对角矩阵，因为对角矩阵是特征基矩阵，而左边的向量矩阵可以作为量纲矩阵。最终我们的目标是得到A ≈ Q Qᵀ A。<br>第二步很简单，有了A ≈ Q Qᵀ A，我们构造一个矩阵B = Qᵀ A，因为Q是低秩的，所以矩阵B很小。我们可以用传统SVD的方法来对矩阵B进行分解B = S Σ Vᵀ，得到左奇异，奇异值矩阵，右奇异向量矩阵。到这里A ≈ Q Qᵀ A = Q (S Σ Vᵀ)，最右边所有量都已知，成功地对A求到了一个低秩的近似U Σ Vᵀ。<br>（通过上面的代码，可以很直接得理解这两步原理。）<br>Tricks and intuition:<br>randomized SVD的trick就是能够非常高效得求得范围近似矩阵Q，从直觉上来思考，为了估计原始矩阵的范围，我们可以用一些随机的向量，通过原始矩阵A和这些随机向量的相乘所作出的变动的近似来得到A的波动范围。<br>Specific：假设我们使用一个高斯向量矩阵M来和原矩阵相乘，计算Y = A M，然后对Y进行QR分解Q R = Y，这样得到的矩阵Q，它的没一列就是Y的范围的正交基，所以可以作为A的范围近似。</p>
<p>=========<br>转载请注明出处<br>=========</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2019/10/04/开篇/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="jiaxin hu">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="fooSynaptic">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/10/04/开篇/" itemprop="url">开篇</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2019-10-04T07:18:17+08:00">
                2019-10-04
              </time>
            

            

            
          </span>

          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/2019/10/04/开篇/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count ds-thread-count" data-thread-key="2019/10/04/开篇/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>各位同学们大家好，我是fooSynaptic，本来买好了机器打算做一个个人网站，但是没有想到的是hexo居然这么好用，而且markdown对于我来说用的还算比较熟，总体体验还算是可以的。</p>
<h1 id="关于这个website"><a href="#关于这个website" class="headerlink" title="关于这个website"></a>关于这个website</h1><p>这个博客主要会用来记录包括但不限于如下的一些内容：</p>
<ul>
<li>NLP技术</li>
<li>机器学习算法的实现细节</li>
<li>深度学习框架建模细节</li>
<li>Mathmatic</li>
<li>程序算法设计</li>
<li>Python</li>
<li>web应用开发</li>
</ul>
<h1 id="关于我"><a href="#关于我" class="headerlink" title="关于我"></a>关于我</h1><p>NLP researcher<br>如果你想了解更多关于我的项目，请参考我的github项目：<a href="https://github.com/fooSynaptic" target="_blank" rel="noopener">ref link</a></p>
<p>=========<br>转载请注明出处<br>=========</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2019/10/04/article/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="jiaxin hu">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="fooSynaptic">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/10/04/article/" itemprop="url">article</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2019-10-04T06:42:41+08:00">
                2019-10-04
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/demo/" itemprop="url" rel="index">
                    <span itemprop="name">demo</span>
                  </a>
                </span>

                
                
                  , 
                
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/demo/Let-s-begin/" itemprop="url" rel="index">
                    <span itemprop="name">Let's begin</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/2019/10/04/article/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count ds-thread-count" data-thread-key="2019/10/04/article/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            
          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
  </section>

  


          </div>
          


          

        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      

      <section class="site-overview-wrap sidebar-panel sidebar-panel-active">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <p class="site-author-name" itemprop="name">jiaxin hu</p>
              <p class="site-description motion-element" itemprop="description">Head first to the Truth as Synaptics.</p>
          </div>

          <nav class="site-state motion-element">

            
              <div class="site-state-item site-state-posts">
              
                <a href="/archives/">
              
                  <span class="site-state-item-count">6</span>
                  <span class="site-state-item-name">posts</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-categories">
                
                  <span class="site-state-item-count">2</span>
                  <span class="site-state-item-name">categories</span>
                
              </div>
            

            
              
              
              <div class="site-state-item site-state-tags">
                <a href="/tags/index.html">
                  <span class="site-state-item-count">9</span>
                  <span class="site-state-item-name">tags</span>
                </a>
              </div>
            

          </nav>

          

          
            <div class="links-of-author motion-element">
                
                  <span class="links-of-author-item">
                    <a href="https://github.com/fooSynaptic" target="_blank" title="GitHub">
                      
                        <i class="fa fa-fw fa-globe"></i>GitHub</a>
                  </span>
                
                  <span class="links-of-author-item">
                    <a href="https://www.zhihu.com/people/jiu-san-gong-ren/activities" target="_blank" title="ZhiHu">
                      
                        <i class="fa fa-fw fa-globe"></i>ZhiHu</a>
                  </span>
                
            </div>
          

          
          

          
          

          

        </div>
      </section>

      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2019</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">jiaxin hu</span>

  
</div>


  <div class="powered-by">Powered by <a class="theme-link" target="_blank" href="https://hexo.io">Hexo</a></div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">Theme &mdash; <a class="theme-link" target="_blank" href="https://github.com/iissnan/hexo-theme-next">NexT.Muse</a> v5.1.4</div>




        







        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  












  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>
  

  
  
    <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.4"></script>



  
  

  

  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.4"></script>



  

  
    
  

  <script type="text/javascript">
    var duoshuoQuery = {short_name:"your-duoshuo-shortname"};
    (function() {
      var ds = document.createElement('script');
      ds.type = 'text/javascript';ds.async = true;
      ds.id = 'duoshuo-script';
      ds.src = (document.location.protocol == 'https:' ? 'https:' : 'http:') + '//static.duoshuo.com/embed.js';
      ds.charset = 'UTF-8';
      (document.getElementsByTagName('head')[0]
      || document.getElementsByTagName('body')[0]).appendChild(ds);
    })();
  </script>

  
    
    
    <script src="/lib/ua-parser-js/dist/ua-parser.min.js?v=0.7.9"></script>
    <script src="/js/src/hook-duoshuo.js"></script>
  
















  <script src="//cdn1.lncld.net/static/js/3.0.4/av-min.js"></script>
  <script src="//unpkg.com/valine/dist/Valine.min.js"></script>
  
  <script type="text/javascript">
    var GUEST = ['nick','mail','link'];
    var guest = 'nick';
    guest = guest.split(',').filter(item=>{
      return GUEST.indexOf(item)>-1;
    });
    new Valine({
        el: '#comments' ,
        verify: false,
        notify: false,
        appId: 'm3IyaPmV3FOoJuQ9ic9ToH5x-gzGzoHsz',
        appKey: 'Gu82zvrKj6u6gHD5UN0iL222',
        placeholder: 'Welecome to share your idea!',
        avatar:'wavatar',
        guest_info:guest,
        pageSize:'10' || 10,
    });
  </script>



  





  

  

  

  
  

  

  

  

</body>
</html>
