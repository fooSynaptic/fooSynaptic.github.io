<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width">
<meta name="theme-color" content="#222"><meta name="generator" content="Hexo 8.1.1">

  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/jojo_median.ico">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/jojo_small.ico">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">



<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/7.0.0/css/all.min.css" integrity="sha256-VHqXKFhhMxcpubYf9xiWdCiojEbY9NexQ4jh8AxbvcM=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/animate.css/3.1.1/animate.min.css" integrity="sha256-PR7ttpcvz8qrF57fur/yAx1qXMFJeJFiA6pSzWi0OIE=" crossorigin="anonymous">

<script class="next-config" data-name="main" type="application/json">{"hostname":"foosynaptic.github.io","root":"/","images":"/images","scheme":"Muse","darkmode":false,"version":"8.26.0","exturl":false,"sidebar":{"position":"left","width_expanded":320,"width_dual_column":240,"display":"post","padding":18,"offset":12},"hljswrap":true,"codeblock":{"theme":{"light":"default","dark":"dark"},"prism":{"light":"prism","dark":"prism-dark"},"copy_button":{"enable":true,"style":null},"fold":{"enable":false,"height":500},"language":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"stickytabs":false,"motion":{"enable":true,"async":false,"duration":200,"transition":{"menu_item":"fadeInDown","post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},"i18n":{"placeholder":"搜索...","empty":"没有找到任何搜索结果：${query}","hits_time":"找到 ${hits} 个搜索结果（用时 ${time} 毫秒）","hits":"找到 ${hits} 个搜索结果"},"path":"/search.json","localsearch":{"enable":true,"top_n_per_article":1,"unescape":false,"preload":false,"trigger":"auto"}}</script><script src="/js/config.js" defer></script>

    <meta name="description" content="Head first to the Truth as Synaptic.">
<meta property="og:type" content="website">
<meta property="og:title" content="fooSynaptic">
<meta property="og:url" content="https://foosynaptic.github.io/index.html">
<meta property="og:site_name" content="fooSynaptic">
<meta property="og:description" content="Head first to the Truth as Synaptic.">
<meta property="og:locale" content="zh_CN">
<meta property="article:author" content="fooSynaptic">
<meta property="article:tag" content="AI, LLM, NLP, Deep Learning">
<meta name="twitter:card" content="summary">


<link rel="canonical" href="https://foosynaptic.github.io/">


<script class="next-config" data-name="page" type="application/json">{"sidebar":"","isHome":true,"isPost":false,"lang":"zh-CN","comments":"","permalink":"","path":"index.html","title":""}</script>

<script class="next-config" data-name="calendar" type="application/json">""</script>
<title>fooSynaptic</title>
  








  
  <script src="https://cdnjs.cloudflare.com/ajax/libs/animejs/3.2.1/anime.min.js" integrity="sha256-XL2inqUJaslATFnHdJOi9GfQ60on8Wx1C2H8DYiN1xY=" crossorigin="anonymous" defer></script>
<script src="/js/utils.js" defer></script><script src="/js/motion.js" defer></script><script src="/js/sidebar.js" defer></script><script src="/js/next-boot.js" defer></script>

  <script src="https://cdnjs.cloudflare.com/ajax/libs/hexo-generator-searchdb/1.5.0/search.js" integrity="sha256-xFC6PJ82SL9b3WkGjFavNiA9gm5z6UBxWPiu4CYjptg=" crossorigin="anonymous" defer></script>
<script src="/js/third-party/search/local-search.js" defer></script>







  




  

  <script class="next-config" data-name="enableMath" type="application/json">true</script><script class="next-config" data-name="mathjax" type="application/json">{"enable":true,"tags":"none","js":{"url":"https://cdnjs.cloudflare.com/ajax/libs/mathjax/3.2.2/es5/tex-mml-chtml.js","integrity":"sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI="}}</script>
<script src="/js/third-party/math/mathjax.js" defer></script>



  <noscript>
    <link rel="stylesheet" href="/css/noscript.css">
  </noscript>
<style>mjx-container[jax="SVG"] {
  direction: ltr;
}

mjx-container[jax="SVG"] > svg {
  overflow: visible;
}

mjx-container[jax="SVG"][display="true"] {
  display: block;
  text-align: center;
  margin: 1em 0;
}

mjx-container[jax="SVG"][justify="left"] {
  text-align: left;
}

mjx-container[jax="SVG"][justify="right"] {
  text-align: right;
}

g[data-mml-node="merror"] > g {
  fill: red;
  stroke: red;
}

g[data-mml-node="merror"] > rect[data-background] {
  fill: yellow;
  stroke: none;
}

g[data-mml-node="mtable"] > line[data-line] {
  stroke-width: 70px;
  fill: none;
}

g[data-mml-node="mtable"] > rect[data-frame] {
  stroke-width: 70px;
  fill: none;
}

g[data-mml-node="mtable"] > .mjx-dashed {
  stroke-dasharray: 140;
}

g[data-mml-node="mtable"] > .mjx-dotted {
  stroke-linecap: round;
  stroke-dasharray: 0,140;
}

g[data-mml-node="mtable"] > svg {
  overflow: visible;
}

[jax="SVG"] mjx-tool {
  display: inline-block;
  position: relative;
  width: 0;
  height: 0;
}

[jax="SVG"] mjx-tool > mjx-tip {
  position: absolute;
  top: 0;
  left: 0;
}

mjx-tool > mjx-tip {
  display: inline-block;
  padding: .2em;
  border: 1px solid #888;
  font-size: 70%;
  background-color: #F8F8F8;
  color: black;
  box-shadow: 2px 2px 5px #AAAAAA;
}

g[data-mml-node="maction"][data-toggle] {
  cursor: pointer;
}

mjx-status {
  display: block;
  position: fixed;
  left: 1em;
  bottom: 1em;
  min-width: 25%;
  padding: .2em .4em;
  border: 1px solid #888;
  font-size: 90%;
  background-color: #F8F8F8;
  color: black;
}

foreignObject[data-mjx-xml] {
  font-family: initial;
  line-height: normal;
  overflow: visible;
}

.MathJax path {
  stroke-width: 3;
}

mjx-container[display="true"] {
  overflow: auto hidden;
}

mjx-container[display="true"] + br {
  display: none;
}
</style></head>

<body itemscope itemtype="http://schema.org/WebPage" class="use-motion">
  <div class="headband"></div>

  <main class="main">
    <div class="column">
      <header class="header" itemscope itemtype="http://schema.org/WPHeader"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏" role="button">
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <i class="logo-line"></i>
      <h1 class="site-title">fooSynaptic</h1>
      <i class="logo-line"></i>
    </a>
      <p class="site-subtitle" itemprop="description">Any problem, please Contact me: 2313990450@qq.com</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger" aria-label="搜索" role="button">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>



<nav class="site-nav">
  <ul class="main-menu menu"><li class="menu-item menu-item-home"><a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a></li><li class="menu-item menu-item-about"><a href="/about/" rel="section"><i class="fa fa-user fa-fw"></i>关于</a></li><li class="menu-item menu-item-archives"><a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档</a></li><li class="menu-item menu-item-tags"><a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>标签</a></li><li class="menu-item menu-item-categories"><a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>分类</a></li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>搜索
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup">
      <div class="search-header">
        <span class="search-icon">
          <i class="fa fa-search"></i>
        </span>
        <div class="search-input-container">
          <input autocomplete="off" autocapitalize="off" maxlength="80"
                placeholder="搜索..." spellcheck="false"
                type="search" class="search-input">
        </div>
        <span class="popup-btn-close" role="button">
          <i class="fa fa-times-circle"></i>
        </span>
      </div>
      <div class="search-result-container">
        <div class="search-result-icon">
          <i class="fa fa-spinner fa-pulse fa-5x"></i>
        </div>
      </div>
    </div>
  </div>

</header>
        
  
  <aside class="sidebar">

    <div class="sidebar-inner sidebar-overview-active">
      <ul class="sidebar-nav">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <div class="sidebar-panel-container">
        <!--noindex-->
        <div class="post-toc-wrap sidebar-panel">
        </div>
        <!--/noindex-->

        <div class="site-overview-wrap sidebar-panel">
          <div class="site-author animated" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="fooSynaptic"
      src="/images/avatar.gif">
  <p class="site-author-name" itemprop="name">fooSynaptic</p>
  <div class="site-description" itemprop="description">Head first to the Truth as Synaptic.</div>
</div>
<div class="site-state-wrap animated">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
        <a href="/archives/">
          <span class="site-state-item-count">17</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
          <a href="/categories/">
        <span class="site-state-item-count">2</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
      <div class="site-state-item site-state-tags">
          <a href="/tags/">
        <span class="site-state-item-count">38</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author animated">
      <span class="links-of-author-item">
        <a href="https://github.com/fooSynaptic" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;fooSynaptic" rel="noopener me" target="_blank"><i class="fab fa-github fa-fw"></i>GitHub</a>
      </span>
      <span class="links-of-author-item">
        <a href="mailto:2313990450@qq.com" title="E-Mail → mailto:2313990450@qq.com" rel="noopener me" target="_blank"><i class="fa fa-envelope fa-fw"></i>E-Mail</a>
      </span>
  </div>

        </div>
      </div>
    </div>

    
  </aside>


    </div>

    <div class="main-inner index posts-expand">

    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://foosynaptic.github.io/2025/12/28/LLM-Game-Agents-%E5%BA%94%E7%94%A8%E6%89%A9%E5%B1%95%E7%AF%87/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="fooSynaptic">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="fooSynaptic">
      <meta itemprop="description" content="Head first to the Truth as Synaptic.">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content=" | fooSynaptic">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2025/12/28/LLM-Game-Agents-%E5%BA%94%E7%94%A8%E6%89%A9%E5%B1%95%E7%AF%87/" class="post-title-link" itemprop="url">LLM 游戏智能体论文解读：应用扩展篇</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2025-12-28 04:02:00" itemprop="dateCreated datePublished" datetime="2025-12-28T04:02:00+08:00">2025-12-28</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E8%AE%BA%E6%96%87%E8%A7%A3%E8%AF%BB/" itemprop="url" rel="index"><span itemprop="name">论文解读</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <p>本文深入解读 LLM 智能体领域的三个重要应用扩展：VOYAGER（终身学习）、Project Sid（AI文明）和 Agent Hospital（可进化医疗智能体）。</p>
<hr>
<h2 id="一、VOYAGER：开放世界具身终身学习智能体"><a href="#一、VOYAGER：开放世界具身终身学习智能体" class="headerlink" title="一、VOYAGER：开放世界具身终身学习智能体"></a>一、VOYAGER：开放世界具身终身学习智能体</h2><p><strong>论文</strong>: An Open-Ended Embodied Agent with Large Language Models<br><strong>会议</strong>: NeurIPS 2023 (FMDM Workshop)<br><strong>作者</strong>: Guanzhi Wang 等 (NVIDIA, Caltech, UT Austin)<br><strong>项目主页</strong>: <a target="_blank" rel="noopener" href="https://voyager.minedojo.org/">voyager.minedojo.org</a></p>
<h3 id="1-1-核心创新"><a href="#1-1-核心创新" class="headerlink" title="1.1 核心创新"></a>1.1 核心创新</h3><p>VOYAGER 是<strong>首个 LLM 驱动的具身终身学习智能体</strong>，在 Minecraft 中持续探索世界、获取技能、做出新发现，无需人类干预。</p>
<p><strong>三大核心组件</strong>:</p>
<table>
<thead>
<tr>
<th>组件</th>
<th>功能</th>
<th>技术实现</th>
</tr>
</thead>
<tbody><tr>
<td><strong>自动课程</strong></td>
<td>提出适当难度的任务</td>
<td>GPT-4 + 探索进度 + 智能体状态</td>
</tr>
<tr>
<td><strong>技能库</strong></td>
<td>存储和检索可复用代码</td>
<td>向量数据库 + 嵌入检索</td>
</tr>
<tr>
<td><strong>迭代提示</strong></td>
<td>自我改进代码生成</td>
<td>环境反馈 + 执行错误 + 自我验证</td>
</tr>
</tbody></table>
<h3 id="1-2-系统架构"><a href="#1-2-系统架构" class="headerlink" title="1.2 系统架构"></a>1.2 系统架构</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">┌─────────────────────────────────────────────────────────────────────┐</span><br><span class="line">│                    VOYAGER 系统架构                                  │</span><br><span class="line">├─────────────────────────────────────────────────────────────────────┤</span><br><span class="line">│                                                                     │</span><br><span class="line">│   ┌───────────────┐                                                 │</span><br><span class="line">│   │   GPT-4 API   │◀──────────────────────────────────┐            │</span><br><span class="line">│   │  (黑盒调用)    │                                   │            │</span><br><span class="line">│   └───────────────┘                                   │            │</span><br><span class="line">│          │                                            │            │</span><br><span class="line">│          ▼                                            │            │</span><br><span class="line">│   ┌───────────────┐    ┌───────────────┐    ┌────────┴────────┐   │</span><br><span class="line">│   │ 自动课程生成   │    │   代码生成    │    │    自我验证     │   │</span><br><span class="line">│   │ (GPT-4提示)   │    │ (GPT-4提示)   │    │  (GPT-4提示)    │   │</span><br><span class="line">│   └───────────────┘    └───────────────┘    └─────────────────┘   │</span><br><span class="line">│          │                    │                      │             │</span><br><span class="line">│          ▼                    ▼                      ▼             │</span><br><span class="line">│   ┌───────────────┐    ┌───────────────┐    ┌─────────────────┐   │</span><br><span class="line">│   │   任务队列    │    │  Minecraft    │    │    技能库       │   │</span><br><span class="line">│   └───────────────┘    │   环境执行    │    │  (向量数据库)   │   │</span><br><span class="line">│                        └───────────────┘    └─────────────────┘   │</span><br><span class="line">│                                                                     │</span><br><span class="line">└─────────────────────────────────────────────────────────────────────┘</span><br></pre></td></tr></table></figure>

<h3 id="1-3-自动课程系统"><a href="#1-3-自动课程系统" class="headerlink" title="1.3 自动课程系统"></a>1.3 自动课程系统</h3><p><strong>设计理念</strong>: 自下而上展开，由好奇心驱动</p>
<p><strong>输入提示组件</strong>:</p>
<ol>
<li><strong>指令</strong>: 鼓励多样化行为并施加约束</li>
<li><strong>智能体当前状态</strong>: 物品栏、装备、位置、生命值等</li>
<li><strong>先前任务记录</strong>: 已完成和失败的任务</li>
<li><strong>额外上下文</strong>: GPT-3.5 自问自答</li>
</ol>
<p><strong>示例提示</strong>:</p>
<blockquote>
<p>“我的最终目标是发现尽可能多的多样化事物…下一个任务不应该太难，因为我可能还没有必要的资源或学会足够的技能来完成它。”</p>
</blockquote>
<h3 id="1-4-技能库机制"><a href="#1-4-技能库机制" class="headerlink" title="1.4 技能库机制"></a>1.4 技能库机制</h3><p><strong>技能表示</strong>: 可执行的 JavaScript 代码</p>
<figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 示例技能: 制作木镐</span></span><br><span class="line"><span class="keyword">async</span> <span class="keyword">function</span> <span class="title function_">craftWoodenPickaxe</span>(<span class="params">bot</span>) {</span><br><span class="line">  <span class="comment">// 首先获取木材</span></span><br><span class="line">  <span class="keyword">await</span> <span class="title function_">mineBlock</span>(bot, <span class="string">"oak_log"</span>, <span class="number">1</span>);</span><br><span class="line">  <span class="comment">// 制作木板</span></span><br><span class="line">  <span class="keyword">await</span> <span class="title function_">craftItem</span>(bot, <span class="string">"oak_planks"</span>, <span class="number">4</span>);</span><br><span class="line">  <span class="comment">// 制作木棍</span></span><br><span class="line">  <span class="keyword">await</span> <span class="title function_">craftItem</span>(bot, <span class="string">"stick"</span>, <span class="number">2</span>);</span><br><span class="line">  <span class="comment">// 制作木镐</span></span><br><span class="line">  <span class="keyword">await</span> <span class="title function_">craftItem</span>(bot, <span class="string">"wooden_pickaxe"</span>, <span class="number">1</span>);</span><br><span class="line">}</span><br></pre></td></tr></table></figure>

<p><strong>存储与检索</strong>:</p>
<ul>
<li><strong>键</strong>: 程序描述的嵌入向量（GPT-3.5生成）</li>
<li><strong>值</strong>: 可执行的JavaScript代码</li>
<li><strong>检索</strong>: 余弦相似度 + 任务上下文</li>
</ul>
<h3 id="1-5-迭代提示机制"><a href="#1-5-迭代提示机制" class="headerlink" title="1.5 迭代提示机制"></a>1.5 迭代提示机制</h3><p><strong>三种反馈类型</strong>:</p>
<table>
<thead>
<tr>
<th>反馈类型</th>
<th>来源</th>
<th>作用</th>
</tr>
</thead>
<tbody><tr>
<td><strong>环境反馈</strong></td>
<td>程序执行日志</td>
<td>显示中间进度，如”需要多7个铁锭”</td>
</tr>
<tr>
<td><strong>执行错误</strong></td>
<td>程序解释器</td>
<td>揭示语法错误和无效操作</td>
</tr>
<tr>
<td><strong>自我验证</strong></td>
<td>GPT-4评论家</td>
<td>判断任务完成，提供改进建议</td>
</tr>
</tbody></table>
<p><strong>代码生成的12个提示组件</strong>:</p>
<table>
<thead>
<tr>
<th>#</th>
<th>组件</th>
<th>描述</th>
</tr>
</thead>
<tbody><tr>
<td>1</td>
<td>代码生成指南</td>
<td>编写规范和约束</td>
</tr>
<tr>
<td>2</td>
<td>控制原语API</td>
<td>高级API（exploreUntil, mineBlock等）</td>
</tr>
<tr>
<td>3</td>
<td>Mineflayer API</td>
<td>底层游戏控制API</td>
</tr>
<tr>
<td>4</td>
<td><strong>检索的技能</strong></td>
<td>从技能库检索的相关代码</td>
</tr>
<tr>
<td>5</td>
<td><strong>上一轮代码</strong></td>
<td>用于迭代改进</td>
</tr>
<tr>
<td>6</td>
<td><strong>环境反馈</strong></td>
<td>聊天日志中的执行信息</td>
</tr>
<tr>
<td>7</td>
<td><strong>执行错误</strong></td>
<td>解释器错误信息</td>
</tr>
<tr>
<td>8</td>
<td><strong>自我验证批评</strong></td>
<td>验证模块的反馈</td>
</tr>
<tr>
<td>9</td>
<td>智能体状态</td>
<td>物品栏、位置、生命值等</td>
</tr>
<tr>
<td>10</td>
<td>任务</td>
<td>自动课程提出的任务</td>
</tr>
<tr>
<td>11</td>
<td>任务上下文</td>
<td>GPT-3.5生成的解决建议</td>
</tr>
<tr>
<td>12</td>
<td>思维链提示</td>
<td>要求解释→计划→代码的顺序</td>
</tr>
</tbody></table>
<h3 id="1-6-实验结果"><a href="#1-6-实验结果" class="headerlink" title="1.6 实验结果"></a>1.6 实验结果</h3><p><strong>vs 基线方法</strong>:</p>
<table>
<thead>
<tr>
<th>指标</th>
<th>VOYAGER</th>
<th>AutoGPT</th>
<th>ReAct</th>
<th>Reflexion</th>
</tr>
</thead>
<tbody><tr>
<td>独特物品发现</td>
<td><strong>63</strong></td>
<td>19</td>
<td>~10</td>
<td>~10</td>
</tr>
<tr>
<td>倍数</td>
<td><strong>3.3x</strong></td>
<td>1x</td>
<td>-</td>
<td>-</td>
</tr>
</tbody></table>
<p><strong>科技树解锁速度</strong>:</p>
<table>
<thead>
<tr>
<th>级别</th>
<th>VOYAGER</th>
<th>AutoGPT</th>
<th>提升</th>
</tr>
</thead>
<tbody><tr>
<td>木制工具</td>
<td>6分钟</td>
<td>92分钟</td>
<td><strong>15.3x</strong></td>
</tr>
<tr>
<td>石制工具</td>
<td>11分钟</td>
<td>94分钟</td>
<td><strong>8.5x</strong></td>
</tr>
<tr>
<td>铁制工具</td>
<td>21分钟</td>
<td>135分钟</td>
<td><strong>6.4x</strong></td>
</tr>
<tr>
<td>钻石工具</td>
<td>102分钟</td>
<td>N/A</td>
<td><strong>唯一成功</strong></td>
</tr>
</tbody></table>
<p><strong>消融实验结论</strong>:</p>
<ul>
<li>自动课程至关重要：移除后物品发现下降93%</li>
<li>自我验证最重要：移除后物品发现下降73%</li>
<li>GPT-4 vs GPT-3.5：GPT-4获得5.7倍更多独特物品</li>
</ul>
<h3 id="1-7-关键洞见"><a href="#1-7-关键洞见" class="headerlink" title="1.7 关键洞见"></a>1.7 关键洞见</h3><blockquote>
<p><strong>代码即记忆</strong>: VOYAGER 将”学习”转化为”运行时组合”——通过检索已有技能并迭代改进代码，而不是更新模型权重。</p>
</blockquote>
<table>
<thead>
<tr>
<th>传统方法</th>
<th>VOYAGER</th>
</tr>
</thead>
<tbody><tr>
<td>微调模型参数</td>
<td>黑盒API调用</td>
</tr>
<tr>
<td>隐式知识存储</td>
<td>显式代码技能库</td>
</tr>
<tr>
<td>难以解释</td>
<td>代码可读可执行</td>
</tr>
<tr>
<td>灾难性遗忘</td>
<td>技能永久保存</td>
</tr>
</tbody></table>
<hr>
<h2 id="二、Project-Sid：迈向AI文明的多智能体模拟"><a href="#二、Project-Sid：迈向AI文明的多智能体模拟" class="headerlink" title="二、Project Sid：迈向AI文明的多智能体模拟"></a>二、Project Sid：迈向AI文明的多智能体模拟</h2><p><strong>论文</strong>: Many-agent simulations toward AI civilization<br><strong>机构</strong>: Altera.AL<br><strong>发布日期</strong>: 2024年10月<br><strong>规模</strong>: 10-1000+ 智能体</p>
<h3 id="2-1-核心问题"><a href="#2-1-核心问题" class="headerlink" title="2.1 核心问题"></a>2.1 核心问题</h3><blockquote>
<p><strong>为什么我们应该尝试构建AI文明？</strong></p>
</blockquote>
<p>为了让智能体与人类社会共存，他们需要是<strong>自主的和协作的</strong>。文明进步——通过智能体在人类文明中共存和进步的能力来衡量——代表了AI智能体能力的<strong>终极基准</strong>。</p>
<h3 id="2-2-构建AI文明的挑战"><a href="#2-2-构建AI文明的挑战" class="headerlink" title="2.2 构建AI文明的挑战"></a>2.2 构建AI文明的挑战</h3><table>
<thead>
<tr>
<th>挑战</th>
<th>问题描述</th>
</tr>
</thead>
<tbody><tr>
<td><strong>单智能体不进展</strong></td>
<td>幻觉积累、陷入重复动作循环</td>
</tr>
<tr>
<td><strong>多智能体不协调</strong></td>
<td>错误沟通导致幻觉传播</td>
</tr>
<tr>
<td><strong>缺乏基准</strong></td>
<td>无法量化文明进步</td>
</tr>
</tbody></table>
<p><strong>一致性问题示例</strong>:</p>
<blockquote>
<p>智能体Abby被Bob要求”给我一把镐”时，聊天模块回应”当然可以！”，但函数调用模块选择”探索”。Bob可能然后尝试用想象的镐采矿。</p>
</blockquote>
<h3 id="2-3-PIANO-架构"><a href="#2-3-PIANO-架构" class="headerlink" title="2.3 PIANO 架构"></a>2.3 PIANO 架构</h3><p><strong>PIANO</strong> = Parallel Information Aggregation via Neural Orchestration<br>（通过神经编排的并行信息聚合）</p>
<p><strong>两大设计原则</strong>:</p>
<table>
<thead>
<tr>
<th>原则</th>
<th>问题</th>
<th>解决方案</th>
</tr>
</thead>
<tbody><tr>
<td><strong>并发性</strong></td>
<td>慢速思考不应阻止快速反应</td>
<td>多模块并行运行，不同时间尺度</td>
</tr>
<tr>
<td><strong>一致性</strong></td>
<td>多输出模块可能产生冲突</td>
<td>认知控制器(CC)作为瓶颈</td>
</tr>
</tbody></table>
<p><strong>10个核心模块</strong>:</p>
<table>
<thead>
<tr>
<th>模块</th>
<th>功能</th>
</tr>
</thead>
<tbody><tr>
<td>记忆</td>
<td>存储/检索对话、动作、观察</td>
</tr>
<tr>
<td>动作意识</td>
<td>评估自身状态和性能</td>
</tr>
<tr>
<td>目标生成</td>
<td>基于经验创建新目标</td>
</tr>
<tr>
<td>社会意识</td>
<td>解释他人社会线索</td>
</tr>
<tr>
<td>说话</td>
<td>解释和生成语音</td>
</tr>
<tr>
<td>技能执行</td>
<td>执行环境中的动作</td>
</tr>
</tbody></table>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">┌─────────────────────────────────────────────────────────────┐</span><br><span class="line">│                    PIANO 架构                                │</span><br><span class="line">├─────────────────────────────────────────────────────────────┤</span><br><span class="line">│                                                             │</span><br><span class="line">│  并发模块:                    认知控制器(瓶颈):              │</span><br><span class="line">│  ┌─────────┐                 ┌───────────────┐             │</span><br><span class="line">│  │ 记忆    │──────────────▶ │               │             │</span><br><span class="line">│  ├─────────┤                │   信息综合    │             │</span><br><span class="line">│  │ 社会    │──────────────▶ │       ↓       │             │</span><br><span class="line">│  ├─────────┤                │   高层决策    │             │</span><br><span class="line">│  │ 目标    │──────────────▶ │       ↓       │             │</span><br><span class="line">│  ├─────────┤                │   决策广播    │             │</span><br><span class="line">│  │ 动作    │──────────────▶ │               │             │</span><br><span class="line">│  └─────────┘                └───────────────┘             │</span><br><span class="line">│       ↑                            │                       │</span><br><span class="line">│       │                            ▼                       │</span><br><span class="line">│       │                     ┌───────────────┐             │</span><br><span class="line">│       │                     │ 输出模块      │             │</span><br><span class="line">│       │                     │ 说话/动作/... │             │</span><br><span class="line">│       │                     └───────────────┘             │</span><br><span class="line">│       └─────────────────────────────┘                      │</span><br><span class="line">│                                                             │</span><br><span class="line">└─────────────────────────────────────────────────────────────┘</span><br></pre></td></tr></table></figure>

<h3 id="2-4-文明进步基准"><a href="#2-4-文明进步基准" class="headerlink" title="2.4 文明进步基准"></a>2.4 文明进步基准</h3><h4 id="基准1：专业化"><a href="#基准1：专业化" class="headerlink" title="基准1：专业化"></a>基准1：专业化</h4><p><strong>定义</strong>: 智能体自主发展专业角色</p>
<p><strong>三个标准</strong>:</p>
<ol>
<li>在选择和转换角色方面表现自主性</li>
<li>专业化通过互动涌现，无需明确指导</li>
<li>角色体现在与专业化一致的行为中</li>
</ol>
<p><strong>实验结果</strong> (30智能体，20分钟):</p>
<table>
<thead>
<tr>
<th>现象</th>
<th>发现</th>
</tr>
</thead>
<tbody><tr>
<td>角色多样性</td>
<td>农民、矿工、工程师、守卫、探险家、铁匠</td>
</tr>
<tr>
<td>角色持久性</td>
<td>每个智能体角色在时间上大体稳定</td>
</tr>
<tr>
<td>角色-行为一致性</td>
<td>艺术家专注采花，农民专注收集种子</td>
</tr>
</tbody></table>
<p><strong>武术社会 vs 艺术社会</strong>:</p>
<ul>
<li>武术社会特有角色：侦察兵、战略家</li>
<li>艺术社会特有角色：策展人、收藏家</li>
</ul>
<h4 id="基准2：集体规则"><a href="#基准2：集体规则" class="headerlink" title="基准2：集体规则"></a>基准2：集体规则</h4><p><strong>定义</strong>: 智能体遵守和改变法律</p>
<p><strong>实验设置</strong>:</p>
<ul>
<li>25个选民智能体</li>
<li>3个影响者（亲税/反税）</li>
<li>1个选举经理</li>
<li>税法：交20%物品到社区箱子</li>
</ul>
<p><strong>关键发现</strong>:</p>
<table>
<thead>
<tr>
<th>现象</th>
<th>结果</th>
</tr>
</thead>
<tbody><tr>
<td>遵守法律</td>
<td>平均交付~20%物品</td>
</tr>
<tr>
<td>影响者影响</td>
<td>亲税/反税影响者显著改变选民态度</td>
</tr>
<tr>
<td>宪法变更</td>
<td>税率从20%降到5-10%时，行为相应调整</td>
</tr>
</tbody></table>
<h4 id="基准3：文化传播"><a href="#基准3：文化传播" class="headerlink" title="基准3：文化传播"></a>基准3：文化传播</h4><p><strong>实验规模</strong>: 500智能体 (6城镇 + 农村)</p>
<p><strong>关键现象</strong>:</p>
<table>
<thead>
<tr>
<th>现象</th>
<th>发现</th>
</tr>
</thead>
<tbody><tr>
<td>模因多样性</td>
<td>不同城镇流行不同模因</td>
</tr>
<tr>
<td>模因动态</td>
<td>流行度随时间上升和下降</td>
</tr>
<tr>
<td>宗教传播</td>
<td>20个牧师传播”飞天面条神教”</td>
</tr>
<tr>
<td>皈依扩散</td>
<td>皈依者数量持续增加，未饱和</td>
</tr>
</tbody></table>
<h3 id="2-5-量化结果"><a href="#2-5-量化结果" class="headerlink" title="2.5 量化结果"></a>2.5 量化结果</h3><table>
<thead>
<tr>
<th>指标</th>
<th>结果</th>
</tr>
</thead>
<tbody><tr>
<td>30分钟内获取物品</td>
<td>平均17个独特物品</td>
</tr>
<tr>
<td>4小时物品饱和</td>
<td>~320个（1/3总物品）</td>
</tr>
<tr>
<td>社会感知准确性</td>
<td>r = 0.81（5+观察者）</td>
</tr>
<tr>
<td>最大规模</td>
<td>1000+ 智能体</td>
</tr>
</tbody></table>
<h3 id="2-6-局限性"><a href="#2-6-局限性" class="headerlink" title="2.6 局限性"></a>2.6 局限性</h3><ol>
<li><strong>缺乏视觉推理</strong>: 限制空间导航和建造能力</li>
<li><strong>缺乏内在驱动</strong>: 无生存、好奇心等催化社会发展</li>
<li><strong>无法从头涌现</strong>: 基于预训练知识，无法模拟创新涌现</li>
</ol>
<hr>
<h2 id="三、Agent-Hospital：可进化的医疗智能体"><a href="#三、Agent-Hospital：可进化的医疗智能体" class="headerlink" title="三、Agent Hospital：可进化的医疗智能体"></a>三、Agent Hospital：可进化的医疗智能体</h2><p><strong>论文</strong>: A Simulacrum of Hospital with Evolvable Medical Agents<br><strong>机构</strong>: 清华大学 AIR<br><strong>发布日期</strong>: 2024年5月</p>
<h3 id="3-1-核心创新"><a href="#3-1-核心创新" class="headerlink" title="3.1 核心创新"></a>3.1 核心创新</h3><p><strong>医生培养的两个阶段</strong>:</p>
<table>
<thead>
<tr>
<th>阶段</th>
<th>内容</th>
<th>时长</th>
</tr>
</thead>
<tbody><tr>
<td>阶段1</td>
<td>知识获取（学校）</td>
<td>~20年</td>
</tr>
<tr>
<td>阶段2</td>
<td>技能获取（医院）</td>
<td>~3年</td>
</tr>
</tbody></table>
<p>现有医疗AI主要集中在<strong>阶段1</strong>（如Med-PaLM）。Agent Hospital 解决<strong>阶段2</strong>：从实践中获取专业技能。</p>
<h3 id="3-2-系统架构"><a href="#3-2-系统架构" class="headerlink" title="3.2 系统架构"></a>3.2 系统架构</h3><p><strong>Agent Hospital</strong> = 虚拟医院，所有患者、护士、医生都是LLM驱动的智能体</p>
<p><strong>系统规模</strong>:</p>
<table>
<thead>
<tr>
<th>指标</th>
<th>数量</th>
</tr>
</thead>
<tbody><tr>
<td>科室</td>
<td>32个</td>
</tr>
<tr>
<td>覆盖疾病</td>
<td>339种</td>
</tr>
<tr>
<td>医生智能体</td>
<td>42个</td>
</tr>
<tr>
<td>护士智能体</td>
<td>4个</td>
</tr>
<tr>
<td>功能区域</td>
<td>16个</td>
</tr>
</tbody></table>
<h3 id="3-3-治疗闭环"><a href="#3-3-治疗闭环" class="headerlink" title="3.3 治疗闭环"></a>3.3 治疗闭环</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">┌─────────────────────────────────────────────────────────────┐</span><br><span class="line">│                    治疗闭环                                  │</span><br><span class="line">├─────────────────────────────────────────────────────────────┤</span><br><span class="line">│                                                             │</span><br><span class="line">│  1. 疾病发作 ──▶ 2. 分诊 ──▶ 3. 挂号                        │</span><br><span class="line">│        │                                                    │</span><br><span class="line">│        ▼                                                    │</span><br><span class="line">│  8. 康复反馈 ◀── 7. 取药 ◀── 6. 诊断                        │</span><br><span class="line">│        │                        ▲                           │</span><br><span class="line">│        │                        │                           │</span><br><span class="line">│        └─────▶ 4. 就诊 ──▶ 5. 检查 ─┘                       │</span><br><span class="line">│                                                             │</span><br><span class="line">│  额外事件：医生智能体在非工作时间阅读医学书籍                  │</span><br><span class="line">│                                                             │</span><br><span class="line">└─────────────────────────────────────────────────────────────┘</span><br></pre></td></tr></table></figure>

<h3 id="3-4-SEAL-框架"><a href="#3-4-SEAL-框架" class="headerlink" title="3.4 SEAL 框架"></a>3.4 SEAL 框架</h3><p><strong>SEAL</strong> = Simulacrum-based Evolutionary Agent Learning<br>（基于仿真的进化智能体学习）</p>
<p><strong>两个组件</strong>:</p>
<table>
<thead>
<tr>
<th>组件</th>
<th>功能</th>
</tr>
</thead>
<tbody><tr>
<td><strong>仿真系统构建</strong></td>
<td>构建虚拟世界，自动生成数据</td>
</tr>
<tr>
<td><strong>智能体进化</strong></td>
<td>从成功/失败中学习</td>
</tr>
</tbody></table>
<h3 id="3-5-MedAgent-Zero-进化机制"><a href="#3-5-MedAgent-Zero-进化机制" class="headerlink" title="3.5 MedAgent-Zero 进化机制"></a>3.5 MedAgent-Zero 进化机制</h3><p><strong>“Zero”含义</strong>: 不使用任何人工标注数据</p>
<p><strong>学习来源</strong>:</p>
<table>
<thead>
<tr>
<th>来源</th>
<th>内容</th>
<th>作用</th>
</tr>
</thead>
<tbody><tr>
<td><strong>成功案例</strong></td>
<td>正确的诊断和治疗</td>
<td>作为参考案例检索</td>
</tr>
<tr>
<td><strong>失败案例</strong></td>
<td>错误的诊断或治疗</td>
<td>反思避免重复错误</td>
</tr>
<tr>
<td><strong>医学教材</strong></td>
<td>专业医学知识</td>
<td>巩固和整合知识</td>
</tr>
</tbody></table>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">┌─────────────────────────────────────────────────────────────┐</span><br><span class="line">│              MedAgent-Zero 进化流程                          │</span><br><span class="line">├─────────────────────────────────────────────────────────────┤</span><br><span class="line">│                                                             │</span><br><span class="line">│  1. 治疗患者智能体                                           │</span><br><span class="line">│     ↓                                                       │</span><br><span class="line">│  2. 收到患者反馈（康复/未康复）                               │</span><br><span class="line">│     ↓                                                       │</span><br><span class="line">│  ┌─────────────────┬─────────────────┐                     │</span><br><span class="line">│  │   成功案例      │    失败案例      │                     │</span><br><span class="line">│  │                 │                 │                     │</span><br><span class="line">│  │  存储为参考案例  │  反思获取经验    │                     │</span><br><span class="line">│  │  用于未来检索   │  避免重复错误    │                     │</span><br><span class="line">│  └─────────────────┴─────────────────┘                     │</span><br><span class="line">│     ↓                                                       │</span><br><span class="line">│  3. 阅读医学教材巩固知识                                     │</span><br><span class="line">│     ↓                                                       │</span><br><span class="line">│  4. 能力持续提升                                             │</span><br><span class="line">│                                                             │</span><br><span class="line">└─────────────────────────────────────────────────────────────┘</span><br></pre></td></tr></table></figure>

<h3 id="3-6-实验结果"><a href="#3-6-实验结果" class="headerlink" title="3.6 实验结果"></a>3.6 实验结果</h3><p><strong>进化效果</strong> (诊断准确率):</p>
<table>
<thead>
<tr>
<th>治疗患者数</th>
<th>准确率</th>
<th>提升</th>
</tr>
</thead>
<tbody><tr>
<td>0 (初始)</td>
<td>~60%</td>
<td>-</td>
</tr>
<tr>
<td>1,000</td>
<td>~72%</td>
<td>+20%</td>
</tr>
<tr>
<td>10,000</td>
<td>~85%</td>
<td>+42%</td>
</tr>
<tr>
<td>50,000</td>
<td>~93%</td>
<td><strong>+55%</strong></td>
</tr>
</tbody></table>
<p><strong>MedQA 基准测试</strong> (美国医师执照考试):</p>
<table>
<thead>
<tr>
<th>方法</th>
<th>准确率</th>
</tr>
</thead>
<tbody><tr>
<td>GPT-4 (少样本)</td>
<td>78.4%</td>
</tr>
<tr>
<td>Med-PaLM 2</td>
<td>86.5%</td>
</tr>
<tr>
<td><strong>Agent Hospital (进化后)</strong></td>
<td><strong>88.7%</strong></td>
</tr>
</tbody></table>
<p><strong>亮点</strong>: 无需使用基准的标注训练数据！</p>
<h3 id="3-7-与-Generative-Agents-的关系"><a href="#3-7-与-Generative-Agents-的关系" class="headerlink" title="3.7 与 Generative Agents 的关系"></a>3.7 与 Generative Agents 的关系</h3><table>
<thead>
<tr>
<th>维度</th>
<th>Generative Agents</th>
<th>Agent Hospital</th>
</tr>
</thead>
<tbody><tr>
<td>灵感来源</td>
<td>原创</td>
<td>受GA启发</td>
</tr>
<tr>
<td>环境</td>
<td>虚拟小镇</td>
<td>虚拟医院</td>
</tr>
<tr>
<td>智能体数量</td>
<td>25个</td>
<td>46+</td>
</tr>
<tr>
<td>任务类型</td>
<td>社交模拟</td>
<td><strong>医疗诊断</strong></td>
</tr>
<tr>
<td>能力进化</td>
<td>无</td>
<td><strong>有(核心创新)</strong></td>
</tr>
<tr>
<td>评估方式</td>
<td>定性</td>
<td>定量(MedQA)</td>
</tr>
</tbody></table>
<h3 id="3-8-SEAL-的通用性"><a href="#3-8-SEAL-的通用性" class="headerlink" title="3.8 SEAL 的通用性"></a>3.8 SEAL 的通用性</h3><p><strong>方法论公式</strong>:</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">领域工作流程 → 构建仿真系统 → 自动生成数据 → 智能体进化</span><br></pre></td></tr></table></figure>

<p><strong>优势</strong>:</p>
<table>
<thead>
<tr>
<th>优势</th>
<th>说明</th>
</tr>
</thead>
<tbody><tr>
<td>无需人工标注</td>
<td>数据由虚拟世界自动生成</td>
</tr>
<tr>
<td>领域适应</td>
<td>直接适应特定应用需求</td>
</tr>
<tr>
<td>成本低</td>
<td>减少数据标注开销</td>
</tr>
<tr>
<td>可扩展</td>
<td>可模拟大量场景和时间</td>
</tr>
</tbody></table>
<p><strong>潜在应用</strong>: 法律咨询、金融投资、教育培训、客户服务</p>
<hr>
<h2 id="四、三大应用扩展对比"><a href="#四、三大应用扩展对比" class="headerlink" title="四、三大应用扩展对比"></a>四、三大应用扩展对比</h2><h3 id="4-1-核心差异"><a href="#4-1-核心差异" class="headerlink" title="4.1 核心差异"></a>4.1 核心差异</h3><table>
<thead>
<tr>
<th>维度</th>
<th>VOYAGER</th>
<th>Project Sid</th>
<th>Agent Hospital</th>
</tr>
</thead>
<tbody><tr>
<td><strong>核心目标</strong></td>
<td>终身学习技能</td>
<td>AI文明模拟</td>
<td>医疗智能体进化</td>
</tr>
<tr>
<td><strong>环境</strong></td>
<td>Minecraft</td>
<td>Minecraft</td>
<td>虚拟医院</td>
</tr>
<tr>
<td><strong>智能体数量</strong></td>
<td>1</td>
<td>10-1000+</td>
<td>46+</td>
</tr>
<tr>
<td><strong>时间跨度</strong></td>
<td>数小时</td>
<td>4小时+</td>
<td>持续</td>
</tr>
<tr>
<td><strong>学习机制</strong></td>
<td>技能库积累</td>
<td>社会互动</td>
<td>经验反思</td>
</tr>
</tbody></table>
<h3 id="4-2-创新贡献"><a href="#4-2-创新贡献" class="headerlink" title="4.2 创新贡献"></a>4.2 创新贡献</h3><table>
<thead>
<tr>
<th>论文</th>
<th>核心创新</th>
</tr>
</thead>
<tbody><tr>
<td><strong>VOYAGER</strong></td>
<td>代码即记忆，技能可组合复用</td>
</tr>
<tr>
<td><strong>Project Sid</strong></td>
<td>文明进步基准：专业化、规则、文化</td>
</tr>
<tr>
<td><strong>Agent Hospital</strong></td>
<td>智能体能力可进化，虚拟技能迁移现实</td>
</tr>
</tbody></table>
<h3 id="4-3-适用场景"><a href="#4-3-适用场景" class="headerlink" title="4.3 适用场景"></a>4.3 适用场景</h3><table>
<thead>
<tr>
<th>场景</th>
<th>推荐方法</th>
<th>原因</th>
</tr>
</thead>
<tbody><tr>
<td>开放世界游戏</td>
<td>VOYAGER</td>
<td>技能积累和终身学习</td>
</tr>
<tr>
<td>社会科学研究</td>
<td>Project Sid</td>
<td>大规模社会动态模拟</td>
</tr>
<tr>
<td>专业领域AI</td>
<td>Agent Hospital</td>
<td>从实践中持续进化</td>
</tr>
<tr>
<td>多智能体协作</td>
<td>Project Sid</td>
<td>PIANO架构支持一致性</td>
</tr>
</tbody></table>
<hr>
<h2 id="五、技术演进路线"><a href="#五、技术演进路线" class="headerlink" title="五、技术演进路线"></a>五、技术演进路线</h2><h3 id="5-1-从基础到应用"><a href="#5-1-从基础到应用" class="headerlink" title="5.1 从基础到应用"></a>5.1 从基础到应用</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">基础框架 (2022-2023):</span><br><span class="line">├── ReAct: 推理+行动</span><br><span class="line">├── Reflexion: 语言反馈学习</span><br><span class="line">└── Generative Agents: 记忆+反思</span><br><span class="line"></span><br><span class="line">应用扩展 (2023-2024):</span><br><span class="line">├── VOYAGER: 终身学习 + 技能库</span><br><span class="line">├── Project Sid: 大规模文明模拟</span><br><span class="line">└── Agent Hospital: 专业领域进化</span><br><span class="line"></span><br><span class="line">未来趋势 (2025+):</span><br><span class="line">├── Agent OS化: AutoGen, LangGraph</span><br><span class="line">├── 多模态融合: 视觉+语言+行动</span><br><span class="line">└── 商业化部署: Operator, Claude</span><br></pre></td></tr></table></figure>

<h3 id="5-2-规模演进"><a href="#5-2-规模演进" class="headerlink" title="5.2 规模演进"></a>5.2 规模演进</h3><table>
<thead>
<tr>
<th>时间</th>
<th>论文</th>
<th>智能体数量</th>
<th>涌现现象</th>
</tr>
</thead>
<tbody><tr>
<td>2023/04</td>
<td>Generative Agents</td>
<td>25</td>
<td>社交行为</td>
</tr>
<tr>
<td>2023/05</td>
<td>VOYAGER</td>
<td>1</td>
<td>终身学习</td>
</tr>
<tr>
<td>2024/05</td>
<td>Agent Hospital</td>
<td>46+</td>
<td>能力进化</td>
</tr>
<tr>
<td>2024/10</td>
<td>Project Sid</td>
<td>500-1000+</td>
<td>文明进步</td>
</tr>
</tbody></table>
<h3 id="5-3-关键技术突破"><a href="#5-3-关键技术突破" class="headerlink" title="5.3 关键技术突破"></a>5.3 关键技术突破</h3><table>
<thead>
<tr>
<th>突破</th>
<th>论文</th>
<th>意义</th>
</tr>
</thead>
<tbody><tr>
<td>代码作为记忆</td>
<td>VOYAGER</td>
<td>可执行、可组合的知识表示</td>
</tr>
<tr>
<td>文明进步基准</td>
<td>Project Sid</td>
<td>量化多智能体社会能力</td>
</tr>
<tr>
<td>无标注进化</td>
<td>Agent Hospital</td>
<td>从实践中自动学习</td>
</tr>
<tr>
<td>千智能体规模</td>
<td>Project Sid</td>
<td>验证大规模可行性</td>
</tr>
</tbody></table>
<hr>
<h2 id="六、实践建议"><a href="#六、实践建议" class="headerlink" title="六、实践建议"></a>六、实践建议</h2><h3 id="6-1-技术选型"><a href="#6-1-技术选型" class="headerlink" title="6.1 技术选型"></a>6.1 技术选型</h3><table>
<thead>
<tr>
<th>需求</th>
<th>推荐技术栈</th>
</tr>
</thead>
<tbody><tr>
<td>单智能体技能学习</td>
<td>VOYAGER (技能库 + 迭代提示)</td>
</tr>
<tr>
<td>多智能体协作</td>
<td>Project Sid (PIANO架构)</td>
</tr>
<tr>
<td>专业领域应用</td>
<td>Agent Hospital (SEAL框架)</td>
</tr>
<tr>
<td>通用任务完成</td>
<td>ReAct + Reflexion</td>
</tr>
</tbody></table>
<h3 id="6-2-架构设计"><a href="#6-2-架构设计" class="headerlink" title="6.2 架构设计"></a>6.2 架构设计</h3><p><strong>理想组合</strong>:</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">理想智能体 = VOYAGER的技能库</span><br><span class="line">           + Project Sid的社会意识</span><br><span class="line">           + Agent Hospital的进化机制</span><br><span class="line">           + Generative Agents的记忆系统</span><br></pre></td></tr></table></figure>

<h3 id="6-3-规模化考虑"><a href="#6-3-规模化考虑" class="headerlink" title="6.3 规模化考虑"></a>6.3 规模化考虑</h3><table>
<thead>
<tr>
<th>规模</th>
<th>关键挑战</th>
<th>解决方案</th>
</tr>
</thead>
<tbody><tr>
<td>1-10</td>
<td>单智能体能力</td>
<td>技能库 + 反思</td>
</tr>
<tr>
<td>10-50</td>
<td>协调一致性</td>
<td>PIANO架构</td>
</tr>
<tr>
<td>50-500</td>
<td>计算资源</td>
<td>并行模块</td>
</tr>
<tr>
<td>500+</td>
<td>涌现管理</td>
<td>文明基准</td>
</tr>
</tbody></table>
<hr>
<h2 id="七、关键论文原文引用"><a href="#七、关键论文原文引用" class="headerlink" title="七、关键论文原文引用"></a>七、关键论文原文引用</h2><h3 id="VOYAGER"><a href="#VOYAGER" class="headerlink" title="VOYAGER"></a>VOYAGER</h3><blockquote>
<p>“VOYAGER is the first LLM-powered embodied lifelong learning agent that explores the world, acquires diverse skills, and makes novel discoveries without human intervention.”</p>
</blockquote>
<h3 id="Project-Sid"><a href="#Project-Sid" class="headerlink" title="Project Sid"></a>Project Sid</h3><blockquote>
<p>“We show how 10-1000+ AI agents behave and progress in agent societies. These simulations reveal that agents can achieve meaningful progress—autonomously developing specialized roles, adhering to and modifying collective rules, and engaging in cultural and religious propagation.”</p>
</blockquote>
<h3 id="Agent-Hospital"><a href="#Agent-Hospital" class="headerlink" title="Agent Hospital"></a>Agent Hospital</h3><blockquote>
<p>“Doctor agents can evolve by treating a large number of patient agents, without the need for manually curated training data. After treating tens of thousands of patient agents (which may take several years for real-world doctors), the evolved doctor agents surpassed state-of-the-art medical AI methods on the MedQA benchmark.”</p>
</blockquote>
<hr>
<p><a href="/2025/12/28/LLM-Game-Agents-%E8%AE%BA%E6%96%87%E8%A7%A3%E8%AF%BB-%E6%80%BB%E8%A7%88/">返回总览</a> | <a href="/2025/12/28/LLM-Game-Agents-%E5%9F%BA%E7%A1%80%E6%A1%86%E6%9E%B6%E7%AF%87/">上一篇：基础框架篇</a></p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://foosynaptic.github.io/2025/12/28/LLM-Game-Agents-%E5%9F%BA%E7%A1%80%E6%A1%86%E6%9E%B6%E7%AF%87/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="fooSynaptic">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="fooSynaptic">
      <meta itemprop="description" content="Head first to the Truth as Synaptic.">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content=" | fooSynaptic">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2025/12/28/LLM-Game-Agents-%E5%9F%BA%E7%A1%80%E6%A1%86%E6%9E%B6%E7%AF%87/" class="post-title-link" itemprop="url">LLM 游戏智能体论文解读：基础框架篇</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2025-12-28 04:01:00" itemprop="dateCreated datePublished" datetime="2025-12-28T04:01:00+08:00">2025-12-28</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E8%AE%BA%E6%96%87%E8%A7%A3%E8%AF%BB/" itemprop="url" rel="index"><span itemprop="name">论文解读</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <p>本文深入解读 LLM 智能体领域的三大基础框架：ReAct、Reflexion 和 Generative Agents，分析它们的核心架构、技术创新和应用场景。</p>
<hr>
<h2 id="一、ReAct：推理与行动的协同"><a href="#一、ReAct：推理与行动的协同" class="headerlink" title="一、ReAct：推理与行动的协同"></a>一、ReAct：推理与行动的协同</h2><p><strong>论文</strong>: Synergizing Reasoning and Acting in Language Models<br><strong>会议</strong>: ICLR 2023<br><strong>作者</strong>: Shunyu Yao 等 (普林斯顿大学 &amp; Google Research)<br><strong>被引用</strong>: 32次（领域内最高）</p>
<h3 id="1-1-核心思想"><a href="#1-1-核心思想" class="headerlink" title="1.1 核心思想"></a>1.1 核心思想</h3><p>人类智能的一个独特特征是能够<strong>无缝结合面向任务的动作与语言推理</strong>。考虑在厨房做菜的例子：</p>
<ul>
<li>在任何两个具体动作之间，我们可能用语言进行推理，以跟踪进度</li>
<li>处理异常或根据情况调整计划</li>
<li>认识到何时需要外部信息</li>
</ul>
<p>ReAct 的核心理念：<strong>将智能体的动作空间扩展为 Â = A ∪ L</strong></p>
<p>其中：</p>
<ul>
<li><strong>A</strong> = 原始动作空间（与环境交互）</li>
<li><strong>L</strong> = 语言空间（思想/推理轨迹）</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">┌─────────────────────────────────────────────────────────────┐</span><br><span class="line">│                    ReAct 工作流程                            │</span><br><span class="line">├─────────────────────────────────────────────────────────────┤</span><br><span class="line">│                                                             │</span><br><span class="line">│   问题 ──▶ 思想1 ──▶ 动作1 ──▶ 观察1                        │</span><br><span class="line">│                       │                                     │</span><br><span class="line">│                       ▼                                     │</span><br><span class="line">│            思想2 ──▶ 动作2 ──▶ 观察2                        │</span><br><span class="line">│                       │                                     │</span><br><span class="line">│                       ▼                                     │</span><br><span class="line">│            思想3 ──▶ 动作3 ──▶ 答案                         │</span><br><span class="line">│                                                             │</span><br><span class="line">│   思想：不影响环境，用于推理和规划                           │</span><br><span class="line">│   动作：与环境交互，获取新信息                               │</span><br><span class="line">│   观察：环境反馈                                             │</span><br><span class="line">│                                                             │</span><br><span class="line">└─────────────────────────────────────────────────────────────┘</span><br></pre></td></tr></table></figure>

<h3 id="1-2-推理轨迹类型"><a href="#1-2-推理轨迹类型" class="headerlink" title="1.2 推理轨迹类型"></a>1.2 推理轨迹类型</h3><table>
<thead>
<tr>
<th>类型</th>
<th>示例</th>
</tr>
</thead>
<tbody><tr>
<td>问题分解</td>
<td>“我需要搜索x，找到y，然后找到z”</td>
</tr>
<tr>
<td>信息提取</td>
<td>“x于1844年创立”</td>
</tr>
<tr>
<td>常识推理</td>
<td>“1844 &lt; 1989，所以x更老”</td>
</tr>
<tr>
<td>搜索重构</td>
<td>“也许我可以搜索/查找x来代替”</td>
</tr>
<tr>
<td>答案综合</td>
<td>“…所以答案是x”</td>
</tr>
</tbody></table>
<h3 id="1-3-实验结果"><a href="#1-3-实验结果" class="headerlink" title="1.3 实验结果"></a>1.3 实验结果</h3><p><strong>知识密集型任务 (HotpotQA, Fever)</strong>:</p>
<table>
<thead>
<tr>
<th>方法</th>
<th>HotpotQA EM</th>
<th>Fever Acc</th>
</tr>
</thead>
<tbody><tr>
<td>CoT</td>
<td>29.4</td>
<td>56.3</td>
</tr>
<tr>
<td>Act</td>
<td>25.7</td>
<td>58.9</td>
</tr>
<tr>
<td><strong>ReAct</strong></td>
<td><strong>27.4</strong></td>
<td><strong>60.9</strong></td>
</tr>
<tr>
<td>ReAct + CoT-SC</td>
<td><strong>35.1</strong></td>
<td><strong>64.6</strong></td>
</tr>
</tbody></table>
<p><strong>决策任务 (ALFWorld, WebShop)</strong>:</p>
<table>
<thead>
<tr>
<th>方法</th>
<th>ALFWorld</th>
<th>WebShop</th>
</tr>
</thead>
<tbody><tr>
<td>BUTLER (模仿学习)</td>
<td>37%</td>
<td>-</td>
</tr>
<tr>
<td>Act</td>
<td>45%</td>
<td>-</td>
</tr>
<tr>
<td><strong>ReAct</strong></td>
<td><strong>71%</strong></td>
<td><strong>+10%</strong></td>
</tr>
</tbody></table>
<h3 id="1-4-成功与失败模式"><a href="#1-4-成功与失败模式" class="headerlink" title="1.4 成功与失败模式"></a>1.4 成功与失败模式</h3><table>
<thead>
<tr>
<th>类型</th>
<th>ReAct</th>
<th>CoT</th>
</tr>
</thead>
<tbody><tr>
<td><strong>成功-真阳性</strong></td>
<td>94%</td>
<td>86%</td>
</tr>
<tr>
<td><strong>成功-假阳性</strong></td>
<td>6%</td>
<td>14%</td>
</tr>
<tr>
<td><strong>失败-幻觉</strong></td>
<td><strong>0%</strong></td>
<td><strong>56%</strong></td>
</tr>
<tr>
<td><strong>失败-推理错误</strong></td>
<td>47%</td>
<td>16%</td>
</tr>
</tbody></table>
<p><strong>关键洞见</strong>：</p>
<ul>
<li>ReAct 的<strong>幻觉率为0%</strong>，因为可以与外部知识库交互验证</li>
<li>CoT 的主要失败模式是幻觉（56%）</li>
<li>ReAct 的主要失败是推理错误（47%），因结构约束降低了灵活性</li>
</ul>
<h3 id="1-5-ReAct-示例"><a href="#1-5-ReAct-示例" class="headerlink" title="1.5 ReAct 示例"></a>1.5 ReAct 示例</h3><p><strong>问题</strong>: 除了Apple Remote，还有什么设备可以控制Apple Remote最初设计交互的程序？</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">思想1: 我需要搜索Apple Remote，找到它最初设计交互的程序</span><br><span class="line">动作1: Search[Apple Remote]</span><br><span class="line">观察1: Apple Remote是一个遥控器...最初设计用于控制Front Row...</span><br><span class="line"></span><br><span class="line">思想2: Apple Remote最初设计控制Front Row。我需要搜索Front Row</span><br><span class="line">动作2: Search[Front Row software]</span><br><span class="line">观察2: Front Row是一个已停产的媒体中心软件...由Apple Remote或键盘功能键控制</span><br><span class="line"></span><br><span class="line">思想3: Front Row由Apple Remote或键盘功能键控制。所以答案是键盘功能键</span><br><span class="line">动作3: Finish[keyboard function keys]</span><br></pre></td></tr></table></figure>

<hr>
<h2 id="二、Reflexion：语言反馈强化学习"><a href="#二、Reflexion：语言反馈强化学习" class="headerlink" title="二、Reflexion：语言反馈强化学习"></a>二、Reflexion：语言反馈强化学习</h2><p><strong>论文</strong>: Language Agents with Verbal Reinforcement Learning<br><strong>会议</strong>: NeurIPS 2023<br><strong>作者</strong>: Noah Shinn 等 (Northeastern &amp; Princeton)<br><strong>被引用</strong>: 17次</p>
<h3 id="2-1-核心思想"><a href="#2-1-核心思想" class="headerlink" title="2.1 核心思想"></a>2.1 核心思想</h3><p>传统强化学习通过梯度更新权重学习，需要大量样本和昂贵的微调。Reflexion 提出用<strong>语言反馈</strong>替代梯度信号：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">┌─────────────────────────────────────────────────────────────┐</span><br><span class="line">│              传统RL vs Reflexion                             │</span><br><span class="line">├─────────────────────────────────────────────────────────────┤</span><br><span class="line">│                                                             │</span><br><span class="line">│   传统RL:                                                   │</span><br><span class="line">│   状态 ──▶ 动作 ──▶ 奖励 ──▶ 梯度更新 ──▶ 参数变化          │</span><br><span class="line">│                                                             │</span><br><span class="line">│   Reflexion:                                                │</span><br><span class="line">│   状态 ──▶ 动作 ──▶ 反馈 ──▶ 语言反思 ──▶ 记忆存储          │</span><br><span class="line">│                       │                                     │</span><br><span class="line">│                       └──────────────────▶ 下次尝试         │</span><br><span class="line">│                                                             │</span><br><span class="line">└─────────────────────────────────────────────────────────────┘</span><br></pre></td></tr></table></figure>

<h3 id="2-2-三大核心组件"><a href="#2-2-三大核心组件" class="headerlink" title="2.2 三大核心组件"></a>2.2 三大核心组件</h3><h4 id="Actor（执行者）"><a href="#Actor（执行者）" class="headerlink" title="Actor（执行者）"></a>Actor（执行者）</h4><p>基于 LLM 构建，生成文本和动作。可以是：</p>
<ul>
<li>Chain of Thought (CoT)</li>
<li>ReAct</li>
<li>其他智能体架构</li>
</ul>
<h4 id="Evaluator（评估者）"><a href="#Evaluator（评估者）" class="headerlink" title="Evaluator（评估者）"></a>Evaluator（评估者）</h4><p>评估 Actor 生成输出的质量：</p>
<ul>
<li><strong>精确匹配(EM)评分</strong>: 推理任务</li>
<li><strong>预定义启发式</strong>: 决策任务</li>
<li><strong>LLM作为评估者</strong>: 编程任务</li>
</ul>
<h4 id="Self-Reflection（自我反思）"><a href="#Self-Reflection（自我反思）" class="headerlink" title="Self-Reflection（自我反思）"></a>Self-Reflection（自我反思）</h4><p>核心创新：将稀疏奖励信号转化为<strong>详细的语言化反思</strong></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">输入: </span><br><span class="line">  - 任务描述</span><br><span class="line">  - 失败轨迹: [动作1, 观察1, 动作2, 观察2, ...]</span><br><span class="line">  - 奖励信号: 二元或标量</span><br><span class="line">  - 历史反思</span><br><span class="line"></span><br><span class="line">输出:</span><br><span class="line">  - 错误诊断</span><br><span class="line">  - 改进方案</span><br><span class="line">  - 具体建议</span><br></pre></td></tr></table></figure>

<h3 id="2-3-记忆机制"><a href="#2-3-记忆机制" class="headerlink" title="2.3 记忆机制"></a>2.3 记忆机制</h3><table>
<thead>
<tr>
<th>类型</th>
<th>内容</th>
<th>作用</th>
</tr>
</thead>
<tbody><tr>
<td><strong>短期记忆</strong></td>
<td>当前轨迹历史</td>
<td>即时决策</td>
</tr>
<tr>
<td><strong>长期记忆</strong></td>
<td>自我反思输出（滑动窗口）</td>
<td>跨尝试学习</td>
</tr>
</tbody></table>
<h3 id="2-4-实验结果"><a href="#2-4-实验结果" class="headerlink" title="2.4 实验结果"></a>2.4 实验结果</h3><p><strong>AlfWorld 决策任务</strong>:</p>
<table>
<thead>
<tr>
<th>方法</th>
<th>成功率</th>
</tr>
</thead>
<tbody><tr>
<td>ReAct</td>
<td>~50%</td>
</tr>
<tr>
<td>ReAct + Reflexion (启发式)</td>
<td><strong>97%</strong> (130/134)</td>
</tr>
<tr>
<td>ReAct + Reflexion (GPT)</td>
<td>88%</td>
</tr>
</tbody></table>
<p><strong>HotPotQA 推理任务</strong>:</p>
<table>
<thead>
<tr>
<th>方法</th>
<th>准确率提升</th>
</tr>
</thead>
<tbody><tr>
<td>CoT (GT)</td>
<td>基准</td>
</tr>
<tr>
<td>+ 情景记忆</td>
<td>+6%</td>
</tr>
<tr>
<td>+ <strong>Reflexion</strong></td>
<td><strong>+14%</strong></td>
</tr>
</tbody></table>
<p><strong>编程任务 (HumanEval)</strong>:</p>
<table>
<thead>
<tr>
<th>基准</th>
<th>先前SOTA</th>
<th>GPT-4</th>
<th><strong>Reflexion</strong></th>
</tr>
</thead>
<tbody><tr>
<td>HumanEval (PY)</td>
<td>65.8%</td>
<td>80.1%</td>
<td><strong>91.0%</strong></td>
</tr>
<tr>
<td>HumanEval (RS)</td>
<td>-</td>
<td>60.0%</td>
<td><strong>68.0%</strong></td>
</tr>
<tr>
<td>Leetcode Hard</td>
<td>-</td>
<td>7.5%</td>
<td><strong>15.0%</strong></td>
</tr>
</tbody></table>
<h3 id="2-5-Reflexion-示例"><a href="#2-5-Reflexion-示例" class="headerlink" title="2.5 Reflexion 示例"></a>2.5 Reflexion 示例</h3><p><strong>任务</strong>: 用台灯检查杯子</p>
<p><strong>第一次尝试（失败）</strong>:</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">&gt; go to drawer 1</span><br><span class="line">抽屉1是关着的</span><br><span class="line">&gt; ... (搜索杯子)</span><br><span class="line">&gt; take mug 1 from desk 1</span><br><span class="line">你从桌子1拿起杯子1</span><br><span class="line">&gt; use desklamp 1</span><br><span class="line">什么都没发生</span><br><span class="line">状态: 失败</span><br></pre></td></tr></table></figure>

<p><strong>反思</strong>:</p>
<blockquote>
<p>在这个环境中，我的计划是先找杯子再找台灯并使用。然而，任务说的是用台灯检查杯子。我应该先找台灯，再找杯子。我注意到台灯在桌子1上。下一次尝试中，我会先去桌子1，找到台灯，然后找杯子并用台灯检查它。</p>
</blockquote>
<p><strong>第二次尝试（成功）</strong>:</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">&gt; go to desk 1</span><br><span class="line">桌子1上有：台灯1、杯子1...</span><br><span class="line">&gt; take mug 1 from desk 1</span><br><span class="line">你从桌子1拿起杯子1</span><br><span class="line">&gt; use desklamp 1</span><br><span class="line">你打开了台灯1</span><br><span class="line">状态: 成功</span><br></pre></td></tr></table></figure>

<hr>
<h2 id="三、Generative-Agents：人类行为的交互式拟像"><a href="#三、Generative-Agents：人类行为的交互式拟像" class="headerlink" title="三、Generative Agents：人类行为的交互式拟像"></a>三、Generative Agents：人类行为的交互式拟像</h2><p><strong>论文</strong>: Interactive Simulacra of Human Behavior<br><strong>会议</strong>: UIST 2023<br><strong>作者</strong>: Joon Sung Park 等 (斯坦福大学 &amp; Google)<br><strong>被引用</strong>: 20次</p>
<h3 id="3-1-核心思想"><a href="#3-1-核心思想" class="headerlink" title="3.1 核心思想"></a>3.1 核心思想</h3><p>构建模拟可信人类行为的计算软件智能体：</p>
<ul>
<li>醒来、做早餐、去上班</li>
<li>艺术家画画，作者写作</li>
<li>形成观点，注意彼此，主动发起对话</li>
<li>回忆和反思过去，规划未来</li>
</ul>
<h3 id="3-2-核心架构"><a href="#3-2-核心架构" class="headerlink" title="3.2 核心架构"></a>3.2 核心架构</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">┌──────────────────────────────────────────────────────────────────┐</span><br><span class="line">│                        记忆流 (Memory Stream)                     │</span><br><span class="line">│  ┌─────────────┐  ┌─────────────┐  ┌─────────────────────────┐   │</span><br><span class="line">│  │   观察      │  │   反思      │  │        计划             │   │</span><br><span class="line">│  │ Observations│  │ Reflections │  │       Plans             │   │</span><br><span class="line">│  └─────────────┘  └─────────────┘  └─────────────────────────┘   │</span><br><span class="line">└──────────────────────────────────────────────────────────────────┘</span><br><span class="line">                                   │</span><br><span class="line">                                   ▼</span><br><span class="line">                    ┌─────────────────────────────────────┐</span><br><span class="line">                    │           记忆检索                  │</span><br><span class="line">                    │    (时近性 + 重要性 + 相关性)        │</span><br><span class="line">                    └──────────────┬──────────────────────┘</span><br><span class="line">                                   │</span><br><span class="line">                                   ▼</span><br><span class="line">                    ┌─────────────────────────────────────┐</span><br><span class="line">                    │           行为生成                  │</span><br><span class="line">                    │     (Plan, React, Dialogue)        │</span><br><span class="line">                    └─────────────────────────────────────┘</span><br></pre></td></tr></table></figure>

<h3 id="3-3-记忆检索公式"><a href="#3-3-记忆检索公式" class="headerlink" title="3.3 记忆检索公式"></a>3.3 记忆检索公式</h3><p><mjx-container class="MathJax" jax="SVG" display="true"><svg style="vertical-align: -0.667ex;" xmlns="http://www.w3.org/2000/svg" width="72.174ex" height="2.237ex" role="img" focusable="false" viewBox="0 -694 31901 989"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D460" d="M131 289Q131 321 147 354T203 415T300 442Q362 442 390 415T419 355Q419 323 402 308T364 292Q351 292 340 300T328 326Q328 342 337 354T354 372T367 378Q368 378 368 379Q368 382 361 388T336 399T297 405Q249 405 227 379T204 326Q204 301 223 291T278 274T330 259Q396 230 396 163Q396 135 385 107T352 51T289 7T195 -10Q118 -10 86 19T53 87Q53 126 74 143T118 160Q133 160 146 151T160 120Q160 94 142 76T111 58Q109 57 108 57T107 55Q108 52 115 47T146 34T201 27Q237 27 263 38T301 66T318 97T323 122Q323 150 302 164T254 181T195 196T148 231Q131 256 131 289Z"></path></g><g data-mml-node="mi" transform="translate(469,0)"><path data-c="1D450" d="M34 159Q34 268 120 355T306 442Q362 442 394 418T427 355Q427 326 408 306T360 285Q341 285 330 295T319 325T330 359T352 380T366 386H367Q367 388 361 392T340 400T306 404Q276 404 249 390Q228 381 206 359Q162 315 142 235T121 119Q121 73 147 50Q169 26 205 26H209Q321 26 394 111Q403 121 406 121Q410 121 419 112T429 98T420 83T391 55T346 25T282 0T202 -11Q127 -11 81 37T34 159Z"></path></g><g data-mml-node="mi" transform="translate(902,0)"><path data-c="1D45C" d="M201 -11Q126 -11 80 38T34 156Q34 221 64 279T146 380Q222 441 301 441Q333 441 341 440Q354 437 367 433T402 417T438 387T464 338T476 268Q476 161 390 75T201 -11ZM121 120Q121 70 147 48T206 26Q250 26 289 58T351 142Q360 163 374 216T388 308Q388 352 370 375Q346 405 306 405Q243 405 195 347Q158 303 140 230T121 120Z"></path></g><g data-mml-node="mi" transform="translate(1387,0)"><path data-c="1D45F" d="M21 287Q22 290 23 295T28 317T38 348T53 381T73 411T99 433T132 442Q161 442 183 430T214 408T225 388Q227 382 228 382T236 389Q284 441 347 441H350Q398 441 422 400Q430 381 430 363Q430 333 417 315T391 292T366 288Q346 288 334 299T322 328Q322 376 378 392Q356 405 342 405Q286 405 239 331Q229 315 224 298T190 165Q156 25 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 114 189T154 366Q154 405 128 405Q107 405 92 377T68 316T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(1838,0)"><path data-c="1D452" d="M39 168Q39 225 58 272T107 350T174 402T244 433T307 442H310Q355 442 388 420T421 355Q421 265 310 237Q261 224 176 223Q139 223 138 221Q138 219 132 186T125 128Q125 81 146 54T209 26T302 45T394 111Q403 121 406 121Q410 121 419 112T429 98T420 82T390 55T344 24T281 -1T205 -11Q126 -11 83 42T39 168ZM373 353Q367 405 305 405Q272 405 244 391T199 357T170 316T154 280T149 261Q149 260 169 260Q282 260 327 284T373 353Z"></path></g><g data-mml-node="mo" transform="translate(2581.8,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="msub" transform="translate(3637.6,0)"><g data-mml-node="mi"><path data-c="1D6FC" d="M34 156Q34 270 120 356T309 442Q379 442 421 402T478 304Q484 275 485 237V208Q534 282 560 374Q564 388 566 390T582 393Q603 393 603 385Q603 376 594 346T558 261T497 161L486 147L487 123Q489 67 495 47T514 26Q528 28 540 37T557 60Q559 67 562 68T577 70Q597 70 597 62Q597 56 591 43Q579 19 556 5T512 -10H505Q438 -10 414 62L411 69L400 61Q390 53 370 41T325 18T267 -2T203 -11Q124 -11 79 39T34 156ZM208 26Q257 26 306 47T379 90L403 112Q401 255 396 290Q382 405 304 405Q235 405 183 332Q156 292 139 224T121 120Q121 71 146 49T208 26Z"></path></g><g data-mml-node="TeXAtom" transform="translate(673,-150) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="1D45F" d="M21 287Q22 290 23 295T28 317T38 348T53 381T73 411T99 433T132 442Q161 442 183 430T214 408T225 388Q227 382 228 382T236 389Q284 441 347 441H350Q398 441 422 400Q430 381 430 363Q430 333 417 315T391 292T366 288Q346 288 334 299T322 328Q322 376 378 392Q356 405 342 405Q286 405 239 331Q229 315 224 298T190 165Q156 25 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 114 189T154 366Q154 405 128 405Q107 405 92 377T68 316T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(451,0)"><path data-c="1D452" d="M39 168Q39 225 58 272T107 350T174 402T244 433T307 442H310Q355 442 388 420T421 355Q421 265 310 237Q261 224 176 223Q139 223 138 221Q138 219 132 186T125 128Q125 81 146 54T209 26T302 45T394 111Q403 121 406 121Q410 121 419 112T429 98T420 82T390 55T344 24T281 -1T205 -11Q126 -11 83 42T39 168ZM373 353Q367 405 305 405Q272 405 244 391T199 357T170 316T154 280T149 261Q149 260 169 260Q282 260 327 284T373 353Z"></path></g><g data-mml-node="mi" transform="translate(917,0)"><path data-c="1D450" d="M34 159Q34 268 120 355T306 442Q362 442 394 418T427 355Q427 326 408 306T360 285Q341 285 330 295T319 325T330 359T352 380T366 386H367Q367 388 361 392T340 400T306 404Q276 404 249 390Q228 381 206 359Q162 315 142 235T121 119Q121 73 147 50Q169 26 205 26H209Q321 26 394 111Q403 121 406 121Q410 121 419 112T429 98T420 83T391 55T346 25T282 0T202 -11Q127 -11 81 37T34 159Z"></path></g><g data-mml-node="mi" transform="translate(1350,0)"><path data-c="1D452" d="M39 168Q39 225 58 272T107 350T174 402T244 433T307 442H310Q355 442 388 420T421 355Q421 265 310 237Q261 224 176 223Q139 223 138 221Q138 219 132 186T125 128Q125 81 146 54T209 26T302 45T394 111Q403 121 406 121Q410 121 419 112T429 98T420 82T390 55T344 24T281 -1T205 -11Q126 -11 83 42T39 168ZM373 353Q367 405 305 405Q272 405 244 391T199 357T170 316T154 280T149 261Q149 260 169 260Q282 260 327 284T373 353Z"></path></g><g data-mml-node="mi" transform="translate(1816,0)"><path data-c="1D45B" d="M21 287Q22 293 24 303T36 341T56 388T89 425T135 442Q171 442 195 424T225 390T231 369Q231 367 232 367L243 378Q304 442 382 442Q436 442 469 415T503 336T465 179T427 52Q427 26 444 26Q450 26 453 27Q482 32 505 65T540 145Q542 153 560 153Q580 153 580 145Q580 144 576 130Q568 101 554 73T508 17T439 -10Q392 -10 371 17T350 73Q350 92 386 193T423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 180T152 343Q153 348 153 366Q153 405 129 405Q91 405 66 305Q60 285 60 284Q58 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(2416,0)"><path data-c="1D450" d="M34 159Q34 268 120 355T306 442Q362 442 394 418T427 355Q427 326 408 306T360 285Q341 285 330 295T319 325T330 359T352 380T366 386H367Q367 388 361 392T340 400T306 404Q276 404 249 390Q228 381 206 359Q162 315 142 235T121 119Q121 73 147 50Q169 26 205 26H209Q321 26 394 111Q403 121 406 121Q410 121 419 112T429 98T420 83T391 55T346 25T282 0T202 -11Q127 -11 81 37T34 159Z"></path></g><g data-mml-node="mi" transform="translate(2849,0)"><path data-c="1D466" d="M21 287Q21 301 36 335T84 406T158 442Q199 442 224 419T250 355Q248 336 247 334Q247 331 231 288T198 191T182 105Q182 62 196 45T238 27Q261 27 281 38T312 61T339 94Q339 95 344 114T358 173T377 247Q415 397 419 404Q432 431 462 431Q475 431 483 424T494 412T496 403Q496 390 447 193T391 -23Q363 -106 294 -155T156 -205Q111 -205 77 -183T43 -117Q43 -95 50 -80T69 -58T89 -48T106 -45Q150 -45 150 -87Q150 -107 138 -122T115 -142T102 -147L99 -148Q101 -153 118 -160T152 -167H160Q177 -167 186 -165Q219 -156 247 -127T290 -65T313 -9T321 21L315 17Q309 13 296 6T270 -6Q250 -11 231 -11Q185 -11 150 11T104 82Q103 89 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g></g></g><g data-mml-node="mo" transform="translate(6943.8,0)"><path data-c="22C5" d="M78 250Q78 274 95 292T138 310Q162 310 180 294T199 251Q199 226 182 208T139 190T96 207T78 250Z"></path></g><g data-mml-node="mi" transform="translate(7444,0)"><path data-c="1D45F" d="M21 287Q22 290 23 295T28 317T38 348T53 381T73 411T99 433T132 442Q161 442 183 430T214 408T225 388Q227 382 228 382T236 389Q284 441 347 441H350Q398 441 422 400Q430 381 430 363Q430 333 417 315T391 292T366 288Q346 288 334 299T322 328Q322 376 378 392Q356 405 342 405Q286 405 239 331Q229 315 224 298T190 165Q156 25 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 114 189T154 366Q154 405 128 405Q107 405 92 377T68 316T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(7895,0)"><path data-c="1D452" d="M39 168Q39 225 58 272T107 350T174 402T244 433T307 442H310Q355 442 388 420T421 355Q421 265 310 237Q261 224 176 223Q139 223 138 221Q138 219 132 186T125 128Q125 81 146 54T209 26T302 45T394 111Q403 121 406 121Q410 121 419 112T429 98T420 82T390 55T344 24T281 -1T205 -11Q126 -11 83 42T39 168ZM373 353Q367 405 305 405Q272 405 244 391T199 357T170 316T154 280T149 261Q149 260 169 260Q282 260 327 284T373 353Z"></path></g><g data-mml-node="mi" transform="translate(8361,0)"><path data-c="1D450" d="M34 159Q34 268 120 355T306 442Q362 442 394 418T427 355Q427 326 408 306T360 285Q341 285 330 295T319 325T330 359T352 380T366 386H367Q367 388 361 392T340 400T306 404Q276 404 249 390Q228 381 206 359Q162 315 142 235T121 119Q121 73 147 50Q169 26 205 26H209Q321 26 394 111Q403 121 406 121Q410 121 419 112T429 98T420 83T391 55T346 25T282 0T202 -11Q127 -11 81 37T34 159Z"></path></g><g data-mml-node="mi" transform="translate(8794,0)"><path data-c="1D452" d="M39 168Q39 225 58 272T107 350T174 402T244 433T307 442H310Q355 442 388 420T421 355Q421 265 310 237Q261 224 176 223Q139 223 138 221Q138 219 132 186T125 128Q125 81 146 54T209 26T302 45T394 111Q403 121 406 121Q410 121 419 112T429 98T420 82T390 55T344 24T281 -1T205 -11Q126 -11 83 42T39 168ZM373 353Q367 405 305 405Q272 405 244 391T199 357T170 316T154 280T149 261Q149 260 169 260Q282 260 327 284T373 353Z"></path></g><g data-mml-node="mi" transform="translate(9260,0)"><path data-c="1D45B" d="M21 287Q22 293 24 303T36 341T56 388T89 425T135 442Q171 442 195 424T225 390T231 369Q231 367 232 367L243 378Q304 442 382 442Q436 442 469 415T503 336T465 179T427 52Q427 26 444 26Q450 26 453 27Q482 32 505 65T540 145Q542 153 560 153Q580 153 580 145Q580 144 576 130Q568 101 554 73T508 17T439 -10Q392 -10 371 17T350 73Q350 92 386 193T423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 180T152 343Q153 348 153 366Q153 405 129 405Q91 405 66 305Q60 285 60 284Q58 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(9860,0)"><path data-c="1D450" d="M34 159Q34 268 120 355T306 442Q362 442 394 418T427 355Q427 326 408 306T360 285Q341 285 330 295T319 325T330 359T352 380T366 386H367Q367 388 361 392T340 400T306 404Q276 404 249 390Q228 381 206 359Q162 315 142 235T121 119Q121 73 147 50Q169 26 205 26H209Q321 26 394 111Q403 121 406 121Q410 121 419 112T429 98T420 83T391 55T346 25T282 0T202 -11Q127 -11 81 37T34 159Z"></path></g><g data-mml-node="mi" transform="translate(10293,0)"><path data-c="1D466" d="M21 287Q21 301 36 335T84 406T158 442Q199 442 224 419T250 355Q248 336 247 334Q247 331 231 288T198 191T182 105Q182 62 196 45T238 27Q261 27 281 38T312 61T339 94Q339 95 344 114T358 173T377 247Q415 397 419 404Q432 431 462 431Q475 431 483 424T494 412T496 403Q496 390 447 193T391 -23Q363 -106 294 -155T156 -205Q111 -205 77 -183T43 -117Q43 -95 50 -80T69 -58T89 -48T106 -45Q150 -45 150 -87Q150 -107 138 -122T115 -142T102 -147L99 -148Q101 -153 118 -160T152 -167H160Q177 -167 186 -165Q219 -156 247 -127T290 -65T313 -9T321 21L315 17Q309 13 296 6T270 -6Q250 -11 231 -11Q185 -11 150 11T104 82Q103 89 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mo" transform="translate(11005.3,0)"><path data-c="2B" d="M56 237T56 250T70 270H369V420L370 570Q380 583 389 583Q402 583 409 568V270H707Q722 262 722 250T707 230H409V-68Q401 -82 391 -82H389H387Q375 -82 369 -68V230H70Q56 237 56 250Z"></path></g><g data-mml-node="msub" transform="translate(12005.5,0)"><g data-mml-node="mi"><path data-c="1D6FC" d="M34 156Q34 270 120 356T309 442Q379 442 421 402T478 304Q484 275 485 237V208Q534 282 560 374Q564 388 566 390T582 393Q603 393 603 385Q603 376 594 346T558 261T497 161L486 147L487 123Q489 67 495 47T514 26Q528 28 540 37T557 60Q559 67 562 68T577 70Q597 70 597 62Q597 56 591 43Q579 19 556 5T512 -10H505Q438 -10 414 62L411 69L400 61Q390 53 370 41T325 18T267 -2T203 -11Q124 -11 79 39T34 156ZM208 26Q257 26 306 47T379 90L403 112Q401 255 396 290Q382 405 304 405Q235 405 183 332Q156 292 139 224T121 120Q121 71 146 49T208 26Z"></path></g><g data-mml-node="TeXAtom" transform="translate(673,-150) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(345,0)"><path data-c="1D45A" d="M21 287Q22 293 24 303T36 341T56 388T88 425T132 442T175 435T205 417T221 395T229 376L231 369Q231 367 232 367L243 378Q303 442 384 442Q401 442 415 440T441 433T460 423T475 411T485 398T493 385T497 373T500 364T502 357L510 367Q573 442 659 442Q713 442 746 415T780 336Q780 285 742 178T704 50Q705 36 709 31T724 26Q752 26 776 56T815 138Q818 149 821 151T837 153Q857 153 857 145Q857 144 853 130Q845 101 831 73T785 17T716 -10Q669 -10 648 17T627 73Q627 92 663 193T700 345Q700 404 656 404H651Q565 404 506 303L499 291L466 157Q433 26 428 16Q415 -11 385 -11Q372 -11 364 -4T353 8T350 18Q350 29 384 161L420 307Q423 322 423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 181Q151 335 151 342Q154 357 154 369Q154 405 129 405Q107 405 92 377T69 316T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(1223,0)"><path data-c="1D45D" d="M23 287Q24 290 25 295T30 317T40 348T55 381T75 411T101 433T134 442Q209 442 230 378L240 387Q302 442 358 442Q423 442 460 395T497 281Q497 173 421 82T249 -10Q227 -10 210 -4Q199 1 187 11T168 28L161 36Q160 35 139 -51T118 -138Q118 -144 126 -145T163 -148H188Q194 -155 194 -157T191 -175Q188 -187 185 -190T172 -194Q170 -194 161 -194T127 -193T65 -192Q-5 -192 -24 -194H-32Q-39 -187 -39 -183Q-37 -156 -26 -148H-6Q28 -147 33 -136Q36 -130 94 103T155 350Q156 355 156 364Q156 405 131 405Q109 405 94 377T71 316T59 280Q57 278 43 278H29Q23 284 23 287ZM178 102Q200 26 252 26Q282 26 310 49T356 107Q374 141 392 215T411 325V331Q411 405 350 405Q339 405 328 402T306 393T286 380T269 365T254 350T243 336T235 326L232 322Q232 321 229 308T218 264T204 212Q178 106 178 102Z"></path></g><g data-mml-node="mi" transform="translate(1726,0)"><path data-c="1D45C" d="M201 -11Q126 -11 80 38T34 156Q34 221 64 279T146 380Q222 441 301 441Q333 441 341 440Q354 437 367 433T402 417T438 387T464 338T476 268Q476 161 390 75T201 -11ZM121 120Q121 70 147 48T206 26Q250 26 289 58T351 142Q360 163 374 216T388 308Q388 352 370 375Q346 405 306 405Q243 405 195 347Q158 303 140 230T121 120Z"></path></g><g data-mml-node="mi" transform="translate(2211,0)"><path data-c="1D45F" d="M21 287Q22 290 23 295T28 317T38 348T53 381T73 411T99 433T132 442Q161 442 183 430T214 408T225 388Q227 382 228 382T236 389Q284 441 347 441H350Q398 441 422 400Q430 381 430 363Q430 333 417 315T391 292T366 288Q346 288 334 299T322 328Q322 376 378 392Q356 405 342 405Q286 405 239 331Q229 315 224 298T190 165Q156 25 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 114 189T154 366Q154 405 128 405Q107 405 92 377T68 316T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(2662,0)"><path data-c="1D461" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path></g><g data-mml-node="mi" transform="translate(3023,0)"><path data-c="1D44E" d="M33 157Q33 258 109 349T280 441Q331 441 370 392Q386 422 416 422Q429 422 439 414T449 394Q449 381 412 234T374 68Q374 43 381 35T402 26Q411 27 422 35Q443 55 463 131Q469 151 473 152Q475 153 483 153H487Q506 153 506 144Q506 138 501 117T481 63T449 13Q436 0 417 -8Q409 -10 393 -10Q359 -10 336 5T306 36L300 51Q299 52 296 50Q294 48 292 46Q233 -10 172 -10Q117 -10 75 30T33 157ZM351 328Q351 334 346 350T323 385T277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q217 26 254 59T298 110Q300 114 325 217T351 328Z"></path></g><g data-mml-node="mi" transform="translate(3552,0)"><path data-c="1D45B" d="M21 287Q22 293 24 303T36 341T56 388T89 425T135 442Q171 442 195 424T225 390T231 369Q231 367 232 367L243 378Q304 442 382 442Q436 442 469 415T503 336T465 179T427 52Q427 26 444 26Q450 26 453 27Q482 32 505 65T540 145Q542 153 560 153Q580 153 580 145Q580 144 576 130Q568 101 554 73T508 17T439 -10Q392 -10 371 17T350 73Q350 92 386 193T423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 180T152 343Q153 348 153 366Q153 405 129 405Q91 405 66 305Q60 285 60 284Q58 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(4152,0)"><path data-c="1D450" d="M34 159Q34 268 120 355T306 442Q362 442 394 418T427 355Q427 326 408 306T360 285Q341 285 330 295T319 325T330 359T352 380T366 386H367Q367 388 361 392T340 400T306 404Q276 404 249 390Q228 381 206 359Q162 315 142 235T121 119Q121 73 147 50Q169 26 205 26H209Q321 26 394 111Q403 121 406 121Q410 121 419 112T429 98T420 83T391 55T346 25T282 0T202 -11Q127 -11 81 37T34 159Z"></path></g><g data-mml-node="mi" transform="translate(4585,0)"><path data-c="1D452" d="M39 168Q39 225 58 272T107 350T174 402T244 433T307 442H310Q355 442 388 420T421 355Q421 265 310 237Q261 224 176 223Q139 223 138 221Q138 219 132 186T125 128Q125 81 146 54T209 26T302 45T394 111Q403 121 406 121Q410 121 419 112T429 98T420 82T390 55T344 24T281 -1T205 -11Q126 -11 83 42T39 168ZM373 353Q367 405 305 405Q272 405 244 391T199 357T170 316T154 280T149 261Q149 260 169 260Q282 260 327 284T373 353Z"></path></g></g></g><g data-mml-node="mo" transform="translate(16522.3,0)"><path data-c="22C5" d="M78 250Q78 274 95 292T138 310Q162 310 180 294T199 251Q199 226 182 208T139 190T96 207T78 250Z"></path></g><g data-mml-node="mi" transform="translate(17022.5,0)"><path data-c="1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(17367.5,0)"><path data-c="1D45A" d="M21 287Q22 293 24 303T36 341T56 388T88 425T132 442T175 435T205 417T221 395T229 376L231 369Q231 367 232 367L243 378Q303 442 384 442Q401 442 415 440T441 433T460 423T475 411T485 398T493 385T497 373T500 364T502 357L510 367Q573 442 659 442Q713 442 746 415T780 336Q780 285 742 178T704 50Q705 36 709 31T724 26Q752 26 776 56T815 138Q818 149 821 151T837 153Q857 153 857 145Q857 144 853 130Q845 101 831 73T785 17T716 -10Q669 -10 648 17T627 73Q627 92 663 193T700 345Q700 404 656 404H651Q565 404 506 303L499 291L466 157Q433 26 428 16Q415 -11 385 -11Q372 -11 364 -4T353 8T350 18Q350 29 384 161L420 307Q423 322 423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 181Q151 335 151 342Q154 357 154 369Q154 405 129 405Q107 405 92 377T69 316T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(18245.5,0)"><path data-c="1D45D" d="M23 287Q24 290 25 295T30 317T40 348T55 381T75 411T101 433T134 442Q209 442 230 378L240 387Q302 442 358 442Q423 442 460 395T497 281Q497 173 421 82T249 -10Q227 -10 210 -4Q199 1 187 11T168 28L161 36Q160 35 139 -51T118 -138Q118 -144 126 -145T163 -148H188Q194 -155 194 -157T191 -175Q188 -187 185 -190T172 -194Q170 -194 161 -194T127 -193T65 -192Q-5 -192 -24 -194H-32Q-39 -187 -39 -183Q-37 -156 -26 -148H-6Q28 -147 33 -136Q36 -130 94 103T155 350Q156 355 156 364Q156 405 131 405Q109 405 94 377T71 316T59 280Q57 278 43 278H29Q23 284 23 287ZM178 102Q200 26 252 26Q282 26 310 49T356 107Q374 141 392 215T411 325V331Q411 405 350 405Q339 405 328 402T306 393T286 380T269 365T254 350T243 336T235 326L232 322Q232 321 229 308T218 264T204 212Q178 106 178 102Z"></path></g><g data-mml-node="mi" transform="translate(18748.5,0)"><path data-c="1D45C" d="M201 -11Q126 -11 80 38T34 156Q34 221 64 279T146 380Q222 441 301 441Q333 441 341 440Q354 437 367 433T402 417T438 387T464 338T476 268Q476 161 390 75T201 -11ZM121 120Q121 70 147 48T206 26Q250 26 289 58T351 142Q360 163 374 216T388 308Q388 352 370 375Q346 405 306 405Q243 405 195 347Q158 303 140 230T121 120Z"></path></g><g data-mml-node="mi" transform="translate(19233.5,0)"><path data-c="1D45F" d="M21 287Q22 290 23 295T28 317T38 348T53 381T73 411T99 433T132 442Q161 442 183 430T214 408T225 388Q227 382 228 382T236 389Q284 441 347 441H350Q398 441 422 400Q430 381 430 363Q430 333 417 315T391 292T366 288Q346 288 334 299T322 328Q322 376 378 392Q356 405 342 405Q286 405 239 331Q229 315 224 298T190 165Q156 25 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 114 189T154 366Q154 405 128 405Q107 405 92 377T68 316T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(19684.5,0)"><path data-c="1D461" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path></g><g data-mml-node="mi" transform="translate(20045.5,0)"><path data-c="1D44E" d="M33 157Q33 258 109 349T280 441Q331 441 370 392Q386 422 416 422Q429 422 439 414T449 394Q449 381 412 234T374 68Q374 43 381 35T402 26Q411 27 422 35Q443 55 463 131Q469 151 473 152Q475 153 483 153H487Q506 153 506 144Q506 138 501 117T481 63T449 13Q436 0 417 -8Q409 -10 393 -10Q359 -10 336 5T306 36L300 51Q299 52 296 50Q294 48 292 46Q233 -10 172 -10Q117 -10 75 30T33 157ZM351 328Q351 334 346 350T323 385T277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q217 26 254 59T298 110Q300 114 325 217T351 328Z"></path></g><g data-mml-node="mi" transform="translate(20574.5,0)"><path data-c="1D45B" d="M21 287Q22 293 24 303T36 341T56 388T89 425T135 442Q171 442 195 424T225 390T231 369Q231 367 232 367L243 378Q304 442 382 442Q436 442 469 415T503 336T465 179T427 52Q427 26 444 26Q450 26 453 27Q482 32 505 65T540 145Q542 153 560 153Q580 153 580 145Q580 144 576 130Q568 101 554 73T508 17T439 -10Q392 -10 371 17T350 73Q350 92 386 193T423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 180T152 343Q153 348 153 366Q153 405 129 405Q91 405 66 305Q60 285 60 284Q58 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(21174.5,0)"><path data-c="1D450" d="M34 159Q34 268 120 355T306 442Q362 442 394 418T427 355Q427 326 408 306T360 285Q341 285 330 295T319 325T330 359T352 380T366 386H367Q367 388 361 392T340 400T306 404Q276 404 249 390Q228 381 206 359Q162 315 142 235T121 119Q121 73 147 50Q169 26 205 26H209Q321 26 394 111Q403 121 406 121Q410 121 419 112T429 98T420 83T391 55T346 25T282 0T202 -11Q127 -11 81 37T34 159Z"></path></g><g data-mml-node="mi" transform="translate(21607.5,0)"><path data-c="1D452" d="M39 168Q39 225 58 272T107 350T174 402T244 433T307 442H310Q355 442 388 420T421 355Q421 265 310 237Q261 224 176 223Q139 223 138 221Q138 219 132 186T125 128Q125 81 146 54T209 26T302 45T394 111Q403 121 406 121Q410 121 419 112T429 98T420 82T390 55T344 24T281 -1T205 -11Q126 -11 83 42T39 168ZM373 353Q367 405 305 405Q272 405 244 391T199 357T170 316T154 280T149 261Q149 260 169 260Q282 260 327 284T373 353Z"></path></g><g data-mml-node="mo" transform="translate(22295.7,0)"><path data-c="2B" d="M56 237T56 250T70 270H369V420L370 570Q380 583 389 583Q402 583 409 568V270H707Q722 262 722 250T707 230H409V-68Q401 -82 391 -82H389H387Q375 -82 369 -68V230H70Q56 237 56 250Z"></path></g><g data-mml-node="msub" transform="translate(23296,0)"><g data-mml-node="mi"><path data-c="1D6FC" d="M34 156Q34 270 120 356T309 442Q379 442 421 402T478 304Q484 275 485 237V208Q534 282 560 374Q564 388 566 390T582 393Q603 393 603 385Q603 376 594 346T558 261T497 161L486 147L487 123Q489 67 495 47T514 26Q528 28 540 37T557 60Q559 67 562 68T577 70Q597 70 597 62Q597 56 591 43Q579 19 556 5T512 -10H505Q438 -10 414 62L411 69L400 61Q390 53 370 41T325 18T267 -2T203 -11Q124 -11 79 39T34 156ZM208 26Q257 26 306 47T379 90L403 112Q401 255 396 290Q382 405 304 405Q235 405 183 332Q156 292 139 224T121 120Q121 71 146 49T208 26Z"></path></g><g data-mml-node="TeXAtom" transform="translate(673,-150) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="1D45F" d="M21 287Q22 290 23 295T28 317T38 348T53 381T73 411T99 433T132 442Q161 442 183 430T214 408T225 388Q227 382 228 382T236 389Q284 441 347 441H350Q398 441 422 400Q430 381 430 363Q430 333 417 315T391 292T366 288Q346 288 334 299T322 328Q322 376 378 392Q356 405 342 405Q286 405 239 331Q229 315 224 298T190 165Q156 25 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 114 189T154 366Q154 405 128 405Q107 405 92 377T68 316T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(451,0)"><path data-c="1D452" d="M39 168Q39 225 58 272T107 350T174 402T244 433T307 442H310Q355 442 388 420T421 355Q421 265 310 237Q261 224 176 223Q139 223 138 221Q138 219 132 186T125 128Q125 81 146 54T209 26T302 45T394 111Q403 121 406 121Q410 121 419 112T429 98T420 82T390 55T344 24T281 -1T205 -11Q126 -11 83 42T39 168ZM373 353Q367 405 305 405Q272 405 244 391T199 357T170 316T154 280T149 261Q149 260 169 260Q282 260 327 284T373 353Z"></path></g><g data-mml-node="mi" transform="translate(917,0)"><path data-c="1D459" d="M117 59Q117 26 142 26Q179 26 205 131Q211 151 215 152Q217 153 225 153H229Q238 153 241 153T246 151T248 144Q247 138 245 128T234 90T214 43T183 6T137 -11Q101 -11 70 11T38 85Q38 97 39 102L104 360Q167 615 167 623Q167 626 166 628T162 632T157 634T149 635T141 636T132 637T122 637Q112 637 109 637T101 638T95 641T94 647Q94 649 96 661Q101 680 107 682T179 688Q194 689 213 690T243 693T254 694Q266 694 266 686Q266 675 193 386T118 83Q118 81 118 75T117 65V59Z"></path></g><g data-mml-node="mi" transform="translate(1215,0)"><path data-c="1D452" d="M39 168Q39 225 58 272T107 350T174 402T244 433T307 442H310Q355 442 388 420T421 355Q421 265 310 237Q261 224 176 223Q139 223 138 221Q138 219 132 186T125 128Q125 81 146 54T209 26T302 45T394 111Q403 121 406 121Q410 121 419 112T429 98T420 82T390 55T344 24T281 -1T205 -11Q126 -11 83 42T39 168ZM373 353Q367 405 305 405Q272 405 244 391T199 357T170 316T154 280T149 261Q149 260 169 260Q282 260 327 284T373 353Z"></path></g><g data-mml-node="mi" transform="translate(1681,0)"><path data-c="1D463" d="M173 380Q173 405 154 405Q130 405 104 376T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Q21 294 29 316T53 368T97 419T160 441Q202 441 225 417T249 361Q249 344 246 335Q246 329 231 291T200 202T182 113Q182 86 187 69Q200 26 250 26Q287 26 319 60T369 139T398 222T409 277Q409 300 401 317T383 343T365 361T357 383Q357 405 376 424T417 443Q436 443 451 425T467 367Q467 340 455 284T418 159T347 40T241 -11Q177 -11 139 22Q102 54 102 117Q102 148 110 181T151 298Q173 362 173 380Z"></path></g><g data-mml-node="mi" transform="translate(2166,0)"><path data-c="1D44E" d="M33 157Q33 258 109 349T280 441Q331 441 370 392Q386 422 416 422Q429 422 439 414T449 394Q449 381 412 234T374 68Q374 43 381 35T402 26Q411 27 422 35Q443 55 463 131Q469 151 473 152Q475 153 483 153H487Q506 153 506 144Q506 138 501 117T481 63T449 13Q436 0 417 -8Q409 -10 393 -10Q359 -10 336 5T306 36L300 51Q299 52 296 50Q294 48 292 46Q233 -10 172 -10Q117 -10 75 30T33 157ZM351 328Q351 334 346 350T323 385T277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q217 26 254 59T298 110Q300 114 325 217T351 328Z"></path></g><g data-mml-node="mi" transform="translate(2695,0)"><path data-c="1D45B" d="M21 287Q22 293 24 303T36 341T56 388T89 425T135 442Q171 442 195 424T225 390T231 369Q231 367 232 367L243 378Q304 442 382 442Q436 442 469 415T503 336T465 179T427 52Q427 26 444 26Q450 26 453 27Q482 32 505 65T540 145Q542 153 560 153Q580 153 580 145Q580 144 576 130Q568 101 554 73T508 17T439 -10Q392 -10 371 17T350 73Q350 92 386 193T423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 180T152 343Q153 348 153 366Q153 405 129 405Q91 405 66 305Q60 285 60 284Q58 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(3295,0)"><path data-c="1D450" d="M34 159Q34 268 120 355T306 442Q362 442 394 418T427 355Q427 326 408 306T360 285Q341 285 330 295T319 325T330 359T352 380T366 386H367Q367 388 361 392T340 400T306 404Q276 404 249 390Q228 381 206 359Q162 315 142 235T121 119Q121 73 147 50Q169 26 205 26H209Q321 26 394 111Q403 121 406 121Q410 121 419 112T429 98T420 83T391 55T346 25T282 0T202 -11Q127 -11 81 37T34 159Z"></path></g><g data-mml-node="mi" transform="translate(3728,0)"><path data-c="1D452" d="M39 168Q39 225 58 272T107 350T174 402T244 433T307 442H310Q355 442 388 420T421 355Q421 265 310 237Q261 224 176 223Q139 223 138 221Q138 219 132 186T125 128Q125 81 146 54T209 26T302 45T394 111Q403 121 406 121Q410 121 419 112T429 98T420 82T390 55T344 24T281 -1T205 -11Q126 -11 83 42T39 168ZM373 353Q367 405 305 405Q272 405 244 391T199 357T170 316T154 280T149 261Q149 260 169 260Q282 260 327 284T373 353Z"></path></g></g></g><g data-mml-node="mo" transform="translate(27206.8,0)"><path data-c="22C5" d="M78 250Q78 274 95 292T138 310Q162 310 180 294T199 251Q199 226 182 208T139 190T96 207T78 250Z"></path></g><g data-mml-node="mi" transform="translate(27707,0)"><path data-c="1D45F" d="M21 287Q22 290 23 295T28 317T38 348T53 381T73 411T99 433T132 442Q161 442 183 430T214 408T225 388Q227 382 228 382T236 389Q284 441 347 441H350Q398 441 422 400Q430 381 430 363Q430 333 417 315T391 292T366 288Q346 288 334 299T322 328Q322 376 378 392Q356 405 342 405Q286 405 239 331Q229 315 224 298T190 165Q156 25 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 114 189T154 366Q154 405 128 405Q107 405 92 377T68 316T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(28158,0)"><path data-c="1D452" d="M39 168Q39 225 58 272T107 350T174 402T244 433T307 442H310Q355 442 388 420T421 355Q421 265 310 237Q261 224 176 223Q139 223 138 221Q138 219 132 186T125 128Q125 81 146 54T209 26T302 45T394 111Q403 121 406 121Q410 121 419 112T429 98T420 82T390 55T344 24T281 -1T205 -11Q126 -11 83 42T39 168ZM373 353Q367 405 305 405Q272 405 244 391T199 357T170 316T154 280T149 261Q149 260 169 260Q282 260 327 284T373 353Z"></path></g><g data-mml-node="mi" transform="translate(28624,0)"><path data-c="1D459" d="M117 59Q117 26 142 26Q179 26 205 131Q211 151 215 152Q217 153 225 153H229Q238 153 241 153T246 151T248 144Q247 138 245 128T234 90T214 43T183 6T137 -11Q101 -11 70 11T38 85Q38 97 39 102L104 360Q167 615 167 623Q167 626 166 628T162 632T157 634T149 635T141 636T132 637T122 637Q112 637 109 637T101 638T95 641T94 647Q94 649 96 661Q101 680 107 682T179 688Q194 689 213 690T243 693T254 694Q266 694 266 686Q266 675 193 386T118 83Q118 81 118 75T117 65V59Z"></path></g><g data-mml-node="mi" transform="translate(28922,0)"><path data-c="1D452" d="M39 168Q39 225 58 272T107 350T174 402T244 433T307 442H310Q355 442 388 420T421 355Q421 265 310 237Q261 224 176 223Q139 223 138 221Q138 219 132 186T125 128Q125 81 146 54T209 26T302 45T394 111Q403 121 406 121Q410 121 419 112T429 98T420 82T390 55T344 24T281 -1T205 -11Q126 -11 83 42T39 168ZM373 353Q367 405 305 405Q272 405 244 391T199 357T170 316T154 280T149 261Q149 260 169 260Q282 260 327 284T373 353Z"></path></g><g data-mml-node="mi" transform="translate(29388,0)"><path data-c="1D463" d="M173 380Q173 405 154 405Q130 405 104 376T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Q21 294 29 316T53 368T97 419T160 441Q202 441 225 417T249 361Q249 344 246 335Q246 329 231 291T200 202T182 113Q182 86 187 69Q200 26 250 26Q287 26 319 60T369 139T398 222T409 277Q409 300 401 317T383 343T365 361T357 383Q357 405 376 424T417 443Q436 443 451 425T467 367Q467 340 455 284T418 159T347 40T241 -11Q177 -11 139 22Q102 54 102 117Q102 148 110 181T151 298Q173 362 173 380Z"></path></g><g data-mml-node="mi" transform="translate(29873,0)"><path data-c="1D44E" d="M33 157Q33 258 109 349T280 441Q331 441 370 392Q386 422 416 422Q429 422 439 414T449 394Q449 381 412 234T374 68Q374 43 381 35T402 26Q411 27 422 35Q443 55 463 131Q469 151 473 152Q475 153 483 153H487Q506 153 506 144Q506 138 501 117T481 63T449 13Q436 0 417 -8Q409 -10 393 -10Q359 -10 336 5T306 36L300 51Q299 52 296 50Q294 48 292 46Q233 -10 172 -10Q117 -10 75 30T33 157ZM351 328Q351 334 346 350T323 385T277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q217 26 254 59T298 110Q300 114 325 217T351 328Z"></path></g><g data-mml-node="mi" transform="translate(30402,0)"><path data-c="1D45B" d="M21 287Q22 293 24 303T36 341T56 388T89 425T135 442Q171 442 195 424T225 390T231 369Q231 367 232 367L243 378Q304 442 382 442Q436 442 469 415T503 336T465 179T427 52Q427 26 444 26Q450 26 453 27Q482 32 505 65T540 145Q542 153 560 153Q580 153 580 145Q580 144 576 130Q568 101 554 73T508 17T439 -10Q392 -10 371 17T350 73Q350 92 386 193T423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 180T152 343Q153 348 153 366Q153 405 129 405Q91 405 66 305Q60 285 60 284Q58 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(31002,0)"><path data-c="1D450" d="M34 159Q34 268 120 355T306 442Q362 442 394 418T427 355Q427 326 408 306T360 285Q341 285 330 295T319 325T330 359T352 380T366 386H367Q367 388 361 392T340 400T306 404Q276 404 249 390Q228 381 206 359Q162 315 142 235T121 119Q121 73 147 50Q169 26 205 26H209Q321 26 394 111Q403 121 406 121Q410 121 419 112T429 98T420 83T391 55T346 25T282 0T202 -11Q127 -11 81 37T34 159Z"></path></g><g data-mml-node="mi" transform="translate(31435,0)"><path data-c="1D452" d="M39 168Q39 225 58 272T107 350T174 402T244 433T307 442H310Q355 442 388 420T421 355Q421 265 310 237Q261 224 176 223Q139 223 138 221Q138 219 132 186T125 128Q125 81 146 54T209 26T302 45T394 111Q403 121 406 121Q410 121 419 112T429 98T420 82T390 55T344 24T281 -1T205 -11Q126 -11 83 42T39 168ZM373 353Q367 405 305 405Q272 405 244 391T199 357T170 316T154 280T149 261Q149 260 169 260Q282 260 327 284T373 353Z"></path></g></g></g></svg></mjx-container></p>
<table>
<thead>
<tr>
<th>组件</th>
<th>描述</th>
<th>实现</th>
</tr>
</thead>
<tbody><tr>
<td><strong>时近性</strong></td>
<td>最近访问的记忆分数更高</td>
<td>指数衰减函数，衰减因子0.995</td>
</tr>
<tr>
<td><strong>重要性</strong></td>
<td>区分平凡记忆和核心记忆</td>
<td>LLM评分1-10</td>
</tr>
<tr>
<td><strong>相关性</strong></td>
<td>与当前情况相关的记忆</td>
<td>嵌入向量余弦相似度</td>
</tr>
</tbody></table>
<h3 id="3-4-反思机制"><a href="#3-4-反思机制" class="headerlink" title="3.4 反思机制"></a>3.4 反思机制</h3><p><strong>触发条件</strong>: 重要性分数总和 &gt; 150（约每天2-3次）</p>
<p><strong>反思生成过程</strong>:</p>
<ol>
<li><p><strong>确定反思内容</strong>: 用最近100条记忆查询</p>
<ul>
<li>提示：”仅根据上述信息，我们可以回答哪3个最突出的高层次问题？”</li>
</ul>
</li>
<li><p><strong>检索相关记忆</strong>: 使用问题作为检索查询</p>
</li>
<li><p><strong>提取洞察</strong>: </p>
<ul>
<li>输出格式：”洞察（因为1, 5, 3）”</li>
</ul>
</li>
</ol>
<p><strong>反思树</strong>: 叶节点=观察，非叶节点=越来越抽象的反思</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">          [Klaus对研究充满热情]  ← 元反思</span><br><span class="line">                /        \</span><br><span class="line">[Klaus致力于研究]    [Klaus和Maria有共同兴趣]  ← 反思</span><br><span class="line">     /    \              /      \</span><br><span class="line">[写论文] [读书]     [讨论项目] [图书馆相遇]  ← 观察</span><br></pre></td></tr></table></figure>

<h3 id="3-5-规划机制"><a href="#3-5-规划机制" class="headerlink" title="3.5 规划机制"></a>3.5 规划机制</h3><p><strong>递归分解日程</strong>:</p>
<ol>
<li><strong>粗略计划</strong>: 一天的议程大纲</li>
<li><strong>小时级分解</strong>: 每小时的活动块</li>
<li><strong>细粒度分解</strong>: 5-15分钟的具体动作</li>
</ol>
<p><strong>示例</strong>:</p>
<ul>
<li>粗略：”下午1:00到5:00创作新音乐”</li>
<li>小时级：”下午1:00：开始为音乐创作头脑风暴…”</li>
<li>细粒度：”下午4:00：拿一些小零食。下午4:05：在工作区周围短暂散步…”</li>
</ul>
<h3 id="3-6-涌现的社会行为"><a href="#3-6-涌现的社会行为" class="headerlink" title="3.6 涌现的社会行为"></a>3.6 涌现的社会行为</h3><p><strong>实验设置</strong>: 25个智能体，Smallville小镇</p>
<p><strong>涌现现象</strong>:</p>
<table>
<thead>
<tr>
<th>现象</th>
<th>描述</th>
</tr>
</thead>
<tbody><tr>
<td><strong>信息扩散</strong></td>
<td>Sam的市长候选资格传播到32%智能体</td>
</tr>
<tr>
<td><strong>关系记忆</strong></td>
<td>智能体记住新认识的人及对话内容</td>
</tr>
<tr>
<td><strong>协调活动</strong></td>
<td>Isabella的情人节派对：5人自发出席</td>
</tr>
<tr>
<td><strong>网络密度</strong></td>
<td>从0.167增加到0.74</td>
</tr>
</tbody></table>
<p><strong>情人节派对案例</strong>:</p>
<ol>
<li>Isabella计划2月14日下午5-7点的派对</li>
<li>她花一天装饰咖啡馆</li>
<li>Maria帮忙装饰，并邀请暗恋的Klaus</li>
<li>最终5个智能体在正确时间出现</li>
</ol>
<h3 id="3-7-评估结果"><a href="#3-7-评估结果" class="headerlink" title="3.7 评估结果"></a>3.7 评估结果</h3><table>
<thead>
<tr>
<th>条件</th>
<th>TrueSkill评分</th>
</tr>
</thead>
<tbody><tr>
<td><strong>完整架构</strong></td>
<td><strong>29.89</strong></td>
</tr>
<tr>
<td>无反思</td>
<td>26.88</td>
</tr>
<tr>
<td>无反思、无计划</td>
<td>25.64</td>
</tr>
<tr>
<td>人类众包</td>
<td>22.95</td>
</tr>
<tr>
<td>无记忆（先前SOTA）</td>
<td>21.21</td>
</tr>
</tbody></table>
<p><strong>效应大小</strong>: 完整架构 vs 先前SOTA = <strong>8个标准差</strong></p>
<hr>
<h2 id="四、三大框架对比"><a href="#四、三大框架对比" class="headerlink" title="四、三大框架对比"></a>四、三大框架对比</h2><h3 id="4-1-核心差异"><a href="#4-1-核心差异" class="headerlink" title="4.1 核心差异"></a>4.1 核心差异</h3><table>
<thead>
<tr>
<th>维度</th>
<th>ReAct</th>
<th>Reflexion</th>
<th>Generative Agents</th>
</tr>
</thead>
<tbody><tr>
<td><strong>核心目标</strong></td>
<td>任务完成</td>
<td>从失败学习</td>
<td>行为拟真</td>
</tr>
<tr>
<td><strong>知识表示</strong></td>
<td>推理轨迹</td>
<td>语言化反思</td>
<td>记忆流</td>
</tr>
<tr>
<td><strong>学习方式</strong></td>
<td>单次推理</td>
<td>跨尝试积累</td>
<td>持续记忆+反思</td>
</tr>
<tr>
<td><strong>时间跨度</strong></td>
<td>单任务</td>
<td>多次尝试</td>
<td>天/周级</td>
</tr>
<tr>
<td><strong>是否微调</strong></td>
<td>❌</td>
<td>❌</td>
<td>❌</td>
</tr>
</tbody></table>
<h3 id="4-2-记忆机制对比"><a href="#4-2-记忆机制对比" class="headerlink" title="4.2 记忆机制对比"></a>4.2 记忆机制对比</h3><table>
<thead>
<tr>
<th>特性</th>
<th>ReAct</th>
<th>Reflexion</th>
<th>Generative Agents</th>
</tr>
</thead>
<tbody><tr>
<td><strong>存储内容</strong></td>
<td>当前轨迹</td>
<td>语言化反思</td>
<td>观察+反思+计划</td>
</tr>
<tr>
<td><strong>存储形式</strong></td>
<td>上下文</td>
<td>滑动窗口</td>
<td>记忆流列表</td>
</tr>
<tr>
<td><strong>检索方式</strong></td>
<td>无</td>
<td>时间顺序</td>
<td>时近性+重要性+相关性</td>
</tr>
<tr>
<td><strong>失败经验</strong></td>
<td>❌</td>
<td>✅ 重点</td>
<td>⚠️ 不强调</td>
</tr>
<tr>
<td><strong>抽象层次</strong></td>
<td>单层</td>
<td>双层</td>
<td>多层（反思树）</td>
</tr>
</tbody></table>
<h3 id="4-3-反思机制对比"><a href="#4-3-反思机制对比" class="headerlink" title="4.3 反思机制对比"></a>4.3 反思机制对比</h3><table>
<thead>
<tr>
<th>特性</th>
<th>ReAct</th>
<th>Reflexion</th>
<th>Generative Agents</th>
</tr>
</thead>
<tbody><tr>
<td><strong>有无反思</strong></td>
<td>❌ 无</td>
<td>✅ 核心</td>
<td>✅ 核心</td>
</tr>
<tr>
<td><strong>触发条件</strong></td>
<td>-</td>
<td>每次失败后</td>
<td>重要性&gt;150</td>
</tr>
<tr>
<td><strong>输出</strong></td>
<td>-</td>
<td>错误分析+改进</td>
<td>高层次洞察</td>
</tr>
<tr>
<td><strong>目的</strong></td>
<td>-</td>
<td>任务成功率</td>
<td>概念抽象</td>
</tr>
</tbody></table>
<h3 id="4-4-适用场景"><a href="#4-4-适用场景" class="headerlink" title="4.4 适用场景"></a>4.4 适用场景</h3><table>
<thead>
<tr>
<th>场景</th>
<th>推荐方法</th>
<th>原因</th>
</tr>
</thead>
<tbody><tr>
<td>知识问答</td>
<td>ReAct</td>
<td>与外部知识库交互</td>
</tr>
<tr>
<td>决策任务</td>
<td>Reflexion</td>
<td>从失败中学习</td>
</tr>
<tr>
<td>编程调试</td>
<td>Reflexion</td>
<td>需要多次尝试改进</td>
</tr>
<tr>
<td>社会模拟</td>
<td>Generative Agents</td>
<td>需要记忆和人格一致性</td>
</tr>
<tr>
<td>角色扮演</td>
<td>Generative Agents</td>
<td>需要丰富的背景记忆</td>
</tr>
</tbody></table>
<hr>
<h2 id="五、组合使用建议"><a href="#五、组合使用建议" class="headerlink" title="五、组合使用建议"></a>五、组合使用建议</h2><h3 id="5-1-理想组合架构"><a href="#5-1-理想组合架构" class="headerlink" title="5.1 理想组合架构"></a>5.1 理想组合架构</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line">┌────────────────────────────────────────────────────────────────────┐</span><br><span class="line">│                    理想智能体架构                                   │</span><br><span class="line">├────────────────────────────────────────────────────────────────────┤</span><br><span class="line">│                                                                    │</span><br><span class="line">│   ┌───────────────────────────────────────────────────────────┐   │</span><br><span class="line">│   │  Generative Agents的记忆流                                 │   │</span><br><span class="line">│   │  • 完整的经历记录                                          │   │</span><br><span class="line">│   │  • 多层次反思                                              │   │</span><br><span class="line">│   │  • 社交关系追踪                                            │   │</span><br><span class="line">│   └───────────────────────────────────────────────────────────┘   │</span><br><span class="line">│                              +                                     │</span><br><span class="line">│   ┌───────────────────────────────────────────────────────────┐   │</span><br><span class="line">│   │  ReAct的推理-行动范式                                      │   │</span><br><span class="line">│   │  • 思想与动作交替                                          │   │</span><br><span class="line">│   │  • 与外部环境交互                                          │   │</span><br><span class="line">│   │  • 减少幻觉                                                │   │</span><br><span class="line">│   └───────────────────────────────────────────────────────────┘   │</span><br><span class="line">│                              +                                     │</span><br><span class="line">│   ┌───────────────────────────────────────────────────────────┐   │</span><br><span class="line">│   │  Reflexion的失败反思                                       │   │</span><br><span class="line">│   │  • 失败经验的语言化                                        │   │</span><br><span class="line">│   │  • 错误诊断与改进建议                                      │   │</span><br><span class="line">│   │  • 跨尝试学习                                              │   │</span><br><span class="line">│   └───────────────────────────────────────────────────────────┘   │</span><br><span class="line">│                                                                    │</span><br><span class="line">└────────────────────────────────────────────────────────────────────┘</span><br></pre></td></tr></table></figure>

<h3 id="5-2-实现要点"><a href="#5-2-实现要点" class="headerlink" title="5.2 实现要点"></a>5.2 实现要点</h3><ol>
<li><strong>使用 ReAct 作为基础行动框架</strong>：思想+动作交替执行</li>
<li><strong>添加 Generative Agents 的记忆系统</strong>：持久化所有经历</li>
<li><strong>集成 Reflexion 的失败反思</strong>：从错误中学习</li>
<li><strong>定期触发高层次反思</strong>：形成长期理解</li>
</ol>
<hr>
<h2 id="六、关键论文原文引用"><a href="#六、关键论文原文引用" class="headerlink" title="六、关键论文原文引用"></a>六、关键论文原文引用</h2><h3 id="ReAct"><a href="#ReAct" class="headerlink" title="ReAct"></a>ReAct</h3><blockquote>
<p>“We propose ReAct — a general paradigm to combine reasoning and acting with language models for solving diverse language reasoning and decision making tasks.”</p>
</blockquote>
<h3 id="Reflexion"><a href="#Reflexion" class="headerlink" title="Reflexion"></a>Reflexion</h3><blockquote>
<p>“Reflexion converts binary or scalar feedback from the environment into verbal feedback in the form of a textual summary, which is then added as additional context for the LLM agent in the next episode.”</p>
</blockquote>
<h3 id="Generative-Agents"><a href="#Generative-Agents" class="headerlink" title="Generative Agents"></a>Generative Agents</h3><blockquote>
<p>“Generative agents wake up, cook breakfast, and head to work; artists paint, authors write; they form opinions, notice each other, and initiate conversations; they remember and reflect on days past as they plan the next day.”</p>
</blockquote>
<hr>
<p><a href="/2025/12/28/LLM-Game-Agents-%E8%AE%BA%E6%96%87%E8%A7%A3%E8%AF%BB-%E6%80%BB%E8%A7%88/">返回总览</a> | <a href="/2025/12/28/LLM-Game-Agents-%E5%BA%94%E7%94%A8%E6%89%A9%E5%B1%95%E7%AF%87/">下一篇：应用扩展篇</a></p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://foosynaptic.github.io/2025/12/28/LLM-Game-Agents-%E8%AE%BA%E6%96%87%E8%A7%A3%E8%AF%BB-%E6%80%BB%E8%A7%88/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="fooSynaptic">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="fooSynaptic">
      <meta itemprop="description" content="Head first to the Truth as Synaptic.">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content=" | fooSynaptic">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2025/12/28/LLM-Game-Agents-%E8%AE%BA%E6%96%87%E8%A7%A3%E8%AF%BB-%E6%80%BB%E8%A7%88/" class="post-title-link" itemprop="url">LLM 游戏智能体论文解读：总览</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2025-12-28 04:00:00" itemprop="dateCreated datePublished" datetime="2025-12-28T04:00:00+08:00">2025-12-28</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E8%AE%BA%E6%96%87%E8%A7%A3%E8%AF%BB/" itemprop="url" rel="index"><span itemprop="name">论文解读</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <p>本系列是 LLM 驱动的游戏智能体领域核心论文的解读与总结，涵盖 103+ 篇论文，164 条引用关系的系统性分析。</p>
<hr>
<h2 id="领域概述"><a href="#领域概述" class="headerlink" title="领域概述"></a>领域概述</h2><p>随着大型语言模型（LLM）的快速发展，研究者们开始探索将 LLM 作为智能体”大脑”的可能性。这些智能体不仅能理解和生成文本，还能规划、反思、与环境交互，甚至形成复杂的社会行为。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">┌─────────────────────────────────────────────────────────────┐</span><br><span class="line">│                    LLM 游戏智能体技术栈                       │</span><br><span class="line">├─────────────────────────────────────────────────────────────┤</span><br><span class="line">│                                                             │</span><br><span class="line">│   ┌─────────────────┐                                       │</span><br><span class="line">│   │   应用层         │  游戏/模拟/机器人                       │</span><br><span class="line">│   └────────┬────────┘                                       │</span><br><span class="line">│            │                                                │</span><br><span class="line">│   ┌────────▼────────┐                                       │</span><br><span class="line">│   │   智能体框架     │  ReAct / Reflexion / VOYAGER          │</span><br><span class="line">│   └────────┬────────┘                                       │</span><br><span class="line">│            │                                                │</span><br><span class="line">│   ┌────────▼────────┐                                       │</span><br><span class="line">│   │   核心能力       │  记忆 / 规划 / 反思 / 工具使用          │</span><br><span class="line">│   └────────┬────────┘                                       │</span><br><span class="line">│            │                                                │</span><br><span class="line">│   ┌────────▼────────┐                                       │</span><br><span class="line">│   │   基础模型       │  GPT-4 / Claude / Llama               │</span><br><span class="line">│   └─────────────────┘                                       │</span><br><span class="line">│                                                             │</span><br><span class="line">└─────────────────────────────────────────────────────────────┘</span><br></pre></td></tr></table></figure>

<hr>
<h2 id="核心论文引用关系"><a href="#核心论文引用关系" class="headerlink" title="核心论文引用关系"></a>核心论文引用关系</h2><p>基于 103 篇论文的引用网络分析，以下是领域内最具影响力的基础性工作：</p>
<table>
<thead>
<tr>
<th>排名</th>
<th>论文</th>
<th>会议</th>
<th>被引用</th>
<th>核心贡献</th>
</tr>
</thead>
<tbody><tr>
<td>1</td>
<td><strong>ReAct</strong></td>
<td>ICLR 2023</td>
<td>32</td>
<td>推理+行动交替范式</td>
</tr>
<tr>
<td>2</td>
<td><strong>Generative Agents</strong></td>
<td>UIST 2023</td>
<td>20</td>
<td>记忆-反思-规划架构</td>
</tr>
<tr>
<td>3</td>
<td><strong>Reflexion</strong></td>
<td>NeurIPS 2023</td>
<td>17</td>
<td>语言反馈强化学习</td>
</tr>
<tr>
<td>4</td>
<td><strong>VOYAGER</strong></td>
<td>NeurIPS 2023</td>
<td>-</td>
<td>技能库+终身学习</td>
</tr>
</tbody></table>
<h3 id="技术层次金字塔"><a href="#技术层次金字塔" class="headerlink" title="技术层次金字塔"></a>技术层次金字塔</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">                ┌─────────────────────┐</span><br><span class="line">                │   🎯 上层应用       │</span><br><span class="line">                │  竞技/社交/特定游戏  │</span><br><span class="line">                │  (Werewolf, Poker,  │</span><br><span class="line">                │   StarCraft等)      │</span><br><span class="line">                └──────────┬──────────┘</span><br><span class="line">                           │</span><br><span class="line">          ┌────────────────┼────────────────┐</span><br><span class="line">          │                │                │</span><br><span class="line">┌─────────▼─────────┐ ┌────▼────┐ ┌────────▼────────┐</span><br><span class="line">│  🏗️ 中间层       │ │模拟仿真 │ │  🤝 多智能体    │</span><br><span class="line">│  环境适配层      │ │         │ │  协作层         │</span><br><span class="line">│ (Crafter,       │ │Generative│ │                │</span><br><span class="line">│  Minecraft)     │ │ Agents  │ │                │</span><br><span class="line">└─────────┬───────┘ └────┬────┘ └────────┬───────┘</span><br><span class="line">          │              │               │</span><br><span class="line">          └──────────────┼───────────────┘</span><br><span class="line">                         │</span><br><span class="line">                ┌────────▼────────┐</span><br><span class="line">                │  🔧 基础框架层   │</span><br><span class="line">                │                 │</span><br><span class="line">                │  • ReAct        │ ← 推理+行动范式</span><br><span class="line">                │  • Reflexion    │ ← 自我反思机制</span><br><span class="line">                │  • Grounding RL │ ← 环境交互学习</span><br><span class="line">                └─────────────────┘</span><br></pre></td></tr></table></figure>

<hr>
<h2 id="系列文章目录"><a href="#系列文章目录" class="headerlink" title="系列文章目录"></a>系列文章目录</h2><h3 id="基础框架篇"><a href="#基础框架篇" class="headerlink" title="基础框架篇"></a>基础框架篇</h3><table>
<thead>
<tr>
<th>文章</th>
<th>核心内容</th>
</tr>
</thead>
<tbody><tr>
<td><a href="/2025/12/28/LLM-Game-Agents-%E5%9F%BA%E7%A1%80%E6%A1%86%E6%9E%B6%E7%AF%87/">基础框架：ReAct / Reflexion / Generative Agents</a></td>
<td>三大核心框架的详细对比分析</td>
</tr>
</tbody></table>
<h3 id="应用扩展篇"><a href="#应用扩展篇" class="headerlink" title="应用扩展篇"></a>应用扩展篇</h3><table>
<thead>
<tr>
<th>文章</th>
<th>核心内容</th>
</tr>
</thead>
<tbody><tr>
<td><a href="/2025/12/28/LLM-Game-Agents-%E5%BA%94%E7%94%A8%E6%89%A9%E5%B1%95%E7%AF%87/">应用扩展：VOYAGER / Project Sid / Agent Hospital</a></td>
<td>终身学习、AI文明、医疗智能体</td>
</tr>
</tbody></table>
<hr>
<h2 id="研究脉络时间线"><a href="#研究脉络时间线" class="headerlink" title="研究脉络时间线"></a>研究脉络时间线</h2><h3 id="2023年：基础奠定"><a href="#2023年：基础奠定" class="headerlink" title="2023年：基础奠定"></a>2023年：基础奠定</h3><table>
<thead>
<tr>
<th>时间</th>
<th>论文</th>
<th>会议</th>
<th>核心贡献</th>
</tr>
</thead>
<tbody><tr>
<td>2022/10</td>
<td><strong>ReAct</strong></td>
<td>ICLR 2023</td>
<td>推理与行动协同范式</td>
</tr>
<tr>
<td>2023/03</td>
<td><strong>Reflexion</strong></td>
<td>NeurIPS 2023</td>
<td>语言反馈强化学习</td>
</tr>
<tr>
<td>2023/04</td>
<td><strong>Generative Agents</strong></td>
<td>UIST 2023</td>
<td>25智能体小镇模拟</td>
</tr>
<tr>
<td>2023/05</td>
<td><strong>VOYAGER</strong></td>
<td>NeurIPS 2023</td>
<td>Minecraft终身学习</td>
</tr>
</tbody></table>
<h3 id="2024年：深度发展"><a href="#2024年：深度发展" class="headerlink" title="2024年：深度发展"></a>2024年：深度发展</h3><table>
<thead>
<tr>
<th>时间</th>
<th>论文</th>
<th>核心贡献</th>
</tr>
</thead>
<tbody><tr>
<td>2024/05</td>
<td><strong>Agent Hospital</strong></td>
<td>可进化医疗智能体</td>
</tr>
<tr>
<td>2024/10</td>
<td><strong>Project Sid</strong></td>
<td>500-1000+智能体文明模拟</td>
</tr>
<tr>
<td>2024/10</td>
<td><strong>Claude Computer Use</strong></td>
<td>商业级计算机控制</td>
</tr>
</tbody></table>
<h3 id="2025年：产业化"><a href="#2025年：产业化" class="headerlink" title="2025年：产业化"></a>2025年：产业化</h3><table>
<thead>
<tr>
<th>时间</th>
<th>趋势</th>
<th>代表产品</th>
</tr>
</thead>
<tbody><tr>
<td>2025</td>
<td>Agent OS化</td>
<td>AutoGen, LangGraph</td>
</tr>
<tr>
<td>2025</td>
<td>商业化加速</td>
<td>OpenAI Operator</td>
</tr>
<tr>
<td>2025</td>
<td>多模态融合</td>
<td>视觉+语言+行动</td>
</tr>
</tbody></table>
<hr>
<h2 id="游戏类型与论文分布"><a href="#游戏类型与论文分布" class="headerlink" title="游戏类型与论文分布"></a>游戏类型与论文分布</h2><table>
<thead>
<tr>
<th>游戏类型</th>
<th>论文数</th>
<th>代表论文</th>
</tr>
</thead>
<tbody><tr>
<td>文字冒险</td>
<td>22</td>
<td>ReAct, Reflexion, ALFWorld</td>
</tr>
<tr>
<td>Minecraft</td>
<td>15</td>
<td>VOYAGER, GITM, JARVIS-1</td>
</tr>
<tr>
<td>社会模拟</td>
<td>12</td>
<td>Generative Agents, Project Sid</td>
</tr>
<tr>
<td>竞技游戏</td>
<td>15</td>
<td>PokéLLMon, StarCraft II</td>
</tr>
<tr>
<td>合作游戏</td>
<td>7</td>
<td>Co-LLM-Agents, TeamCraft</td>
</tr>
<tr>
<td>对话游戏</td>
<td>16</td>
<td>Werewolf, Avalon</td>
</tr>
</tbody></table>
<hr>
<h2 id="核心技术对比"><a href="#核心技术对比" class="headerlink" title="核心技术对比"></a>核心技术对比</h2><h3 id="记忆机制"><a href="#记忆机制" class="headerlink" title="记忆机制"></a>记忆机制</h3><table>
<thead>
<tr>
<th>方法</th>
<th>存储内容</th>
<th>检索方式</th>
<th>特点</th>
</tr>
</thead>
<tbody><tr>
<td><strong>VOYAGER</strong></td>
<td>可执行代码</td>
<td>语义相似度</td>
<td>技能可复用</td>
</tr>
<tr>
<td><strong>Generative Agents</strong></td>
<td>自然语言</td>
<td>时近性+重要性+相关性</td>
<td>多层抽象</td>
</tr>
<tr>
<td><strong>Reflexion</strong></td>
<td>语言化反思</td>
<td>时间顺序</td>
<td>失败学习</td>
</tr>
</tbody></table>
<h3 id="反思机制"><a href="#反思机制" class="headerlink" title="反思机制"></a>反思机制</h3><table>
<thead>
<tr>
<th>方法</th>
<th>触发条件</th>
<th>输出</th>
<th>目的</th>
</tr>
</thead>
<tbody><tr>
<td><strong>VOYAGER</strong></td>
<td>每轮执行后</td>
<td>成功/失败+批评</td>
<td>任务验证</td>
</tr>
<tr>
<td><strong>Generative Agents</strong></td>
<td>重要性&gt;150</td>
<td>高层次洞察</td>
<td>概念抽象</td>
</tr>
<tr>
<td><strong>Reflexion</strong></td>
<td>每次失败后</td>
<td>详细反思</td>
<td>错误诊断</td>
</tr>
</tbody></table>
<h3 id="学习方式"><a href="#学习方式" class="headerlink" title="学习方式"></a>学习方式</h3><table>
<thead>
<tr>
<th>方法</th>
<th>是否微调</th>
<th>知识形式</th>
<th>学习目标</th>
</tr>
</thead>
<tbody><tr>
<td><strong>传统RL</strong></td>
<td>✅ 梯度更新</td>
<td>策略网络</td>
<td>奖励最大化</td>
</tr>
<tr>
<td><strong>VOYAGER</strong></td>
<td>❌ 提示工程</td>
<td>代码技能库</td>
<td>技能积累</td>
</tr>
<tr>
<td><strong>Reflexion</strong></td>
<td>❌ 语言强化</td>
<td>反思记忆</td>
<td>任务成功率</td>
</tr>
</tbody></table>
<hr>
<h2 id="关键洞见"><a href="#关键洞见" class="headerlink" title="关键洞见"></a>关键洞见</h2><h3 id="1-无需微调的力量"><a href="#1-无需微调的力量" class="headerlink" title="1. 无需微调的力量"></a>1. 无需微调的力量</h3><p>三大核心框架（ReAct、Reflexion、Generative Agents）都证明：<strong>仅通过提示工程和运行时机制，无需微调模型参数，就能实现复杂的智能体行为</strong>。</p>
<h3 id="2-记忆是关键"><a href="#2-记忆是关键" class="headerlink" title="2. 记忆是关键"></a>2. 记忆是关键</h3><p>有效的记忆机制是智能体成功的基础：</p>
<ul>
<li><strong>VOYAGER</strong>：代码即记忆，技能可复用</li>
<li><strong>Generative Agents</strong>：记忆即人格，反思即成长</li>
<li><strong>Reflexion</strong>：反思即学习，失败即进步</li>
</ul>
<h3 id="3-协同优于孤立"><a href="#3-协同优于孤立" class="headerlink" title="3. 协同优于孤立"></a>3. 协同优于孤立</h3><table>
<thead>
<tr>
<th>单一能力</th>
<th>协同能力</th>
</tr>
</thead>
<tbody><tr>
<td>仅推理 → 幻觉严重</td>
<td>推理+行动 → ReAct</td>
</tr>
<tr>
<td>仅行动 → 无法规划</td>
<td>行动+反思 → Reflexion</td>
</tr>
<tr>
<td>单智能体 → 能力有限</td>
<td>多智能体 → 涌现社会行为</td>
</tr>
</tbody></table>
<h3 id="4-规模带来涌现"><a href="#4-规模带来涌现" class="headerlink" title="4. 规模带来涌现"></a>4. 规模带来涌现</h3><table>
<thead>
<tr>
<th>规模</th>
<th>涌现现象</th>
</tr>
</thead>
<tbody><tr>
<td>25 智能体</td>
<td>社交行为、信息传播 (Generative Agents)</td>
</tr>
<tr>
<td>50 智能体</td>
<td>长期关系、角色分化 (Project Sid)</td>
</tr>
<tr>
<td>500+ 智能体</td>
<td>文化传播、宗教涌现 (Project Sid)</td>
</tr>
</tbody></table>
<hr>
<h2 id="实践建议"><a href="#实践建议" class="headerlink" title="实践建议"></a>实践建议</h2><h3 id="场景匹配"><a href="#场景匹配" class="headerlink" title="场景匹配"></a>场景匹配</h3><table>
<thead>
<tr>
<th>场景</th>
<th>推荐方法</th>
<th>原因</th>
</tr>
</thead>
<tbody><tr>
<td>开放世界游戏</td>
<td>VOYAGER</td>
<td>技能可复用、可组合</td>
</tr>
<tr>
<td>社会模拟</td>
<td>Generative Agents</td>
<td>丰富记忆和人格一致性</td>
</tr>
<tr>
<td>决策任务</td>
<td>Reflexion</td>
<td>失败反思对决策优化关键</td>
</tr>
<tr>
<td>医疗/专业领域</td>
<td>Agent Hospital</td>
<td>可进化的专业智能体</td>
</tr>
</tbody></table>
<h3 id="组合架构"><a href="#组合架构" class="headerlink" title="组合架构"></a>组合架构</h3><p>理想的智能体应该结合三者优势：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">理想架构 = Generative Agents的记忆流</span><br><span class="line">         + VOYAGER的技能库</span><br><span class="line">         + Reflexion的失败反思</span><br></pre></td></tr></table></figure>

<hr>
<h2 id="工业趋势"><a href="#工业趋势" class="headerlink" title="工业趋势"></a>工业趋势</h2><h3 id="主要玩家"><a href="#主要玩家" class="headerlink" title="主要玩家"></a>主要玩家</h3><table>
<thead>
<tr>
<th>公司</th>
<th>产品</th>
<th>核心能力</th>
</tr>
</thead>
<tbody><tr>
<td>OpenAI</td>
<td>GPT-4V Agent, Operator</td>
<td>通用Agent能力</td>
</tr>
<tr>
<td>Anthropic</td>
<td>Claude Computer Use</td>
<td>计算机自主控制</td>
</tr>
<tr>
<td>Microsoft</td>
<td>AutoGen 0.4</td>
<td>企业级多Agent框架</td>
</tr>
<tr>
<td>Altera AI</td>
<td>Project Sid</td>
<td>AI文明模拟</td>
</tr>
</tbody></table>
<h3 id="开源生态"><a href="#开源生态" class="headerlink" title="开源生态"></a>开源生态</h3><table>
<thead>
<tr>
<th>框架</th>
<th>定位</th>
<th>热度</th>
</tr>
</thead>
<tbody><tr>
<td>AutoGen</td>
<td>多Agent对话与协作</td>
<td>🔥🔥🔥</td>
</tr>
<tr>
<td>LangGraph</td>
<td>状态机Agent工作流</td>
<td>🔥🔥🔥</td>
</tr>
<tr>
<td>MetaGPT</td>
<td>多角色软件开发</td>
<td>🔥🔥</td>
</tr>
<tr>
<td>CrewAI</td>
<td>角色扮演Agent团队</td>
<td>🔥🔥</td>
</tr>
</tbody></table>
<hr>
<h2 id="参考资源"><a href="#参考资源" class="headerlink" title="参考资源"></a>参考资源</h2><h3 id="论文列表"><a href="#论文列表" class="headerlink" title="论文列表"></a>论文列表</h3><ul>
<li><a target="_blank" rel="noopener" href="https://github.com/git-disl/awesome-LLM-game-agent-papers">awesome-LLM-game-agent-papers</a></li>
<li><a target="_blank" rel="noopener" href="https://arxiv.org/abs/2404.02039">A Survey on Large Language Model-Based Game Agents</a></li>
</ul>
<h3 id="代码仓库"><a href="#代码仓库" class="headerlink" title="代码仓库"></a>代码仓库</h3><table>
<thead>
<tr>
<th>论文</th>
<th>代码</th>
</tr>
</thead>
<tbody><tr>
<td>ReAct</td>
<td><a target="_blank" rel="noopener" href="https://github.com/ysymyth/ReAct">github.com/ysymyth/ReAct</a></td>
</tr>
<tr>
<td>Reflexion</td>
<td><a target="_blank" rel="noopener" href="https://github.com/noahshinn024/reflexion">github.com/noahshinn024/reflexion</a></td>
</tr>
<tr>
<td>Generative Agents</td>
<td><a target="_blank" rel="noopener" href="https://github.com/joonspk-research/generative_agents">github.com/joonspk-research/generative_agents</a></td>
</tr>
<tr>
<td>VOYAGER</td>
<td><a target="_blank" rel="noopener" href="https://voyager.minedojo.org/">voyager.minedojo.org</a></td>
</tr>
</tbody></table>
<hr>
<p><a href="/2025/12/28/LLM-Game-Agents-%E5%9F%BA%E7%A1%80%E6%A1%86%E6%9E%B6%E7%AF%87/">下一篇：基础框架篇</a> | <a href="/2025/12/28/LLM-Game-Agents-%E5%BA%94%E7%94%A8%E6%89%A9%E5%B1%95%E7%AF%87/">应用扩展篇</a></p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://foosynaptic.github.io/2025/12/28/DDIA-Part3-%E8%A1%8D%E7%94%9F%E6%95%B0%E6%8D%AE/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="fooSynaptic">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="fooSynaptic">
      <meta itemprop="description" content="Head first to the Truth as Synaptic.">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content=" | fooSynaptic">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2025/12/28/DDIA-Part3-%E8%A1%8D%E7%94%9F%E6%95%B0%E6%8D%AE/" class="post-title-link" itemprop="url">DDIA Part 3：衍生数据</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2025-12-28 02:03:00" itemprop="dateCreated datePublished" datetime="2025-12-28T02:03:00+08:00">2025-12-28</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/" itemprop="url" rel="index"><span itemprop="name">读书笔记</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <p>本文是 DDIA 第三部分的读书笔记，涵盖第 10-12 章：批处理、流处理、数据系统的未来。</p>
<hr>
<h2 id="第10章：批处理"><a href="#第10章：批处理" class="headerlink" title="第10章：批处理"></a>第10章：批处理</h2><h3 id="三种系统类型"><a href="#三种系统类型" class="headerlink" title="三种系统类型"></a>三种系统类型</h3><table>
<thead>
<tr>
<th>类型</th>
<th>特点</th>
<th>延迟</th>
<th>示例</th>
</tr>
</thead>
<tbody><tr>
<td>在线服务</td>
<td>请求-响应</td>
<td>毫秒</td>
<td>Web API</td>
</tr>
<tr>
<td>批处理</td>
<td>大量数据，高吞吐</td>
<td>分钟~小时</td>
<td>MapReduce</td>
</tr>
<tr>
<td>流处理</td>
<td>持续处理数据流</td>
<td>毫秒~秒</td>
<td>Kafka Streams</td>
</tr>
</tbody></table>
<h3 id="Unix-哲学"><a href="#Unix-哲学" class="headerlink" title="Unix 哲学"></a>Unix 哲学</h3><blockquote>
<p>每个程序做好一件事，输出可成为另一程序的输入</p>
</blockquote>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cat</span> access.log | </span><br><span class="line">  awk <span class="string">'{print $7}'</span> |    <span class="comment"># 提取 URL</span></span><br><span class="line">  <span class="built_in">sort</span> | <span class="built_in">uniq</span> -c |      <span class="comment"># 计数</span></span><br><span class="line">  <span class="built_in">sort</span> -rn | <span class="built_in">head</span> -10   <span class="comment"># 取前10</span></span><br></pre></td></tr></table></figure>

<h3 id="MapReduce"><a href="#MapReduce" class="headerlink" title="MapReduce"></a>MapReduce</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">输入 → Map → Shuffle(按键分组) → Reduce → 输出</span><br><span class="line"></span><br><span class="line">示例（词频统计）:</span><br><span class="line">输入: "hello world hello"</span><br><span class="line">Map:  (hello,1) (world,1) (hello,1)</span><br><span class="line">Shuffle: hello:[1,1], world:[1]</span><br><span class="line">Reduce: (hello,2) (world,1)</span><br></pre></td></tr></table></figure>

<p><strong>分布式执行</strong>：数据本地性原则，尽量在数据所在节点执行 Map</p>
<h3 id="Join-类型"><a href="#Join-类型" class="headerlink" title="Join 类型"></a>Join 类型</h3><table>
<thead>
<tr>
<th>类型</th>
<th>说明</th>
<th>适用场景</th>
</tr>
</thead>
<tbody><tr>
<td>Reduce 端 Join</td>
<td>Shuffle 后按键合并</td>
<td>通用</td>
</tr>
<tr>
<td>广播 Join</td>
<td>小表广播到所有 Map</td>
<td>大表 Join 小表</td>
</tr>
<tr>
<td>分区 Join</td>
<td>两表相同分区策略</td>
<td>预分区数据</td>
</tr>
</tbody></table>
<h3 id="现代批处理框架"><a href="#现代批处理框架" class="headerlink" title="现代批处理框架"></a>现代批处理框架</h3><table>
<thead>
<tr>
<th>框架</th>
<th>特点</th>
</tr>
</thead>
<tbody><tr>
<td><strong>Spark</strong></td>
<td>RDD 抽象，内存缓存，迭代友好</td>
</tr>
<tr>
<td><strong>Flink</strong></td>
<td>流批一体，增量处理</td>
</tr>
</tbody></table>
<p><strong>vs MapReduce</strong>：</p>
<table>
<thead>
<tr>
<th>方面</th>
<th>MapReduce</th>
<th>数据流引擎</th>
</tr>
</thead>
<tbody><tr>
<td>编程模型</td>
<td>Map/Reduce</td>
<td>任意 DAG</td>
</tr>
<tr>
<td>中间数据</td>
<td>写入 HDFS</td>
<td>内存流转</td>
</tr>
<tr>
<td>迭代支持</td>
<td>效率低</td>
<td>高效</td>
</tr>
</tbody></table>
<hr>
<h2 id="第11章：流处理"><a href="#第11章：流处理" class="headerlink" title="第11章：流处理"></a>第11章：流处理</h2><h3 id="批处理-vs-流处理"><a href="#批处理-vs-流处理" class="headerlink" title="批处理 vs 流处理"></a>批处理 vs 流处理</h3><table>
<thead>
<tr>
<th>方面</th>
<th>批处理</th>
<th>流处理</th>
</tr>
</thead>
<tbody><tr>
<td>数据</td>
<td>有界，静态</td>
<td>无界，持续到达</td>
</tr>
<tr>
<td>延迟</td>
<td>分钟~小时</td>
<td>毫秒~秒</td>
</tr>
<tr>
<td>结果</td>
<td>一次性输出</td>
<td>持续更新</td>
</tr>
</tbody></table>
<h3 id="消息系统"><a href="#消息系统" class="headerlink" title="消息系统"></a>消息系统</h3><p><strong>传统消息队列</strong> (RabbitMQ)：</p>
<ul>
<li>消息处理后删除</li>
<li>每条消息只被一个消费者处理</li>
</ul>
<p><strong>日志型消息系统</strong> (Kafka)：</p>
<ul>
<li>消息持久化，可重放</li>
<li>分区保序</li>
<li>多消费者组独立消费</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">分区0: [msg0][msg3][msg6] → 消费者A</span><br><span class="line">分区1: [msg1][msg4][msg7] → 消费者B</span><br><span class="line">分区2: [msg2][msg5][msg8] → 消费者C</span><br></pre></td></tr></table></figure>

<h3 id="变更数据捕获-CDC"><a href="#变更数据捕获-CDC" class="headerlink" title="变更数据捕获 (CDC)"></a>变更数据捕获 (CDC)</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">应用 → 数据库 → CDC工具(Debezium) → Kafka → 派生系统</span><br></pre></td></tr></table></figure>

<p><strong>应用</strong>：同步搜索索引、微服务集成、实时 ETL</p>
<h3 id="事件溯源"><a href="#事件溯源" class="headerlink" title="事件溯源"></a>事件溯源</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">传统方式：只存当前状态</span><br><span class="line">┌ balance = 1000 ┐</span><br><span class="line"></span><br><span class="line">事件溯源：存储所有事件</span><br><span class="line">│ 1. 创建账户 balance=0    │</span><br><span class="line">│ 2. 存款 +500             │</span><br><span class="line">│ 3. 存款 +800             │</span><br><span class="line">│ 4. 取款 -300             │</span><br><span class="line">└ 当前: 0+500+800-300=1000 ┘</span><br></pre></td></tr></table></figure>

<p><strong>优势</strong>：完整审计、可重放、调试友好</p>
<h3 id="时间语义"><a href="#时间语义" class="headerlink" title="时间语义"></a>时间语义</h3><table>
<thead>
<tr>
<th>类型</th>
<th>定义</th>
</tr>
</thead>
<tbody><tr>
<td>事件时间</td>
<td>事件实际发生的时间</td>
</tr>
<tr>
<td>处理时间</td>
<td>事件到达处理器的时间</td>
</tr>
</tbody></table>
<h3 id="窗口类型"><a href="#窗口类型" class="headerlink" title="窗口类型"></a>窗口类型</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">滚动窗口：┌──┐┌──┐┌──┐ (固定大小，不重叠)</span><br><span class="line">滑动窗口：┌────┐</span><br><span class="line">            ┌────┐</span><br><span class="line">              ┌────┐  (固定大小，可重叠)</span><br><span class="line">会话窗口：┌──┐   ┌─────┐  ┌─┐ (基于活动间隙)</span><br></pre></td></tr></table></figure>

<h3 id="水位线-Watermark"><a href="#水位线-Watermark" class="headerlink" title="水位线 (Watermark)"></a>水位线 (Watermark)</h3><blockquote>
<p>不会再有 ≤ 该时间的事件到达</p>
</blockquote>
<p><strong>迟到事件处理</strong>：丢弃、更新结果、侧输出</p>
<h3 id="流处理框架"><a href="#流处理框架" class="headerlink" title="流处理框架"></a>流处理框架</h3><table>
<thead>
<tr>
<th>框架</th>
<th>特点</th>
</tr>
</thead>
<tbody><tr>
<td>Kafka Streams</td>
<td>轻量级库，与 Kafka 紧密集成</td>
</tr>
<tr>
<td>Flink</td>
<td>真正的流处理，强一致性</td>
</tr>
<tr>
<td>Spark Streaming</td>
<td>微批处理</td>
</tr>
</tbody></table>
<h3 id="流表对偶"><a href="#流表对偶" class="headerlink" title="流表对偶"></a>流表对偶</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">流 → 表：聚合/累积（物化视图）</span><br><span class="line">表 → 流：捕获变更（变更日志）</span><br></pre></td></tr></table></figure>

<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">-- KSQL: 流转表</span></span><br><span class="line"><span class="keyword">CREATE TABLE</span> page_counts <span class="keyword">AS</span></span><br><span class="line">  <span class="keyword">SELECT</span> page_id, <span class="built_in">COUNT</span>(<span class="operator">*</span>) <span class="keyword">as</span> views</span><br><span class="line">  <span class="keyword">FROM</span> pageviews</span><br><span class="line">  <span class="keyword">GROUP</span> <span class="keyword">BY</span> page_id;</span><br></pre></td></tr></table></figure>

<hr>
<h2 id="第12章：数据系统的未来"><a href="#第12章：数据系统的未来" class="headerlink" title="第12章：数据系统的未来"></a>第12章：数据系统的未来</h2><h3 id="数据集成"><a href="#数据集成" class="headerlink" title="数据集成"></a>数据集成</h3><p><strong>现状</strong>：多种专用工具（PostgreSQL + Redis + ES + Kafka）</p>
<p><strong>以日志为中心的架构</strong>：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">写入 → 事件日志(Kafka) → 数据库</span><br><span class="line">              ↓        → 搜索索引</span><br><span class="line">                       → 缓存</span><br></pre></td></tr></table></figure>

<p><strong>Lambda vs Kappa</strong>：</p>
<table>
<thead>
<tr>
<th>架构</th>
<th>特点</th>
</tr>
</thead>
<tbody><tr>
<td>Lambda</td>
<td>批处理+流处理双路径，需维护两套代码</td>
</tr>
<tr>
<td>Kappa</td>
<td>只用流处理，日志保留足够长支持重放</td>
</tr>
</tbody></table>
<h3 id="分拆数据库"><a href="#分拆数据库" class="headerlink" title="分拆数据库"></a>分拆数据库</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">传统数据库 = 存储 + 事务 + 索引 + 复制 + 查询优化</span><br><span class="line"></span><br><span class="line">分拆后：</span><br><span class="line">Kafka(日志) → Flink(处理) → RocksDB(存储)</span><br><span class="line">每个组件专注一件事</span><br></pre></td></tr></table></figure>

<p><strong>主数据 vs 衍生数据</strong>：</p>
<table>
<thead>
<tr>
<th>类型</th>
<th>说明</th>
</tr>
</thead>
<tbody><tr>
<td>主数据</td>
<td>真相来源，写入时的输入</td>
</tr>
<tr>
<td>衍生数据</td>
<td>从主数据计算，可重建（索引、缓存）</td>
</tr>
</tbody></table>
<h3 id="端到端正确性"><a href="#端到端正确性" class="headerlink" title="端到端正确性"></a>端到端正确性</h3><p><strong>幂等性</strong>：执行多次与执行一次效果相同</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">幂等：SET x = 5</span><br><span class="line">非幂等：INCR x（需要去重）</span><br></pre></td></tr></table></figure>

<p><strong>端到端论证</strong>：只在每层保证正确不够，需在最终用户层面验证</p>
<h3 id="审计与可追溯"><a href="#审计与可追溯" class="headerlink" title="审计与可追溯"></a>审计与可追溯</h3><p><strong>不可变日志的优势</strong>：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">传统：UPDATE email='new@...'（历史丢失）</span><br><span class="line">事件日志：</span><br><span class="line">  1. 注册 email='old@...'</span><br><span class="line">  2. 更新 email='new@...'（完整历史）</span><br></pre></td></tr></table></figure>

<h3 id="伦理考量"><a href="#伦理考量" class="headerlink" title="伦理考量"></a>伦理考量</h3><table>
<thead>
<tr>
<th>问题</th>
<th>考量</th>
</tr>
</thead>
<tbody><tr>
<td>隐私</td>
<td>收集什么数据？用于什么？</td>
</tr>
<tr>
<td>偏见</td>
<td>算法是否存在歧视？</td>
</tr>
<tr>
<td>透明度</td>
<td>用户能否理解决策过程？</td>
</tr>
<tr>
<td>问责</td>
<td>出错时谁负责？</td>
</tr>
</tbody></table>
<h3 id="设计原则"><a href="#设计原则" class="headerlink" title="设计原则"></a>设计原则</h3><table>
<thead>
<tr>
<th>原则</th>
<th>说明</th>
</tr>
</thead>
<tbody><tr>
<td>简单性</td>
<td>避免不必要的复杂性</td>
</tr>
<tr>
<td>可组合性</td>
<td>使用可组合的组件</td>
</tr>
<tr>
<td>可观测性</td>
<td>便于理解系统行为</td>
</tr>
<tr>
<td>可演化性</td>
<td>能适应变化的需求</td>
</tr>
</tbody></table>
<h3 id="未来趋势"><a href="#未来趋势" class="headerlink" title="未来趋势"></a>未来趋势</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">1. 流批一体：批处理 = 有界流</span><br><span class="line">2. 声明式数据管理：描述想要什么</span><br><span class="line">3. 自动化运维：自动调优、扩缩容</span><br><span class="line">4. 边缘计算：数据处理靠近产生地</span><br></pre></td></tr></table></figure>

<hr>
<h2 id="全书总结"><a href="#全书总结" class="headerlink" title="全书总结"></a>全书总结</h2><h3 id="核心主题"><a href="#核心主题" class="headerlink" title="核心主题"></a>核心主题</h3><table>
<thead>
<tr>
<th>主题</th>
<th>章节</th>
<th>要点</th>
</tr>
</thead>
<tbody><tr>
<td>数据存储</td>
<td>2, 3, 4</td>
<td>选择合适的数据模型和存储引擎</td>
</tr>
<tr>
<td>分布式</td>
<td>5-9</td>
<td>理解分布式系统的权衡</td>
</tr>
<tr>
<td>数据处理</td>
<td>10, 11</td>
<td>批处理与流处理的统一</td>
</tr>
<tr>
<td>系统设计</td>
<td>1, 12</td>
<td>可靠、可扩展、可维护</td>
</tr>
</tbody></table>
<h3 id="关键要点"><a href="#关键要点" class="headerlink" title="关键要点"></a>关键要点</h3><ol>
<li><strong>没有银弹</strong>：不同工具适合不同场景</li>
<li><strong>日志是关键</strong>：事件日志是数据集成的基础</li>
<li><strong>衍生数据可重建</strong>：主数据是真相来源</li>
<li><strong>端到端正确性</strong>：只在某一层保证不够</li>
<li><strong>技术选择有社会影响</strong>：需要考虑伦理问题</li>
<li><strong>简单性是美德</strong>：避免不必要的复杂性</li>
</ol>
<hr>
<h2 id="推荐阅读"><a href="#推荐阅读" class="headerlink" title="推荐阅读"></a>推荐阅读</h2><table>
<thead>
<tr>
<th>书籍</th>
<th>主题</th>
</tr>
</thead>
<tbody><tr>
<td>《Database Internals》</td>
<td>数据库内部原理</td>
</tr>
<tr>
<td>《Streaming Systems》</td>
<td>流处理深入</td>
</tr>
<tr>
<td>《Building Microservices》</td>
<td>微服务架构</td>
</tr>
<tr>
<td>《Clean Architecture》</td>
<td>软件架构</td>
</tr>
</tbody></table>
<hr>
<p><a href="/2025/12/28/DDIA-Part2-%E5%88%86%E5%B8%83%E5%BC%8F%E6%95%B0%E6%8D%AE/">上一部分：分布式数据</a> | <a href="/2025/12/28/DDIA-%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0-%E6%80%BB%E8%A7%88/">返回总览</a></p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://foosynaptic.github.io/2025/12/28/DDIA-Part2-%E5%88%86%E5%B8%83%E5%BC%8F%E6%95%B0%E6%8D%AE/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="fooSynaptic">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="fooSynaptic">
      <meta itemprop="description" content="Head first to the Truth as Synaptic.">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content=" | fooSynaptic">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2025/12/28/DDIA-Part2-%E5%88%86%E5%B8%83%E5%BC%8F%E6%95%B0%E6%8D%AE/" class="post-title-link" itemprop="url">DDIA Part 2：分布式数据</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2025-12-28 02:02:00" itemprop="dateCreated datePublished" datetime="2025-12-28T02:02:00+08:00">2025-12-28</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/" itemprop="url" rel="index"><span itemprop="name">读书笔记</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <p>本文是 DDIA 第二部分的读书笔记，涵盖第 5-9 章：数据复制、分区、事务、分布式挑战、一致性与共识。</p>
<hr>
<h2 id="第5章：数据复制"><a href="#第5章：数据复制" class="headerlink" title="第5章：数据复制"></a>第5章：数据复制</h2><h3 id="复制的目的"><a href="#复制的目的" class="headerlink" title="复制的目的"></a>复制的目的</h3><table>
<thead>
<tr>
<th>目的</th>
<th>说明</th>
</tr>
</thead>
<tbody><tr>
<td>高可用性</td>
<td>部分节点故障时系统仍可用</td>
</tr>
<tr>
<td>降低延迟</td>
<td>数据放在离用户更近的地方</td>
</tr>
<tr>
<td>提高读吞吐</td>
<td>多个副本并行处理读请求</td>
</tr>
</tbody></table>
<h3 id="主从复制"><a href="#主从复制" class="headerlink" title="主从复制"></a>主从复制</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">客户端 ──写入──&gt; 主节点 ──复制日志──&gt; 从节点1</span><br><span class="line">                              └──&gt; 从节点2</span><br></pre></td></tr></table></figure>

<p><strong>同步 vs 异步复制</strong>：</p>
<table>
<thead>
<tr>
<th>方式</th>
<th>优点</th>
<th>缺点</th>
</tr>
</thead>
<tbody><tr>
<td>同步</td>
<td>数据一致</td>
<td>延迟高，可用性差</td>
</tr>
<tr>
<td>异步</td>
<td>延迟低</td>
<td>可能数据丢失</td>
</tr>
<tr>
<td>半同步</td>
<td>平衡</td>
<td>实现复杂</td>
</tr>
</tbody></table>
<h3 id="复制延迟问题"><a href="#复制延迟问题" class="headerlink" title="复制延迟问题"></a>复制延迟问题</h3><table>
<thead>
<tr>
<th>问题</th>
<th>说明</th>
<th>解决方案</th>
</tr>
</thead>
<tbody><tr>
<td>读己之写</td>
<td>写后读可能读到旧数据</td>
<td>修改的数据从主节点读</td>
</tr>
<tr>
<td>单调读</td>
<td>刷新后可能看到更旧的数据</td>
<td>每个用户固定副本</td>
</tr>
<tr>
<td>一致前缀读</td>
<td>因果关系被打乱</td>
<td>相关写入同一分区</td>
</tr>
</tbody></table>
<h3 id="多主复制"><a href="#多主复制" class="headerlink" title="多主复制"></a>多主复制</h3><p><strong>适用场景</strong>：多数据中心、离线客户端、协作编辑</p>
<p><strong>写冲突解决</strong>：</p>
<table>
<thead>
<tr>
<th>策略</th>
<th>说明</th>
</tr>
</thead>
<tbody><tr>
<td>最后写入胜出 (LWW)</td>
<td>时间戳最新的覆盖</td>
</tr>
<tr>
<td>合并值</td>
<td>如拼接 “A/B”</td>
</tr>
<tr>
<td>CRDT</td>
<td>特殊数据结构自动合并</td>
</tr>
<tr>
<td>提示用户</td>
<td>类似 Git 冲突</td>
</tr>
</tbody></table>
<h3 id="无主复制-Dynamo-风格"><a href="#无主复制-Dynamo-风格" class="headerlink" title="无主复制 (Dynamo 风格)"></a>无主复制 (Dynamo 风格)</h3><p><strong>Quorum 公式</strong>：<mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.186ex;" xmlns="http://www.w3.org/2000/svg" width="11.88ex" height="1.731ex" role="img" focusable="false" viewBox="0 -683 5251 765"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D44A" d="M436 683Q450 683 486 682T553 680Q604 680 638 681T677 682Q695 682 695 674Q695 670 692 659Q687 641 683 639T661 637Q636 636 621 632T600 624T597 615Q597 603 613 377T629 138L631 141Q633 144 637 151T649 170T666 200T690 241T720 295T759 362Q863 546 877 572T892 604Q892 619 873 628T831 637Q817 637 817 647Q817 650 819 660Q823 676 825 679T839 682Q842 682 856 682T895 682T949 681Q1015 681 1034 683Q1048 683 1048 672Q1048 666 1045 655T1038 640T1028 637Q1006 637 988 631T958 617T939 600T927 584L923 578L754 282Q586 -14 585 -15Q579 -22 561 -22Q546 -22 542 -17Q539 -14 523 229T506 480L494 462Q472 425 366 239Q222 -13 220 -15T215 -19Q210 -22 197 -22Q178 -22 176 -15Q176 -12 154 304T131 622Q129 631 121 633T82 637H58Q51 644 51 648Q52 671 64 683H76Q118 680 176 680Q301 680 313 683H323Q329 677 329 674T327 656Q322 641 318 637H297Q236 634 232 620Q262 160 266 136L501 550L499 587Q496 629 489 632Q483 636 447 637Q428 637 422 639T416 648Q416 650 418 660Q419 664 420 669T421 676T424 680T428 682T436 683Z"></path></g><g data-mml-node="mo" transform="translate(1270.2,0)"><path data-c="2B" d="M56 237T56 250T70 270H369V420L370 570Q380 583 389 583Q402 583 409 568V270H707Q722 262 722 250T707 230H409V-68Q401 -82 391 -82H389H387Q375 -82 369 -68V230H70Q56 237 56 250Z"></path></g><g data-mml-node="mi" transform="translate(2270.4,0)"><path data-c="1D445" d="M230 637Q203 637 198 638T193 649Q193 676 204 682Q206 683 378 683Q550 682 564 680Q620 672 658 652T712 606T733 563T739 529Q739 484 710 445T643 385T576 351T538 338L545 333Q612 295 612 223Q612 212 607 162T602 80V71Q602 53 603 43T614 25T640 16Q668 16 686 38T712 85Q717 99 720 102T735 105Q755 105 755 93Q755 75 731 36Q693 -21 641 -21H632Q571 -21 531 4T487 82Q487 109 502 166T517 239Q517 290 474 313Q459 320 449 321T378 323H309L277 193Q244 61 244 59Q244 55 245 54T252 50T269 48T302 46H333Q339 38 339 37T336 19Q332 6 326 0H311Q275 2 180 2Q146 2 117 2T71 2T50 1Q33 1 33 10Q33 12 36 24Q41 43 46 45Q50 46 61 46H67Q94 46 127 49Q141 52 146 61Q149 65 218 339T287 628Q287 635 230 637ZM630 554Q630 586 609 608T523 636Q521 636 500 636T462 637H440Q393 637 386 627Q385 624 352 494T319 361Q319 360 388 360Q466 361 492 367Q556 377 592 426Q608 449 619 486T630 554Z"></path></g><g data-mml-node="mo" transform="translate(3307.2,0)"><path data-c="3E" d="M84 520Q84 528 88 533T96 539L99 540Q106 540 253 471T544 334L687 265Q694 260 694 250T687 235Q685 233 395 96L107 -40H101Q83 -38 83 -20Q83 -19 83 -17Q82 -10 98 -1Q117 9 248 71Q326 108 378 132L626 250L378 368Q90 504 86 509Q84 513 84 520Z"></path></g><g data-mml-node="mi" transform="translate(4363,0)"><path data-c="1D441" d="M234 637Q231 637 226 637Q201 637 196 638T191 649Q191 676 202 682Q204 683 299 683Q376 683 387 683T401 677Q612 181 616 168L670 381Q723 592 723 606Q723 633 659 637Q635 637 635 648Q635 650 637 660Q641 676 643 679T653 683Q656 683 684 682T767 680Q817 680 843 681T873 682Q888 682 888 672Q888 650 880 642Q878 637 858 637Q787 633 769 597L620 7Q618 0 599 0Q585 0 582 2Q579 5 453 305L326 604L261 344Q196 88 196 79Q201 46 268 46H278Q284 41 284 38T282 19Q278 6 272 0H259Q228 2 151 2Q123 2 100 2T63 2T46 1Q31 1 31 10Q31 14 34 26T39 40Q41 46 62 46Q130 49 150 85Q154 91 221 362L289 634Q287 635 234 637Z"></path></g></g></g></svg></mjx-container></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">N=3, W=2, R=2:</span><br><span class="line">写入需要 2 个副本确认</span><br><span class="line">读取需要查询 2 个副本</span><br><span class="line">至少 1 个副本既写入又读取，保证读到最新值</span><br></pre></td></tr></table></figure>

<hr>
<h2 id="第6章：数据分区"><a href="#第6章：数据分区" class="headerlink" title="第6章：数据分区"></a>第6章：数据分区</h2><h3 id="分区策略"><a href="#分区策略" class="headerlink" title="分区策略"></a>分区策略</h3><table>
<thead>
<tr>
<th>策略</th>
<th>优点</th>
<th>缺点</th>
</tr>
</thead>
<tbody><tr>
<td>按键范围</td>
<td>支持范围查询</td>
<td>可能热点</td>
</tr>
<tr>
<td>按键哈希</td>
<td>分布均匀</td>
<td>失去范围查询</td>
</tr>
</tbody></table>
<p><strong>一致性哈希</strong>：添加/删除节点只影响相邻区间</p>
<h3 id="热点问题"><a href="#热点问题" class="headerlink" title="热点问题"></a>热点问题</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">明星发微博 → 所有请求发往同一分区</span><br></pre></td></tr></table></figure>

<p><strong>解决方案</strong>：拆分热键（添加随机后缀）、本地缓存、限流</p>
<h3 id="二级索引分区"><a href="#二级索引分区" class="headerlink" title="二级索引分区"></a>二级索引分区</h3><table>
<thead>
<tr>
<th>类型</th>
<th>特点</th>
</tr>
</thead>
<tbody><tr>
<td>本地索引</td>
<td>每分区维护自己的索引，查询需 scatter/gather</td>
</tr>
<tr>
<td>全局索引</td>
<td>索引本身分区，读快写慢（异步更新）</td>
</tr>
</tbody></table>
<h3 id="再平衡策略"><a href="#再平衡策略" class="headerlink" title="再平衡策略"></a>再平衡策略</h3><table>
<thead>
<tr>
<th>策略</th>
<th>说明</th>
<th>产品示例</th>
</tr>
</thead>
<tbody><tr>
<td>固定分区数</td>
<td>预创建大量分区</td>
<td>Elasticsearch</td>
</tr>
<tr>
<td>动态分区</td>
<td>自动拆分合并</td>
<td>HBase</td>
</tr>
<tr>
<td>按节点比例</td>
<td>每节点固定分区数</td>
<td>Cassandra</td>
</tr>
</tbody></table>
<h3 id="请求路由"><a href="#请求路由" class="headerlink" title="请求路由"></a>请求路由</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">方案1: 客户端直连任意节点 → 转发</span><br><span class="line">方案2: 路由层（知道分区映射）</span><br><span class="line">方案3: 客户端感知分区（如使用 ZooKeeper）</span><br></pre></td></tr></table></figure>

<hr>
<h2 id="第7章：事务"><a href="#第7章：事务" class="headerlink" title="第7章：事务"></a>第7章：事务</h2><h3 id="ACID-特性"><a href="#ACID-特性" class="headerlink" title="ACID 特性"></a>ACID 特性</h3><table>
<thead>
<tr>
<th>特性</th>
<th>含义</th>
</tr>
</thead>
<tbody><tr>
<td>原子性</td>
<td>全部成功或全部失败</td>
</tr>
<tr>
<td>一致性</td>
<td>从有效状态到有效状态</td>
</tr>
<tr>
<td>隔离性</td>
<td>并发事务互不干扰</td>
</tr>
<tr>
<td>持久性</td>
<td>提交后数据不丢失</td>
</tr>
</tbody></table>
<h3 id="隔离级别"><a href="#隔离级别" class="headerlink" title="隔离级别"></a>隔离级别</h3><table>
<thead>
<tr>
<th>级别</th>
<th>防止问题</th>
</tr>
</thead>
<tbody><tr>
<td>读已提交</td>
<td>脏读、脏写</td>
</tr>
<tr>
<td>快照隔离</td>
<td>不可重复读</td>
</tr>
<tr>
<td>串行化</td>
<td>所有并发异常</td>
</tr>
</tbody></table>
<h3 id="丢失更新问题"><a href="#丢失更新问题" class="headerlink" title="丢失更新问题"></a>丢失更新问题</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">事务1: 读取 counter=10     写入 counter=11</span><br><span class="line">事务2:      读取 counter=10        写入 counter=11</span><br><span class="line">期望: 12，实际: 11（事务1的更新丢失）</span><br></pre></td></tr></table></figure>

<p><strong>解决</strong>：原子操作、显式锁定、Compare-and-Set</p>
<h3 id="写偏斜"><a href="#写偏斜" class="headerlink" title="写偏斜"></a>写偏斜</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">医院规则：至少1名医生值班</span><br><span class="line">Alice 查询：2人值班，取消自己</span><br><span class="line">Bob 同时：2人值班，取消自己</span><br><span class="line">结果：无人值班！</span><br></pre></td></tr></table></figure>

<p><strong>解决</strong>：串行化隔离、物化冲突、显式锁定</p>
<h3 id="串行化实现"><a href="#串行化实现" class="headerlink" title="串行化实现"></a>串行化实现</h3><table>
<thead>
<tr>
<th>方式</th>
<th>特点</th>
<th>产品</th>
</tr>
</thead>
<tbody><tr>
<td>实际串行</td>
<td>单线程执行</td>
<td>Redis, VoltDB</td>
</tr>
<tr>
<td>两阶段锁 (2PL)</td>
<td>读写互斥</td>
<td>传统数据库</td>
</tr>
<tr>
<td>串行化快照隔离 (SSI)</td>
<td>乐观并发</td>
<td>PostgreSQL 9.1+</td>
</tr>
</tbody></table>
<h3 id="分布式事务-2PC"><a href="#分布式事务-2PC" class="headerlink" title="分布式事务 (2PC)"></a>分布式事务 (2PC)</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">阶段1: 协调者 ──准备?──&gt; 所有参与者</span><br><span class="line">阶段2: 协调者 ──提交/回滚──&gt; 所有参与者</span><br><span class="line"></span><br><span class="line">问题：协调者故障时参与者阻塞</span><br></pre></td></tr></table></figure>

<hr>
<h2 id="第8章：分布式系统的挑战"><a href="#第8章：分布式系统的挑战" class="headerlink" title="第8章：分布式系统的挑战"></a>第8章：分布式系统的挑战</h2><h3 id="部分失效"><a href="#部分失效" class="headerlink" title="部分失效"></a>部分失效</h3><table>
<thead>
<tr>
<th>单机系统</th>
<th>分布式系统</th>
</tr>
</thead>
<tbody><tr>
<td>要么工作要么不工作</td>
<td>部分可能工作</td>
</tr>
<tr>
<td>故障通常完全</td>
<td>故障通常部分</td>
</tr>
</tbody></table>
<h3 id="不可靠的网络"><a href="#不可靠的网络" class="headerlink" title="不可靠的网络"></a>不可靠的网络</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">请求可能：丢失、延迟、重复</span><br><span class="line">响应可能：丢失、延迟</span><br><span class="line">无法区分：网络故障 vs 节点故障</span><br></pre></td></tr></table></figure>

<p><strong>超时困境</strong>：太短误判正常节点，太长恢复慢</p>
<h3 id="不可靠的时钟"><a href="#不可靠的时钟" class="headerlink" title="不可靠的时钟"></a>不可靠的时钟</h3><table>
<thead>
<tr>
<th>时钟类型</th>
<th>用途</th>
</tr>
</thead>
<tbody><tr>
<td>日历时钟</td>
<td>当前时间（可能跳跃）</td>
</tr>
<tr>
<td>单调时钟</td>
<td>测量持续时间（保证递增）</td>
</tr>
</tbody></table>
<p><strong>LWW 的风险</strong>：时钟不同步导致新数据被旧数据覆盖</p>
<h3 id="Fencing-Token"><a href="#Fencing-Token" class="headerlink" title="Fencing Token"></a>Fencing Token</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">节点A 获取锁 token=33 → 暂停</span><br><span class="line">节点B 获取锁 token=34 → 写入成功</span><br><span class="line">节点A 恢复 token=33 → 被拒绝（33 &lt; 34）</span><br></pre></td></tr></table></figure>

<h3 id="系统模型"><a href="#系统模型" class="headerlink" title="系统模型"></a>系统模型</h3><table>
<thead>
<tr>
<th>时序假设</th>
<th>节点故障假设</th>
</tr>
</thead>
<tbody><tr>
<td>同步/部分同步/异步</td>
<td>崩溃-停止/崩溃-恢复/拜占庭</td>
</tr>
</tbody></table>
<p><strong>正确性</strong>：安全性（坏事不发生） + 活性（好事最终发生）</p>
<hr>
<h2 id="第9章：一致性与共识"><a href="#第9章：一致性与共识" class="headerlink" title="第9章：一致性与共识"></a>第9章：一致性与共识</h2><h3 id="一致性模型"><a href="#一致性模型" class="headerlink" title="一致性模型"></a>一致性模型</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">弱 ←─────────────────────────────────→ 强</span><br><span class="line"></span><br><span class="line">最终一致性    因果一致性    顺序一致性    线性一致性</span><br></pre></td></tr></table></figure>

<h3 id="线性一致性"><a href="#线性一致性" class="headerlink" title="线性一致性"></a>线性一致性</h3><blockquote>
<p>系统表现得好像只有一个数据副本，所有操作都是原子的</p>
</blockquote>
<p><strong>应用</strong>：分布式锁、领导者选举、唯一性约束</p>
<h3 id="CAP-定理"><a href="#CAP-定理" class="headerlink" title="CAP 定理"></a>CAP 定理</h3><p><mjx-container class="MathJax" jax="SVG" display="true"><svg style="vertical-align: -0.452ex;" xmlns="http://www.w3.org/2000/svg" width="38.462ex" height="2.149ex" role="img" focusable="false" viewBox="0 -750 17000 950"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mtext"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">网</text><text data-variant="normal" transform="translate(1000,0) scale(1,-1)" font-size="884px" font-family="serif">络</text><text data-variant="normal" transform="translate(2000,0) scale(1,-1)" font-size="884px" font-family="serif">分</text><text data-variant="normal" transform="translate(3000,0) scale(1,-1)" font-size="884px" font-family="serif">区</text><text data-variant="normal" transform="translate(4000,0) scale(1,-1)" font-size="884px" font-family="serif">时</text><text data-variant="normal" transform="translate(5000,0) scale(1,-1)" font-size="884px" font-family="serif">，</text><text data-variant="normal" transform="translate(6000,0) scale(1,-1)" font-size="884px" font-family="serif">一</text><text data-variant="normal" transform="translate(7000,0) scale(1,-1)" font-size="884px" font-family="serif">致</text><text data-variant="normal" transform="translate(8000,0) scale(1,-1)" font-size="884px" font-family="serif">性</text><text data-variant="normal" transform="translate(9000,0) scale(1,-1)" font-size="884px" font-family="serif">与</text><text data-variant="normal" transform="translate(10000,0) scale(1,-1)" font-size="884px" font-family="serif">可</text><text data-variant="normal" transform="translate(11000,0) scale(1,-1)" font-size="884px" font-family="serif">用</text><text data-variant="normal" transform="translate(12000,0) scale(1,-1)" font-size="884px" font-family="serif">性</text><text data-variant="normal" transform="translate(13000,0) scale(1,-1)" font-size="884px" font-family="serif">不</text><text data-variant="normal" transform="translate(14000,0) scale(1,-1)" font-size="884px" font-family="serif">可</text><text data-variant="normal" transform="translate(15000,0) scale(1,-1)" font-size="884px" font-family="serif">兼</text><text data-variant="normal" transform="translate(16000,0) scale(1,-1)" font-size="884px" font-family="serif">得</text></g></g></g></svg></mjx-container></p>
<table>
<thead>
<tr>
<th>选择</th>
<th>含义</th>
</tr>
</thead>
<tbody><tr>
<td>CP</td>
<td>保证一致性，牺牲可用性</td>
</tr>
<tr>
<td>AP</td>
<td>保证可用性，牺牲一致性</td>
</tr>
</tbody></table>
<h3 id="共识问题"><a href="#共识问题" class="headerlink" title="共识问题"></a>共识问题</h3><blockquote>
<p>多个节点就某个值达成一致</p>
</blockquote>
<p><strong>性质</strong>：一致同意、完整性、终止性、有效性</p>
<p><strong>FLP 不可能定理</strong>：异步系统中存在故障节点时，不存在总能达成共识的算法</p>
<h3 id="Paxos-算法"><a href="#Paxos-算法" class="headerlink" title="Paxos 算法"></a>Paxos 算法</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">阶段1 (Prepare):</span><br><span class="line">提议者 ──Prepare(n)──&gt; 接受者</span><br><span class="line">        &lt;──Promise──</span><br><span class="line"></span><br><span class="line">阶段2 (Accept):</span><br><span class="line">提议者 ──Accept(n,v)──&gt; 接受者</span><br><span class="line">        &lt;──Accepted──</span><br></pre></td></tr></table></figure>

<h3 id="Raft-算法"><a href="#Raft-算法" class="headerlink" title="Raft 算法"></a>Raft 算法</h3><p><strong>比 Paxos 更易理解</strong></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">角色：领导者、跟随者、候选人</span><br><span class="line">任期：逻辑时钟，每次选举递增</span><br><span class="line"></span><br><span class="line">选举流程：</span><br><span class="line">1. 跟随者超时 → 变候选人</span><br><span class="line">2. 请求投票 → 获多数票</span><br><span class="line">3. 成为领导者 → 复制日志</span><br></pre></td></tr></table></figure>

<h3 id="共识的应用"><a href="#共识的应用" class="headerlink" title="共识的应用"></a>共识的应用</h3><table>
<thead>
<tr>
<th>产品</th>
<th>用途</th>
</tr>
</thead>
<tbody><tr>
<td>ZooKeeper</td>
<td>协调服务、配置管理</td>
</tr>
<tr>
<td>etcd</td>
<td>Kubernetes 状态存储</td>
</tr>
<tr>
<td>Consul</td>
<td>服务发现</td>
</tr>
</tbody></table>
<hr>
<h2 id="本部分要点总结"><a href="#本部分要点总结" class="headerlink" title="本部分要点总结"></a>本部分要点总结</h2><ol>
<li><strong>复制的核心挑战是处理数据变更</strong></li>
<li><strong>分区策略需要权衡范围查询和负载均衡</strong></li>
<li><strong>事务隔离级别是正确性和性能的权衡</strong></li>
<li><strong>分布式系统的核心挑战是部分失效</strong></li>
<li><strong>线性一致性是最强保证，但代价高昂</strong></li>
<li><strong>Raft 比 Paxos 更易理解，适合学习</strong></li>
</ol>
<hr>
<p><a href="/2025/12/28/DDIA-Part1-%E6%95%B0%E6%8D%AE%E7%B3%BB%E7%BB%9F%E5%9F%BA%E7%A1%80/">上一部分：数据系统基础</a> | <a href="/2025/12/28/DDIA-%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0-%E6%80%BB%E8%A7%88/">返回总览</a> | <a href="/2025/12/28/DDIA-Part3-%E8%A1%8D%E7%94%9F%E6%95%B0%E6%8D%AE/">下一部分：衍生数据</a></p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://foosynaptic.github.io/2025/12/28/DDIA-Part1-%E6%95%B0%E6%8D%AE%E7%B3%BB%E7%BB%9F%E5%9F%BA%E7%A1%80/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="fooSynaptic">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="fooSynaptic">
      <meta itemprop="description" content="Head first to the Truth as Synaptic.">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content=" | fooSynaptic">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2025/12/28/DDIA-Part1-%E6%95%B0%E6%8D%AE%E7%B3%BB%E7%BB%9F%E5%9F%BA%E7%A1%80/" class="post-title-link" itemprop="url">DDIA Part 1：数据系统基础</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2025-12-28 02:01:00" itemprop="dateCreated datePublished" datetime="2025-12-28T02:01:00+08:00">2025-12-28</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/" itemprop="url" rel="index"><span itemprop="name">读书笔记</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <p>本文是 DDIA 第一部分的读书笔记，涵盖第 1-4 章：可靠性与可扩展性、数据模型、存储引擎、数据编码。</p>
<hr>
<h2 id="第1章：可靠性、可扩展性与可维护性"><a href="#第1章：可靠性、可扩展性与可维护性" class="headerlink" title="第1章：可靠性、可扩展性与可维护性"></a>第1章：可靠性、可扩展性与可维护性</h2><h3 id="数据密集型应用的组成"><a href="#数据密集型应用的组成" class="headerlink" title="数据密集型应用的组成"></a>数据密集型应用的组成</h3><p>现代数据密集型应用通常由多个组件组合：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">┌─────────────────────────────────────────┐</span><br><span class="line">│         数据密集型应用架构               │</span><br><span class="line">├─────────────────────────────────────────┤</span><br><span class="line">│  数据库 → 缓存 → 搜索索引               │</span><br><span class="line">│  流处理 → 批处理 → 消息队列             │</span><br><span class="line">└─────────────────────────────────────────┘</span><br></pre></td></tr></table></figure>

<h3 id="可靠性-Reliability"><a href="#可靠性-Reliability" class="headerlink" title="可靠性 (Reliability)"></a>可靠性 (Reliability)</h3><blockquote>
<p>系统在面对故障时仍能正确运行</p>
</blockquote>
<p><strong>故障类型与应对：</strong></p>
<table>
<thead>
<tr>
<th>故障类型</th>
<th>应对策略</th>
</tr>
</thead>
<tbody><tr>
<td>硬件故障</td>
<td>RAID、双电源、多副本</td>
</tr>
<tr>
<td>软件错误</td>
<td>测试、隔离、监控、快速重启</td>
</tr>
<tr>
<td>人为错误</td>
<td>沙箱环境、灰度发布、快速回滚</td>
</tr>
</tbody></table>
<h3 id="可扩展性-Scalability"><a href="#可扩展性-Scalability" class="headerlink" title="可扩展性 (Scalability)"></a>可扩展性 (Scalability)</h3><blockquote>
<p>系统应对负载增长的能力</p>
</blockquote>
<p><strong>性能指标</strong>：使用百分位数而非平均值</p>
<table>
<thead>
<tr>
<th>百分位</th>
<th>含义</th>
</tr>
</thead>
<tbody><tr>
<td>p50</td>
<td>中位数，典型响应时间</td>
</tr>
<tr>
<td>p95</td>
<td>95%请求快于此值</td>
</tr>
<tr>
<td>p99</td>
<td>常用于 SLA 标准</td>
</tr>
</tbody></table>
<p><strong>扩展策略</strong>：</p>
<ul>
<li><strong>纵向扩展</strong>：使用更强大的机器</li>
<li><strong>横向扩展</strong>：使用多台普通机器</li>
<li><strong>弹性扩展</strong>：根据负载自动增减资源</li>
</ul>
<h3 id="可维护性-Maintainability"><a href="#可维护性-Maintainability" class="headerlink" title="可维护性 (Maintainability)"></a>可维护性 (Maintainability)</h3><table>
<thead>
<tr>
<th>方面</th>
<th>目标</th>
</tr>
</thead>
<tbody><tr>
<td>可操作性</td>
<td>运维团队能轻松保持系统运行</td>
</tr>
<tr>
<td>简单性</td>
<td>新工程师能快速理解系统</td>
</tr>
<tr>
<td>可演化性</td>
<td>能轻松修改和扩展系统</td>
</tr>
</tbody></table>
<hr>
<h2 id="第2章：数据模型与查询语言"><a href="#第2章：数据模型与查询语言" class="headerlink" title="第2章：数据模型与查询语言"></a>第2章：数据模型与查询语言</h2><h3 id="三种数据模型对比"><a href="#三种数据模型对比" class="headerlink" title="三种数据模型对比"></a>三种数据模型对比</h3><table>
<thead>
<tr>
<th>模型</th>
<th>特点</th>
<th>适用场景</th>
</tr>
</thead>
<tbody><tr>
<td><strong>关系模型</strong></td>
<td>结构化、规范化、SQL</td>
<td>事务处理、复杂查询</td>
</tr>
<tr>
<td><strong>文档模型</strong></td>
<td>灵活模式、嵌套结构</td>
<td>树状数据、快速迭代</td>
</tr>
<tr>
<td><strong>图模型</strong></td>
<td>多对多关系</td>
<td>社交网络、知识图谱</td>
</tr>
</tbody></table>
<h3 id="关系模型"><a href="#关系模型" class="headerlink" title="关系模型"></a>关系模型</h3><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">-- 规范化设计：使用外键</span></span><br><span class="line"><span class="keyword">CREATE TABLE</span> users (</span><br><span class="line">    user_id <span class="type">INT</span> <span class="keyword">PRIMARY KEY</span>,</span><br><span class="line">    name <span class="type">VARCHAR</span>(<span class="number">100</span>),</span><br><span class="line">    position_id <span class="type">INT</span> <span class="keyword">REFERENCES</span> positions(position_id)</span><br><span class="line">);</span><br></pre></td></tr></table></figure>

<p><strong>优势</strong>：数据一致性、灵活查询、事务支持<br><strong>局限</strong>：对象-关系阻抗不匹配、模式僵化</p>
<h3 id="文档模型"><a href="#文档模型" class="headerlink" title="文档模型"></a>文档模型</h3><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="punctuation">{</span></span><br><span class="line">  <span class="attr">"user_id"</span><span class="punctuation">:</span> <span class="number">1</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">"name"</span><span class="punctuation">:</span> <span class="string">"张三"</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">"positions"</span><span class="punctuation">:</span> <span class="punctuation">[</span></span><br><span class="line">    <span class="punctuation">{</span><span class="attr">"title"</span><span class="punctuation">:</span> <span class="string">"工程师"</span><span class="punctuation">,</span> <span class="attr">"company"</span><span class="punctuation">:</span> <span class="string">"ABC公司"</span><span class="punctuation">}</span><span class="punctuation">,</span></span><br><span class="line">    <span class="punctuation">{</span><span class="attr">"title"</span><span class="punctuation">:</span> <span class="string">"技术总监"</span><span class="punctuation">,</span> <span class="attr">"company"</span><span class="punctuation">:</span> <span class="string">"XYZ公司"</span><span class="punctuation">}</span></span><br><span class="line">  <span class="punctuation">]</span></span><br><span class="line"><span class="punctuation">}</span></span><br></pre></td></tr></table></figure>

<p><strong>Schema-on-read vs Schema-on-write</strong>：</p>
<ul>
<li>关系数据库：写入时验证模式（静态类型）</li>
<li>文档数据库：读取时解释结构（动态类型）</li>
</ul>
<h3 id="图模型"><a href="#图模型" class="headerlink" title="图模型"></a>图模型</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">// Neo4j Cypher 查询</span><br><span class="line">MATCH (alice:Person {name: 'Alice'})-[:FOLLOWS]-&gt;()-[:FOLLOWS]-&gt;(fof)</span><br><span class="line">RETURN fof.name</span><br></pre></td></tr></table></figure>

<h3 id="声明式-vs-命令式"><a href="#声明式-vs-命令式" class="headerlink" title="声明式 vs 命令式"></a>声明式 vs 命令式</h3><table>
<thead>
<tr>
<th>类型</th>
<th>特点</th>
<th>示例</th>
</tr>
</thead>
<tbody><tr>
<td>声明式</td>
<td>描述想要什么结果</td>
<td>SQL, Cypher</td>
</tr>
<tr>
<td>命令式</td>
<td>描述如何得到结果</td>
<td>编程语言循环</td>
</tr>
</tbody></table>
<hr>
<h2 id="第3章：存储与检索"><a href="#第3章：存储与检索" class="headerlink" title="第3章：存储与检索"></a>第3章：存储与检索</h2><h3 id="两大存储引擎家族"><a href="#两大存储引擎家族" class="headerlink" title="两大存储引擎家族"></a>两大存储引擎家族</h3><table>
<thead>
<tr>
<th>类型</th>
<th>优化目标</th>
<th>代表产品</th>
</tr>
</thead>
<tbody><tr>
<td>日志结构 (LSM)</td>
<td>写入优化</td>
<td>RocksDB, Cassandra</td>
</tr>
<tr>
<td>原地更新 (B-Tree)</td>
<td>读取优化</td>
<td>MySQL, PostgreSQL</td>
</tr>
</tbody></table>
<h3 id="LSM-Tree-结构"><a href="#LSM-Tree-结构" class="headerlink" title="LSM-Tree 结构"></a>LSM-Tree 结构</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">Level 0 (内存):</span><br><span class="line">┌────────────┐</span><br><span class="line">│  Memtable  │ ← 当前写入（平衡树）</span><br><span class="line">└────────────┘</span><br><span class="line">      ↓ 达到阈值，写入磁盘</span><br><span class="line">Level 1-N (磁盘):</span><br><span class="line">┌────┐ ┌────┐ ┌────┐</span><br><span class="line">│SS1 │ │SS2 │ │SS3 │ ← SSTable（排序键）</span><br><span class="line">└────┘ └────┘ └────┘</span><br></pre></td></tr></table></figure>

<p><strong>读取流程</strong>：Memtable → 最新 SSTable → … → 最老 SSTable</p>
<p><strong>优化技术</strong>：</p>
<ul>
<li><strong>布隆过滤器</strong>：快速判断键是否存在</li>
<li><strong>压缩策略</strong>：Size-Tiered（写密集）、Leveled（读密集）</li>
</ul>
<h3 id="B-Tree-结构"><a href="#B-Tree-结构" class="headerlink" title="B-Tree 结构"></a>B-Tree 结构</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">          ┌───────────────┐</span><br><span class="line">          │    [30, 70]   │ ← 根节点</span><br><span class="line">          └───────────────┘</span><br><span class="line">         /       │        \</span><br><span class="line">┌───────┐  ┌───────────┐  ┌───────┐</span><br><span class="line">│[10,20]│  │[40,50,60] │  │[80,90]│ ← 叶子节点</span><br><span class="line">└───────┘  └───────────┘  └───────┘</span><br></pre></td></tr></table></figure>

<p><strong>WAL (预写日志)</strong>：先写日志，再更新数据，保证崩溃恢复</p>
<h3 id="B-Tree-vs-LSM-Tree"><a href="#B-Tree-vs-LSM-Tree" class="headerlink" title="B-Tree vs LSM-Tree"></a>B-Tree vs LSM-Tree</h3><table>
<thead>
<tr>
<th>特性</th>
<th>B-Tree</th>
<th>LSM-Tree</th>
</tr>
</thead>
<tbody><tr>
<td>写入</td>
<td>原地更新</td>
<td>追加写入</td>
</tr>
<tr>
<td>读取</td>
<td>快（一次定位）</td>
<td>可能检查多个文件</td>
</tr>
<tr>
<td>写放大</td>
<td>较低</td>
<td>较高（压缩开销）</td>
</tr>
<tr>
<td>空间利用</td>
<td>可能碎片化</td>
<td>更紧凑</td>
</tr>
</tbody></table>
<h3 id="OLTP-vs-OLAP"><a href="#OLTP-vs-OLAP" class="headerlink" title="OLTP vs OLAP"></a>OLTP vs OLAP</h3><table>
<thead>
<tr>
<th>特性</th>
<th>OLTP</th>
<th>OLAP</th>
</tr>
</thead>
<tbody><tr>
<td>操作</td>
<td>增删改查</td>
<td>复杂查询、聚合</td>
</tr>
<tr>
<td>数据量</td>
<td>GB~TB</td>
<td>TB~PB</td>
</tr>
<tr>
<td>用户</td>
<td>应用程序</td>
<td>分析师</td>
</tr>
<tr>
<td>存储</td>
<td>行存储</td>
<td>列存储</td>
</tr>
</tbody></table>
<p><strong>列存储优势</strong>：只读取需要的列、压缩友好、向量化处理</p>
<hr>
<h2 id="第4章：数据编码与演化"><a href="#第4章：数据编码与演化" class="headerlink" title="第4章：数据编码与演化"></a>第4章：数据编码与演化</h2><h3 id="兼容性概念"><a href="#兼容性概念" class="headerlink" title="兼容性概念"></a>兼容性概念</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">时间线: v1 ──&gt; v2 ──&gt; v3 ──&gt; v4</span><br><span class="line"></span><br><span class="line">后向兼容：新代码能读取旧数据 (v3 读 v1 数据 ✓)</span><br><span class="line">前向兼容：旧代码能读取新数据 (v1 读 v3 数据 ✓)</span><br></pre></td></tr></table></figure>

<p><strong>滚动升级</strong>：新旧版本代码同时运行，需要双向兼容</p>
<h3 id="编码格式对比"><a href="#编码格式对比" class="headerlink" title="编码格式对比"></a>编码格式对比</h3><table>
<thead>
<tr>
<th>格式</th>
<th>可读性</th>
<th>空间效率</th>
<th>模式演化</th>
</tr>
</thead>
<tbody><tr>
<td>JSON</td>
<td>高</td>
<td>低</td>
<td>手动</td>
</tr>
<tr>
<td>Protobuf</td>
<td>无</td>
<td>高</td>
<td>支持</td>
</tr>
<tr>
<td>Thrift</td>
<td>无</td>
<td>高</td>
<td>支持</td>
</tr>
<tr>
<td>Avro</td>
<td>无</td>
<td>最高</td>
<td>支持</td>
</tr>
</tbody></table>
<h3 id="Protocol-Buffers"><a href="#Protocol-Buffers" class="headerlink" title="Protocol Buffers"></a>Protocol Buffers</h3><figure class="highlight protobuf"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">message </span><span class="title class_">Person</span> {</span><br><span class="line">  <span class="keyword">required</span> <span class="type">string</span> user_name = <span class="number">1</span>;</span><br><span class="line">  <span class="keyword">optional</span> <span class="type">int64</span> favorite_number = <span class="number">2</span>;</span><br><span class="line">  <span class="keyword">repeated</span> <span class="type">string</span> interests = <span class="number">3</span>;</span><br><span class="line">}</span><br></pre></td></tr></table></figure>

<p><strong>关键规则</strong>：字段名可改，字段标签（数字）不能改</p>
<p><strong>兼容性规则</strong>：</p>
<table>
<thead>
<tr>
<th>操作</th>
<th>后向兼容</th>
<th>前向兼容</th>
</tr>
</thead>
<tbody><tr>
<td>添加可选字段</td>
<td>✓</td>
<td>✓</td>
</tr>
<tr>
<td>删除可选字段</td>
<td>✓</td>
<td>✓</td>
</tr>
<tr>
<td>添加必填字段</td>
<td>✗</td>
<td>✗</td>
</tr>
</tbody></table>
<h3 id="Avro"><a href="#Avro" class="headerlink" title="Avro"></a>Avro</h3><p><strong>特点</strong>：读写模式分离，不存储字段标签，更紧凑</p>
<figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="punctuation">{</span></span><br><span class="line">  <span class="attr">"type"</span><span class="punctuation">:</span> <span class="string">"record"</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">"name"</span><span class="punctuation">:</span> <span class="string">"Person"</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">"fields"</span><span class="punctuation">:</span> <span class="punctuation">[</span></span><br><span class="line">    <span class="punctuation">{</span><span class="attr">"name"</span><span class="punctuation">:</span> <span class="string">"userName"</span><span class="punctuation">,</span> <span class="attr">"type"</span><span class="punctuation">:</span> <span class="string">"string"</span><span class="punctuation">}</span><span class="punctuation">,</span></span><br><span class="line">    <span class="punctuation">{</span><span class="attr">"name"</span><span class="punctuation">:</span> <span class="string">"favoriteNumber"</span><span class="punctuation">,</span> <span class="attr">"type"</span><span class="punctuation">:</span> <span class="punctuation">[</span><span class="string">"null"</span><span class="punctuation">,</span> <span class="string">"long"</span><span class="punctuation">]</span><span class="punctuation">,</span> <span class="attr">"default"</span><span class="punctuation">:</span> <span class="literal"><span class="keyword">null</span></span><span class="punctuation">}</span></span><br><span class="line">  <span class="punctuation">]</span></span><br><span class="line"><span class="punctuation">}</span></span><br></pre></td></tr></table></figure>

<h3 id="数据流模式"><a href="#数据流模式" class="headerlink" title="数据流模式"></a>数据流模式</h3><table>
<thead>
<tr>
<th>模式</th>
<th>场景</th>
<th>兼容性考虑</th>
</tr>
</thead>
<tbody><tr>
<td>数据库</td>
<td>持久存储</td>
<td>数据可能比代码更持久</td>
</tr>
<tr>
<td>服务调用</td>
<td>REST/RPC</td>
<td>API 版本控制</td>
</tr>
<tr>
<td>消息传递</td>
<td>队列/Actor</td>
<td>生产者消费者解耦</td>
</tr>
</tbody></table>
<hr>
<h2 id="本部分要点总结"><a href="#本部分要点总结" class="headerlink" title="本部分要点总结"></a>本部分要点总结</h2><ol>
<li><strong>可靠性、可扩展性、可维护性</strong>是优秀系统的三大支柱</li>
<li><strong>数据模型选择</strong>取决于数据结构和查询需求</li>
<li><strong>LSM-Tree 优化写入，B-Tree 优化读取</strong></li>
<li><strong>列存储适合 OLAP，行存储适合 OLTP</strong></li>
<li><strong>二进制编码比 JSON 更紧凑高效</strong></li>
<li><strong>模式演化需要保证前向和后向兼容</strong></li>
</ol>
<hr>
<p><a href="/2025/12/28/DDIA-%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0-%E6%80%BB%E8%A7%88/">返回总览</a> | <a href="/2025/12/28/DDIA-Part2-%E5%88%86%E5%B8%83%E5%BC%8F%E6%95%B0%E6%8D%AE/">下一部分：分布式数据</a></p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://foosynaptic.github.io/2025/12/28/DDIA-%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0-%E6%80%BB%E8%A7%88/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="fooSynaptic">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="fooSynaptic">
      <meta itemprop="description" content="Head first to the Truth as Synaptic.">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content=" | fooSynaptic">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2025/12/28/DDIA-%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0-%E6%80%BB%E8%A7%88/" class="post-title-link" itemprop="url">DDIA 读书笔记：数据密集型应用系统设计</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2025-12-28 02:00:00" itemprop="dateCreated datePublished" datetime="2025-12-28T02:00:00+08:00">2025-12-28</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/" itemprop="url" rel="index"><span itemprop="name">读书笔记</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <blockquote>
<p><strong>Designing Data-Intensive Applications: The Big Ideas Behind Reliable, Scalable, and Maintainable Systems</strong></p>
</blockquote>
<p>这是一份关于《数据密集型应用系统设计》(DDIA) 的完整读书笔记，本书被誉为”数据系统领域的圣经”。</p>
<h2 id="书籍信息"><a href="#书籍信息" class="headerlink" title="书籍信息"></a>书籍信息</h2><table>
<thead>
<tr>
<th>项目</th>
<th>内容</th>
</tr>
</thead>
<tbody><tr>
<td><strong>书名</strong></td>
<td>Designing Data-Intensive Applications (DDIA)</td>
</tr>
<tr>
<td><strong>中文名</strong></td>
<td>数据密集型应用系统设计</td>
</tr>
<tr>
<td><strong>作者</strong></td>
<td>Martin Kleppmann（剑桥大学分布式系统研究员）</td>
</tr>
<tr>
<td><strong>出版时间</strong></td>
<td>2017年3月</td>
</tr>
</tbody></table>
<h2 id="核心主题"><a href="#核心主题" class="headerlink" title="核心主题"></a>核心主题</h2><p>本书围绕三个核心概念展开：</p>
<ul>
<li><strong>可靠性 (Reliability)</strong>：系统在遇到故障时仍能正确工作</li>
<li><strong>可扩展性 (Scalability)</strong>：系统能够应对负载增长</li>
<li><strong>可维护性 (Maintainability)</strong>：系统易于理解、修改和扩展</li>
</ul>
<h2 id="全书结构"><a href="#全书结构" class="headerlink" title="全书结构"></a>全书结构</h2><h3 id="第一部分：数据系统基础"><a href="#第一部分：数据系统基础" class="headerlink" title="第一部分：数据系统基础"></a>第一部分：数据系统基础</h3><blockquote>
<p><a href="/2025/12/28/DDIA-Part1-%E6%95%B0%E6%8D%AE%E7%B3%BB%E7%BB%9F%E5%9F%BA%E7%A1%80/">查看详细笔记</a></p>
</blockquote>
<table>
<thead>
<tr>
<th>章节</th>
<th>核心内容</th>
</tr>
</thead>
<tbody><tr>
<td>第1章</td>
<td>可靠性、可扩展性、可维护性的定义与实践</td>
</tr>
<tr>
<td>第2章</td>
<td>关系模型、文档模型、图模型的对比与选择</td>
</tr>
<tr>
<td>第3章</td>
<td>存储引擎原理：B-Tree、LSM-Tree、OLTP vs OLAP</td>
</tr>
<tr>
<td>第4章</td>
<td>数据编码格式与模式演化：JSON、Protobuf、Avro</td>
</tr>
</tbody></table>
<h3 id="第二部分：分布式数据"><a href="#第二部分：分布式数据" class="headerlink" title="第二部分：分布式数据"></a>第二部分：分布式数据</h3><blockquote>
<p><a href="/2025/12/28/DDIA-Part2-%E5%88%86%E5%B8%83%E5%BC%8F%E6%95%B0%E6%8D%AE/">查看详细笔记</a></p>
</blockquote>
<table>
<thead>
<tr>
<th>章节</th>
<th>核心内容</th>
</tr>
</thead>
<tbody><tr>
<td>第5章</td>
<td>数据复制：主从、多主、无主复制策略</td>
</tr>
<tr>
<td>第6章</td>
<td>数据分区：分区策略、再平衡、请求路由</td>
</tr>
<tr>
<td>第7章</td>
<td>事务：ACID、隔离级别、分布式事务</td>
</tr>
<tr>
<td>第8章</td>
<td>分布式系统挑战：网络、时钟、故障模型</td>
</tr>
<tr>
<td>第9章</td>
<td>一致性与共识：CAP、Paxos、Raft</td>
</tr>
</tbody></table>
<h3 id="第三部分：衍生数据"><a href="#第三部分：衍生数据" class="headerlink" title="第三部分：衍生数据"></a>第三部分：衍生数据</h3><blockquote>
<p><a href="/2025/12/28/DDIA-Part3-%E8%A1%8D%E7%94%9F%E6%95%B0%E6%8D%AE/">查看详细笔记</a></p>
</blockquote>
<table>
<thead>
<tr>
<th>章节</th>
<th>核心内容</th>
</tr>
</thead>
<tbody><tr>
<td>第10章</td>
<td>批处理：MapReduce、Spark、数据流引擎</td>
</tr>
<tr>
<td>第11章</td>
<td>流处理：Kafka、Flink、事件时间与水位线</td>
</tr>
<tr>
<td>第12章</td>
<td>数据系统未来：数据集成、端到端正确性、伦理</td>
</tr>
</tbody></table>
<h2 id="学习路线"><a href="#学习路线" class="headerlink" title="学习路线"></a>学习路线</h2><h3 id="入门路线（适合初学者）"><a href="#入门路线（适合初学者）" class="headerlink" title="入门路线（适合初学者）"></a>入门路线（适合初学者）</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">第1章 → 第2章 → 第3章 → 第4章（建立基础）</span><br><span class="line">    ↓</span><br><span class="line">第5章 → 第6章（理解分布式基础）</span><br><span class="line">    ↓</span><br><span class="line">第10章 → 第11章（了解数据处理）</span><br></pre></td></tr></table></figure>

<h3 id="进阶路线（适合有经验的开发者）"><a href="#进阶路线（适合有经验的开发者）" class="headerlink" title="进阶路线（适合有经验的开发者）"></a>进阶路线（适合有经验的开发者）</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">第7章 → 第8章 → 第9章（深入分布式）</span><br><span class="line">    ↓</span><br><span class="line">第12章（展望未来）</span><br><span class="line">    ↓</span><br><span class="line">回顾第1-4章填补知识空白</span><br></pre></td></tr></table></figure>

<h3 id="专题路线"><a href="#专题路线" class="headerlink" title="专题路线"></a>专题路线</h3><table>
<thead>
<tr>
<th>方向</th>
<th>推荐阅读顺序</th>
</tr>
</thead>
<tbody><tr>
<td><strong>数据库</strong></td>
<td>2 → 3 → 5 → 6 → 7</td>
</tr>
<tr>
<td><strong>分布式系统</strong></td>
<td>5 → 6 → 8 → 9</td>
</tr>
<tr>
<td><strong>数据工程</strong></td>
<td>3 → 10 → 11 → 12</td>
</tr>
</tbody></table>
<h2 id="核心要点速览"><a href="#核心要点速览" class="headerlink" title="核心要点速览"></a>核心要点速览</h2><h3 id="数据模型选择"><a href="#数据模型选择" class="headerlink" title="数据模型选择"></a>数据模型选择</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">关系模型 ──── 结构化数据、复杂查询、事务支持</span><br><span class="line">     ↓</span><br><span class="line">文档模型 ──── 灵活模式、树状结构、局部性好</span><br><span class="line">     ↓</span><br><span class="line">图模型 ───── 复杂关系、社交网络、知识图谱</span><br></pre></td></tr></table></figure>

<h3 id="存储引擎对比"><a href="#存储引擎对比" class="headerlink" title="存储引擎对比"></a>存储引擎对比</h3><table>
<thead>
<tr>
<th>引擎</th>
<th>优化目标</th>
<th>典型应用</th>
</tr>
</thead>
<tbody><tr>
<td>B-Tree</td>
<td>读取优化</td>
<td>OLTP 数据库</td>
</tr>
<tr>
<td>LSM-Tree</td>
<td>写入优化</td>
<td>日志、时序数据</td>
</tr>
<tr>
<td>列存储</td>
<td>分析优化</td>
<td>OLAP、数据仓库</td>
</tr>
</tbody></table>
<h3 id="分布式系统核心权衡"><a href="#分布式系统核心权衡" class="headerlink" title="分布式系统核心权衡"></a>分布式系统核心权衡</h3><p><mjx-container class="MathJax" jax="SVG" display="true"><svg style="vertical-align: -0.452ex;" xmlns="http://www.w3.org/2000/svg" width="50.686ex" height="2.149ex" role="img" focusable="false" viewBox="0 -750 22403 950"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mtext"><path data-c="43" d="M56 342Q56 428 89 500T174 615T283 681T391 705Q394 705 400 705T408 704Q499 704 569 636L582 624L612 663Q639 700 643 704Q644 704 647 704T653 705H657Q660 705 666 699V419L660 413H626Q620 419 619 430Q610 512 571 572T476 651Q457 658 426 658Q322 658 252 588Q173 509 173 342Q173 221 211 151Q232 111 263 84T328 45T384 29T428 24Q517 24 571 93T626 244Q626 251 632 257H660L666 251V236Q661 133 590 56T403 -21Q262 -21 159 83T56 342Z"></path><path data-c="41" d="M255 0Q240 3 140 3Q48 3 39 0H32V46H47Q119 49 139 88Q140 91 192 245T295 553T348 708Q351 716 366 716H376Q396 715 400 709Q402 707 508 390L617 67Q624 54 636 51T687 46H717V0H708Q699 3 581 3Q458 3 437 0H427V46H440Q510 46 510 64Q510 66 486 138L462 209H229L209 150Q189 91 189 85Q189 72 209 59T259 46H264V0H255ZM447 255L345 557L244 256Q244 255 345 255H447Z" transform="translate(722,0)"></path><path data-c="50" d="M130 622Q123 629 119 631T103 634T60 637H27V683H214Q237 683 276 683T331 684Q419 684 471 671T567 616Q624 563 624 489Q624 421 573 372T451 307Q429 302 328 301H234V181Q234 62 237 58Q245 47 304 46H337V0H326Q305 3 182 3Q47 3 38 0H27V46H60Q102 47 111 49T130 61V622ZM507 488Q507 514 506 528T500 564T483 597T450 620T397 635Q385 637 307 637H286Q237 637 234 628Q231 624 231 483V342H302H339Q390 342 423 349T481 382Q507 411 507 488Z" transform="translate(1472,0)"></path><path data-c="20" d="" transform="translate(2153,0)"></path><text data-variant="normal" transform="translate(2403,0) scale(1,-1)" font-size="884px" font-family="serif">定</text><text data-variant="normal" transform="translate(3403,0) scale(1,-1)" font-size="884px" font-family="serif">理</text><text data-variant="normal" transform="translate(4403,0) scale(1,-1)" font-size="884px" font-family="serif">：</text><text data-variant="normal" transform="translate(5403,0) scale(1,-1)" font-size="884px" font-family="serif">网</text><text data-variant="normal" transform="translate(6403,0) scale(1,-1)" font-size="884px" font-family="serif">络</text><text data-variant="normal" transform="translate(7403,0) scale(1,-1)" font-size="884px" font-family="serif">分</text><text data-variant="normal" transform="translate(8403,0) scale(1,-1)" font-size="884px" font-family="serif">区</text><text data-variant="normal" transform="translate(9403,0) scale(1,-1)" font-size="884px" font-family="serif">时</text><text data-variant="normal" transform="translate(10403,0) scale(1,-1)" font-size="884px" font-family="serif">，</text><text data-variant="normal" transform="translate(11403,0) scale(1,-1)" font-size="884px" font-family="serif">一</text><text data-variant="normal" transform="translate(12403,0) scale(1,-1)" font-size="884px" font-family="serif">致</text><text data-variant="normal" transform="translate(13403,0) scale(1,-1)" font-size="884px" font-family="serif">性</text><text data-variant="normal" transform="translate(14403,0) scale(1,-1)" font-size="884px" font-family="serif">与</text><text data-variant="normal" transform="translate(15403,0) scale(1,-1)" font-size="884px" font-family="serif">可</text><text data-variant="normal" transform="translate(16403,0) scale(1,-1)" font-size="884px" font-family="serif">用</text><text data-variant="normal" transform="translate(17403,0) scale(1,-1)" font-size="884px" font-family="serif">性</text><text data-variant="normal" transform="translate(18403,0) scale(1,-1)" font-size="884px" font-family="serif">不</text><text data-variant="normal" transform="translate(19403,0) scale(1,-1)" font-size="884px" font-family="serif">可</text><text data-variant="normal" transform="translate(20403,0) scale(1,-1)" font-size="884px" font-family="serif">兼</text><text data-variant="normal" transform="translate(21403,0) scale(1,-1)" font-size="884px" font-family="serif">得</text></g></g></g></svg></mjx-container></p>
<h3 id="处理范式对比"><a href="#处理范式对比" class="headerlink" title="处理范式对比"></a>处理范式对比</h3><table>
<thead>
<tr>
<th>范式</th>
<th>数据特性</th>
<th>延迟</th>
<th>典型框架</th>
</tr>
</thead>
<tbody><tr>
<td>批处理</td>
<td>有界、静态</td>
<td>分钟~小时</td>
<td>Spark, Hadoop</td>
</tr>
<tr>
<td>流处理</td>
<td>无界、持续</td>
<td>毫秒~秒</td>
<td>Flink, Kafka Streams</td>
</tr>
</tbody></table>
<h2 id="延伸资源"><a href="#延伸资源" class="headerlink" title="延伸资源"></a>延伸资源</h2><ul>
<li><strong>官方网站</strong>：<a target="_blank" rel="noopener" href="https://dataintensive.net/">dataintensive.net</a></li>
<li><strong>中文翻译</strong>：<a target="_blank" rel="noopener" href="https://ddia.vonng.com/">ddia.vonng.com</a></li>
<li><strong>作者博客</strong>：<a target="_blank" rel="noopener" href="https://martin.kleppmann.com/">martin.kleppmann.com</a></li>
</ul>
<hr>
<p><em>本读书笔记整理于 2025年，基于 DDIA 第一版内容编写</em></p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://foosynaptic.github.io/2019/11/22/Nuural-Approaches-to-Machine-Reading-Comprehension-and-Dialogue/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="fooSynaptic">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="fooSynaptic">
      <meta itemprop="description" content="Head first to the Truth as Synaptic.">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content=" | fooSynaptic">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2019/11/22/Nuural-Approaches-to-Machine-Reading-Comprehension-and-Dialogue/" class="post-title-link" itemprop="url">神经网络机器阅读理解：从 Attention 到 LLM</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2019-11-22 05:31:56" itemprop="dateCreated datePublished" datetime="2019-11-22T05:31:56+08:00">2019-11-22</time>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <p>本文综述神经网络在机器阅读理解和对话系统中的发展历程，从早期的注意力机制到现代大语言模型。</p>
<h2 id="发展时间线"><a href="#发展时间线" class="headerlink" title="发展时间线"></a>发展时间线</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">2015-2016: 注意力机制兴起</span><br><span class="line">    └── Attentive Reader, Impatient Reader, BiDAF</span><br><span class="line"></span><br><span class="line">2017-2018: 深度交互与预训练</span><br><span class="line">    └── R-Net, QANet, BERT</span><br><span class="line"></span><br><span class="line">2019-2020: 大规模预训练</span><br><span class="line">    └── RoBERTa, ALBERT, T5</span><br><span class="line"></span><br><span class="line">2021-2023: 大语言模型时代</span><br><span class="line">    └── GPT-3, ChatGPT, GPT-4, LLaMA</span><br><span class="line"></span><br><span class="line">2024-: 检索增强与多模态</span><br><span class="line">    └── RAG, Vision-Language Models</span><br></pre></td></tr></table></figure>

<h2 id="核心技术演进"><a href="#核心技术演进" class="headerlink" title="核心技术演进"></a>核心技术演进</h2><h3 id="阶段一：注意力机制-2015-2017"><a href="#阶段一：注意力机制-2015-2017" class="headerlink" title="阶段一：注意力机制 (2015-2017)"></a>阶段一：注意力机制 (2015-2017)</h3><p><strong>问题</strong>：如何让模型”关注”与问题相关的上下文？</p>
<p><mjx-container class="MathJax" jax="SVG" display="true"><svg style="vertical-align: -0.566ex;" xmlns="http://www.w3.org/2000/svg" width="21.681ex" height="2.262ex" role="img" focusable="false" viewBox="0 -750 9583.1 1000"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="msub"><g data-mml-node="mi"><path data-c="1D6FC" d="M34 156Q34 270 120 356T309 442Q379 442 421 402T478 304Q484 275 485 237V208Q534 282 560 374Q564 388 566 390T582 393Q603 393 603 385Q603 376 594 346T558 261T497 161L486 147L487 123Q489 67 495 47T514 26Q528 28 540 37T557 60Q559 67 562 68T577 70Q597 70 597 62Q597 56 591 43Q579 19 556 5T512 -10H505Q438 -10 414 62L411 69L400 61Q390 53 370 41T325 18T267 -2T203 -11Q124 -11 79 39T34 156ZM208 26Q257 26 306 47T379 90L403 112Q401 255 396 290Q382 405 304 405Q235 405 183 332Q156 292 139 224T121 120Q121 71 146 49T208 26Z"></path></g><g data-mml-node="mi" transform="translate(673,-150) scale(0.707)"><path data-c="1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path></g></g><g data-mml-node="mo" transform="translate(1244.7,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="mtext" transform="translate(2300.5,0)"><path data-c="73" d="M295 316Q295 356 268 385T190 414Q154 414 128 401Q98 382 98 349Q97 344 98 336T114 312T157 287Q175 282 201 278T245 269T277 256Q294 248 310 236T342 195T359 133Q359 71 321 31T198 -10H190Q138 -10 94 26L86 19L77 10Q71 4 65 -1L54 -11H46H42Q39 -11 33 -5V74V132Q33 153 35 157T45 162H54Q66 162 70 158T75 146T82 119T101 77Q136 26 198 26Q295 26 295 104Q295 133 277 151Q257 175 194 187T111 210Q75 227 54 256T33 318Q33 357 50 384T93 424T143 442T187 447H198Q238 447 268 432L283 424L292 431Q302 440 314 448H322H326Q329 448 335 442V310L329 304H301Q295 310 295 316Z"></path><path data-c="6F" d="M28 214Q28 309 93 378T250 448Q340 448 405 380T471 215Q471 120 407 55T250 -10Q153 -10 91 57T28 214ZM250 30Q372 30 372 193V225V250Q372 272 371 288T364 326T348 362T317 390T268 410Q263 411 252 411Q222 411 195 399Q152 377 139 338T126 246V226Q126 130 145 91Q177 30 250 30Z" transform="translate(394,0)"></path><path data-c="66" d="M273 0Q255 3 146 3Q43 3 34 0H26V46H42Q70 46 91 49Q99 52 103 60Q104 62 104 224V385H33V431H104V497L105 564L107 574Q126 639 171 668T266 704Q267 704 275 704T289 705Q330 702 351 679T372 627Q372 604 358 590T321 576T284 590T270 627Q270 647 288 667H284Q280 668 273 668Q245 668 223 647T189 592Q183 572 182 497V431H293V385H185V225Q185 63 186 61T189 57T194 54T199 51T206 49T213 48T222 47T231 47T241 46T251 46H282V0H273Z" transform="translate(894,0)"></path><path data-c="74" d="M27 422Q80 426 109 478T141 600V615H181V431H316V385H181V241Q182 116 182 100T189 68Q203 29 238 29Q282 29 292 100Q293 108 293 146V181H333V146V134Q333 57 291 17Q264 -10 221 -10Q187 -10 162 2T124 33T105 68T98 100Q97 107 97 248V385H18V422H27Z" transform="translate(1200,0)"></path><path data-c="6D" d="M41 46H55Q94 46 102 60V68Q102 77 102 91T102 122T103 161T103 203Q103 234 103 269T102 328V351Q99 370 88 376T43 385H25V408Q25 431 27 431L37 432Q47 433 65 434T102 436Q119 437 138 438T167 441T178 442H181V402Q181 364 182 364T187 369T199 384T218 402T247 421T285 437Q305 442 336 442Q351 442 364 440T387 434T406 426T421 417T432 406T441 395T448 384T452 374T455 366L457 361L460 365Q463 369 466 373T475 384T488 397T503 410T523 422T546 432T572 439T603 442Q729 442 740 329Q741 322 741 190V104Q741 66 743 59T754 49Q775 46 803 46H819V0H811L788 1Q764 2 737 2T699 3Q596 3 587 0H579V46H595Q656 46 656 62Q657 64 657 200Q656 335 655 343Q649 371 635 385T611 402T585 404Q540 404 506 370Q479 343 472 315T464 232V168V108Q464 78 465 68T468 55T477 49Q498 46 526 46H542V0H534L510 1Q487 2 460 2T422 3Q319 3 310 0H302V46H318Q379 46 379 62Q380 64 380 200Q379 335 378 343Q372 371 358 385T334 402T308 404Q263 404 229 370Q202 343 195 315T187 232V168V108Q187 78 188 68T191 55T200 49Q221 46 249 46H265V0H257L234 1Q210 2 183 2T145 3Q42 3 33 0H25V46H41Z" transform="translate(1589,0)"></path><path data-c="61" d="M137 305T115 305T78 320T63 359Q63 394 97 421T218 448Q291 448 336 416T396 340Q401 326 401 309T402 194V124Q402 76 407 58T428 40Q443 40 448 56T453 109V145H493V106Q492 66 490 59Q481 29 455 12T400 -6T353 12T329 54V58L327 55Q325 52 322 49T314 40T302 29T287 17T269 6T247 -2T221 -8T190 -11Q130 -11 82 20T34 107Q34 128 41 147T68 188T116 225T194 253T304 268H318V290Q318 324 312 340Q290 411 215 411Q197 411 181 410T156 406T148 403Q170 388 170 359Q170 334 154 320ZM126 106Q126 75 150 51T209 26Q247 26 276 49T315 109Q317 116 318 175Q318 233 317 233Q309 233 296 232T251 223T193 203T147 166T126 106Z" transform="translate(2422,0)"></path><path data-c="78" d="M201 0Q189 3 102 3Q26 3 17 0H11V46H25Q48 47 67 52T96 61T121 78T139 96T160 122T180 150L226 210L168 288Q159 301 149 315T133 336T122 351T113 363T107 370T100 376T94 379T88 381T80 383Q74 383 44 385H16V431H23Q59 429 126 429Q219 429 229 431H237V385Q201 381 201 369Q201 367 211 353T239 315T268 274L272 270L297 304Q329 345 329 358Q329 364 327 369T322 376T317 380T310 384L307 385H302V431H309Q324 428 408 428Q487 428 493 431H499V385H492Q443 385 411 368Q394 360 377 341T312 257L296 236L358 151Q424 61 429 57T446 50Q464 46 499 46H516V0H510H502Q494 1 482 1T457 2T432 2T414 3Q403 3 377 3T327 1L304 0H295V46H298Q309 46 320 51T331 63Q331 65 291 120L250 175Q249 174 219 133T185 88Q181 83 181 74Q181 63 188 55T206 46Q208 46 208 23V0H201Z" transform="translate(2922,0)"></path></g><g data-mml-node="mo" transform="translate(5750.5,0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="mi" transform="translate(6139.5,0)"><path data-c="1D460" d="M131 289Q131 321 147 354T203 415T300 442Q362 442 390 415T419 355Q419 323 402 308T364 292Q351 292 340 300T328 326Q328 342 337 354T354 372T367 378Q368 378 368 379Q368 382 361 388T336 399T297 405Q249 405 227 379T204 326Q204 301 223 291T278 274T330 259Q396 230 396 163Q396 135 385 107T352 51T289 7T195 -10Q118 -10 86 19T53 87Q53 126 74 143T118 160Q133 160 146 151T160 120Q160 94 142 76T111 58Q109 57 108 57T107 55Q108 52 115 47T146 34T201 27Q237 27 263 38T301 66T318 97T323 122Q323 150 302 164T254 181T195 196T148 231Q131 256 131 289Z"></path></g><g data-mml-node="mo" transform="translate(6608.5,0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="msub" transform="translate(6997.5,0)"><g data-mml-node="mi"><path data-c="210E" d="M137 683Q138 683 209 688T282 694Q294 694 294 685Q294 674 258 534Q220 386 220 383Q220 381 227 388Q288 442 357 442Q411 442 444 415T478 336Q478 285 440 178T402 50Q403 36 407 31T422 26Q450 26 474 56T513 138Q516 149 519 151T535 153Q555 153 555 145Q555 144 551 130Q535 71 500 33Q466 -10 419 -10H414Q367 -10 346 17T325 74Q325 90 361 192T398 345Q398 404 354 404H349Q266 404 205 306L198 293L164 158Q132 28 127 16Q114 -11 83 -11Q69 -11 59 -2T48 16Q48 30 121 320L195 616Q195 629 188 632T149 637H128Q122 643 122 645T124 664Q129 683 137 683Z"></path></g><g data-mml-node="mi" transform="translate(609,-150) scale(0.707)"><path data-c="1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path></g></g><g data-mml-node="mo" transform="translate(7900.5,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path></g><g data-mml-node="mi" transform="translate(8345.1,0)"><path data-c="1D45E" d="M33 157Q33 258 109 349T280 441Q340 441 372 389Q373 390 377 395T388 406T404 418Q438 442 450 442Q454 442 457 439T460 434Q460 425 391 149Q320 -135 320 -139Q320 -147 365 -148H390Q396 -156 396 -157T393 -175Q389 -188 383 -194H370Q339 -192 262 -192Q234 -192 211 -192T174 -192T157 -193Q143 -193 143 -185Q143 -182 145 -170Q149 -154 152 -151T172 -148Q220 -148 230 -141Q238 -136 258 -53T279 32Q279 33 272 29Q224 -10 172 -10Q117 -10 75 30T33 157ZM352 326Q329 405 277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q233 26 290 98L298 109L352 326Z"></path></g><g data-mml-node="mo" transform="translate(8805.1,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g><g data-mml-node="mo" transform="translate(9194.1,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g></g></g></svg></mjx-container></p>
<p><mjx-container class="MathJax" jax="SVG" display="true"><svg style="vertical-align: -2.697ex;" xmlns="http://www.w3.org/2000/svg" width="11.871ex" height="4.847ex" role="img" focusable="false" viewBox="0 -950 5247.1 2142.2"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D450" d="M34 159Q34 268 120 355T306 442Q362 442 394 418T427 355Q427 326 408 306T360 285Q341 285 330 295T319 325T330 359T352 380T366 386H367Q367 388 361 392T340 400T306 404Q276 404 249 390Q228 381 206 359Q162 315 142 235T121 119Q121 73 147 50Q169 26 205 26H209Q321 26 394 111Q403 121 406 121Q410 121 419 112T429 98T420 83T391 55T346 25T282 0T202 -11Q127 -11 81 37T34 159Z"></path></g><g data-mml-node="mo" transform="translate(710.8,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="munder" transform="translate(1766.6,0)"><g data-mml-node="mo"><path data-c="2211" d="M60 948Q63 950 665 950H1267L1325 815Q1384 677 1388 669H1348L1341 683Q1320 724 1285 761Q1235 809 1174 838T1033 881T882 898T699 902H574H543H251L259 891Q722 258 724 252Q725 250 724 246Q721 243 460 -56L196 -356Q196 -357 407 -357Q459 -357 548 -357T676 -358Q812 -358 896 -353T1063 -332T1204 -283T1307 -196Q1328 -170 1348 -124H1388Q1388 -125 1381 -145T1356 -210T1325 -294L1267 -449L666 -450Q64 -450 61 -448Q55 -446 55 -439Q55 -437 57 -433L590 177Q590 178 557 222T452 366T322 544L56 909L55 924Q55 945 60 948Z"></path></g><g data-mml-node="mi" transform="translate(600,-1084.4) scale(0.707)"><path data-c="1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path></g></g><g data-mml-node="msub" transform="translate(3377.2,0)"><g data-mml-node="mi"><path data-c="1D6FC" d="M34 156Q34 270 120 356T309 442Q379 442 421 402T478 304Q484 275 485 237V208Q534 282 560 374Q564 388 566 390T582 393Q603 393 603 385Q603 376 594 346T558 261T497 161L486 147L487 123Q489 67 495 47T514 26Q528 28 540 37T557 60Q559 67 562 68T577 70Q597 70 597 62Q597 56 591 43Q579 19 556 5T512 -10H505Q438 -10 414 62L411 69L400 61Q390 53 370 41T325 18T267 -2T203 -11Q124 -11 79 39T34 156ZM208 26Q257 26 306 47T379 90L403 112Q401 255 396 290Q382 405 304 405Q235 405 183 332Q156 292 139 224T121 120Q121 71 146 49T208 26Z"></path></g><g data-mml-node="mi" transform="translate(673,-150) scale(0.707)"><path data-c="1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path></g></g><g data-mml-node="msub" transform="translate(4344.2,0)"><g data-mml-node="mi"><path data-c="210E" d="M137 683Q138 683 209 688T282 694Q294 694 294 685Q294 674 258 534Q220 386 220 383Q220 381 227 388Q288 442 357 442Q411 442 444 415T478 336Q478 285 440 178T402 50Q403 36 407 31T422 26Q450 26 474 56T513 138Q516 149 519 151T535 153Q555 153 555 145Q555 144 551 130Q535 71 500 33Q466 -10 419 -10H414Q367 -10 346 17T325 74Q325 90 361 192T398 345Q398 404 354 404H349Q266 404 205 306L198 293L164 158Q132 28 127 16Q114 -11 83 -11Q69 -11 59 -2T48 16Q48 30 121 320L195 616Q195 629 188 632T149 637H128Q122 643 122 645T124 664Q129 683 137 683Z"></path></g><g data-mml-node="mi" transform="translate(609,-150) scale(0.707)"><path data-c="1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path></g></g></g></g></svg></mjx-container></p>
<p><strong>代表模型</strong>：Attentive Reader, BiDAF</p>
<h3 id="阶段二：深度交互-2017-2018"><a href="#阶段二：深度交互-2017-2018" class="headerlink" title="阶段二：深度交互 (2017-2018)"></a>阶段二：深度交互 (2017-2018)</h3><p><strong>问题</strong>：如何建模问题和上下文的复杂交互？</p>
<p><strong>技术</strong>：多轮注意力、自注意力、门控机制</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 多轮推理 (R-Net 风格)</span></span><br><span class="line"><span class="keyword">for</span> layer <span class="keyword">in</span> <span class="built_in">range</span>(num_layers):</span><br><span class="line">    <span class="comment"># 自注意力</span></span><br><span class="line">    context = self_attention(context, context)</span><br><span class="line">    <span class="comment"># 交叉注意力</span></span><br><span class="line">    context = cross_attention(context, question)</span><br></pre></td></tr></table></figure>

<h3 id="阶段三：预训练语言模型-2018-2020"><a href="#阶段三：预训练语言模型-2018-2020" class="headerlink" title="阶段三：预训练语言模型 (2018-2020)"></a>阶段三：预训练语言模型 (2018-2020)</h3><p><strong>范式转变</strong>：从 task-specific 到 pretrain-finetune</p>
<p>$$<br>\theta^* = \arg\min_\theta \mathcal{L}<em>{task}(\text{PLM}</em>\theta(x), y)<br>$$</p>
<p><strong>代表模型</strong>：BERT, RoBERTa, ALBERT</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> transformers <span class="keyword">import</span> AutoModelForQuestionAnswering</span><br><span class="line"></span><br><span class="line">model = AutoModelForQuestionAnswering.from_pretrained(<span class="string">"bert-base-uncased"</span>)</span><br><span class="line"><span class="comment"># Fine-tune on SQuAD</span></span><br></pre></td></tr></table></figure>

<h3 id="阶段四：大语言模型-2020-至今"><a href="#阶段四：大语言模型-2020-至今" class="headerlink" title="阶段四：大语言模型 (2020-至今)"></a>阶段四：大语言模型 (2020-至今)</h3><p><strong>范式转变</strong>：从 fine-tuning 到 prompting</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Few-shot prompting</span></span><br><span class="line">prompt = <span class="string">"""</span></span><br><span class="line"><span class="string">Context: The Eiffel Tower was built in 1889.</span></span><br><span class="line"><span class="string">Question: When was the Eiffel Tower built?</span></span><br><span class="line"><span class="string">Answer: 1889</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">Context: {context}</span></span><br><span class="line"><span class="string">Question: {question}</span></span><br><span class="line"><span class="string">Answer:"""</span></span><br></pre></td></tr></table></figure>

<h2 id="架构对比"><a href="#架构对比" class="headerlink" title="架构对比"></a>架构对比</h2><table>
<thead>
<tr>
<th>模型</th>
<th>参数量</th>
<th>训练范式</th>
<th>SQuAD 2.0 F1</th>
</tr>
</thead>
<tbody><tr>
<td>BiDAF</td>
<td>~2M</td>
<td>从零训练</td>
<td>77.3</td>
</tr>
<tr>
<td>BERT-base</td>
<td>110M</td>
<td>预训练+微调</td>
<td>88.5</td>
</tr>
<tr>
<td>BERT-large</td>
<td>340M</td>
<td>预训练+微调</td>
<td>90.9</td>
</tr>
<tr>
<td>RoBERTa-large</td>
<td>355M</td>
<td>预训练+微调</td>
<td>91.4</td>
</tr>
<tr>
<td>GPT-3</td>
<td>175B</td>
<td>Few-shot</td>
<td>~88</td>
</tr>
<tr>
<td>GPT-4</td>
<td>~1.8T</td>
<td>Zero-shot</td>
<td>~95</td>
</tr>
</tbody></table>
<h2 id="现代-MRC-系统设计"><a href="#现代-MRC-系统设计" class="headerlink" title="现代 MRC 系统设计"></a>现代 MRC 系统设计</h2><h3 id="RAG-架构"><a href="#RAG-架构" class="headerlink" title="RAG 架构"></a>RAG 架构</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">ModernMRC</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, retriever, reader</span>):</span><br><span class="line">        <span class="variable language_">self</span>.retriever = retriever  <span class="comment"># Dense retriever</span></span><br><span class="line">        <span class="variable language_">self</span>.reader = reader        <span class="comment"># LLM</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">answer</span>(<span class="params">self, question: <span class="built_in">str</span>, knowledge_base: <span class="built_in">str</span> = <span class="literal">None</span></span>):</span><br><span class="line">        <span class="comment"># 1. 检索</span></span><br><span class="line">        <span class="keyword">if</span> knowledge_base:</span><br><span class="line">            docs = <span class="variable language_">self</span>.retriever.retrieve(question, knowledge_base)</span><br><span class="line">            context = <span class="string">"\n\n"</span>.join([d.text <span class="keyword">for</span> d <span class="keyword">in</span> docs])</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            context = <span class="string">""</span></span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 2. 阅读理解/生成</span></span><br><span class="line">        prompt = <span class="variable language_">self</span>._build_prompt(question, context)</span><br><span class="line">        answer = <span class="variable language_">self</span>.reader.generate(prompt)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 3. 后处理（可选：验证、引用）</span></span><br><span class="line">        <span class="keyword">return</span> <span class="variable language_">self</span>._postprocess(answer, docs)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">_build_prompt</span>(<span class="params">self, question, context</span>):</span><br><span class="line">        <span class="keyword">if</span> context:</span><br><span class="line">            <span class="keyword">return</span> <span class="string">f"""Based on the following context, answer the question.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">Context:</span></span><br><span class="line"><span class="string"><span class="subst">{context}</span></span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">Question: <span class="subst">{question}</span></span></span><br><span class="line"><span class="string">Answer:"""</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">return</span> <span class="string">f"Question: <span class="subst">{question}</span>\nAnswer:"</span></span><br></pre></td></tr></table></figure>

<h3 id="多跳推理"><a href="#多跳推理" class="headerlink" title="多跳推理"></a>多跳推理</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">MultiHopReasoner</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, retriever, llm, max_hops=<span class="number">3</span></span>):</span><br><span class="line">        <span class="variable language_">self</span>.retriever = retriever</span><br><span class="line">        <span class="variable language_">self</span>.llm = llm</span><br><span class="line">        <span class="variable language_">self</span>.max_hops = max_hops</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">reason</span>(<span class="params">self, question</span>):</span><br><span class="line">        reasoning_chain = []</span><br><span class="line">        current_query = question</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">for</span> hop <span class="keyword">in</span> <span class="built_in">range</span>(<span class="variable language_">self</span>.max_hops):</span><br><span class="line">            <span class="comment"># 检索</span></span><br><span class="line">            docs = <span class="variable language_">self</span>.retriever.retrieve(current_query)</span><br><span class="line">            </span><br><span class="line">            <span class="comment"># 生成中间推理</span></span><br><span class="line">            intermediate = <span class="variable language_">self</span>.llm.generate(</span><br><span class="line">                <span class="string">f"Based on: <span class="subst">{docs}</span>\nQuestion: <span class="subst">{current_query}</span>\n"</span></span><br><span class="line">                <span class="string">f"Provide intermediate reasoning or the final answer:"</span></span><br><span class="line">            )</span><br><span class="line">            </span><br><span class="line">            reasoning_chain.append({</span><br><span class="line">                <span class="string">'query'</span>: current_query,</span><br><span class="line">                <span class="string">'docs'</span>: docs,</span><br><span class="line">                <span class="string">'reasoning'</span>: intermediate</span><br><span class="line">            })</span><br><span class="line">            </span><br><span class="line">            <span class="comment"># 检查是否已得到答案</span></span><br><span class="line">            <span class="keyword">if</span> <span class="variable language_">self</span>._is_final_answer(intermediate):</span><br><span class="line">                <span class="keyword">break</span></span><br><span class="line">            </span><br><span class="line">            <span class="comment"># 生成下一跳查询</span></span><br><span class="line">            current_query = <span class="variable language_">self</span>._generate_next_query(question, reasoning_chain)</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">return</span> <span class="variable language_">self</span>._synthesize_answer(question, reasoning_chain)</span><br></pre></td></tr></table></figure>

<h2 id="对话系统中的-MRC"><a href="#对话系统中的-MRC" class="headerlink" title="对话系统中的 MRC"></a>对话系统中的 MRC</h2><h3 id="对话式问答"><a href="#对话式问答" class="headerlink" title="对话式问答"></a>对话式问答</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">ConversationalQA</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, mrc_model, history_length=<span class="number">5</span></span>):</span><br><span class="line">        <span class="variable language_">self</span>.mrc_model = mrc_model</span><br><span class="line">        <span class="variable language_">self</span>.history = []</span><br><span class="line">        <span class="variable language_">self</span>.history_length = history_length</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">ask</span>(<span class="params">self, question, context=<span class="literal">None</span></span>):</span><br><span class="line">        <span class="comment"># 将对话历史纳入问题</span></span><br><span class="line">        contextualized_question = <span class="variable language_">self</span>._contextualize(question)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 获取答案</span></span><br><span class="line">        answer = <span class="variable language_">self</span>.mrc_model.answer(contextualized_question, context)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 更新历史</span></span><br><span class="line">        <span class="variable language_">self</span>.history.append({<span class="string">'q'</span>: question, <span class="string">'a'</span>: answer})</span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">len</span>(<span class="variable language_">self</span>.history) &gt; <span class="variable language_">self</span>.history_length:</span><br><span class="line">            <span class="variable language_">self</span>.history.pop(<span class="number">0</span>)</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">return</span> answer</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">_contextualize</span>(<span class="params">self, question</span>):</span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> <span class="variable language_">self</span>.history:</span><br><span class="line">            <span class="keyword">return</span> question</span><br><span class="line">        </span><br><span class="line">        history_text = <span class="string">"\n"</span>.join([</span><br><span class="line">            <span class="string">f"Q: <span class="subst">{turn[<span class="string">'q'</span>]}</span>\nA: <span class="subst">{turn[<span class="string">'a'</span>]}</span>"</span></span><br><span class="line">            <span class="keyword">for</span> turn <span class="keyword">in</span> <span class="variable language_">self</span>.history</span><br><span class="line">        ])</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">return</span> <span class="string">f"Conversation history:\n<span class="subst">{history_text}</span>\n\nCurrent question: <span class="subst">{question}</span>"</span></span><br></pre></td></tr></table></figure>

<h2 id="评估体系"><a href="#评估体系" class="headerlink" title="评估体系"></a>评估体系</h2><h3 id="传统指标"><a href="#传统指标" class="headerlink" title="传统指标"></a>传统指标</h3><table>
<thead>
<tr>
<th>指标</th>
<th>定义</th>
<th>适用场景</th>
</tr>
</thead>
<tbody><tr>
<td>EM</td>
<td>精确匹配</td>
<td>抽取式 QA</td>
</tr>
<tr>
<td>F1</td>
<td>Token 重叠</td>
<td>抽取式 QA</td>
</tr>
<tr>
<td>BLEU</td>
<td>N-gram 重叠</td>
<td>生成式 QA</td>
</tr>
<tr>
<td>ROUGE</td>
<td>召回导向重叠</td>
<td>摘要、长答案</td>
</tr>
</tbody></table>
<h3 id="LLM-时代指标"><a href="#LLM-时代指标" class="headerlink" title="LLM 时代指标"></a>LLM 时代指标</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># LLM-as-Judge</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">llm_evaluate</span>(<span class="params">question, reference, prediction</span>):</span><br><span class="line">    prompt = <span class="string">f"""Evaluate the answer quality on a scale of 1-5:</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">Question: <span class="subst">{question}</span></span></span><br><span class="line"><span class="string">Reference Answer: <span class="subst">{reference}</span></span></span><br><span class="line"><span class="string">Model Answer: <span class="subst">{prediction}</span></span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">Criteria:</span></span><br><span class="line"><span class="string">- Correctness: Is the information accurate?</span></span><br><span class="line"><span class="string">- Completeness: Does it fully answer the question?</span></span><br><span class="line"><span class="string">- Conciseness: Is it appropriately brief?</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">Score (1-5):"""</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> llm.generate(prompt)</span><br></pre></td></tr></table></figure>

<h2 id="延伸阅读"><a href="#延伸阅读" class="headerlink" title="延伸阅读"></a>延伸阅读</h2><ul>
<li><a target="_blank" rel="noopener" href="https://arxiv.org/abs/1704.00051">Reading Wikipedia to Answer Open-Domain Questions</a></li>
<li><a target="_blank" rel="noopener" href="https://arxiv.org/abs/2005.11401">RAG Paper</a></li>
<li><a target="_blank" rel="noopener" href="https://arxiv.org/abs/1809.09600">HotpotQA: Multi-hop Reasoning</a></li>
<li><a target="_blank" rel="noopener" href="https://arxiv.org/abs/2005.11401">Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks</a></li>
</ul>
<hr>
<blockquote>
<p>转载请注明出处</p>
</blockquote>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://foosynaptic.github.io/2019/11/19/%E5%A6%82%E4%BD%95%E6%95%99%E4%BC%9A%E6%9C%BA%E5%99%A8%E7%90%86%E8%A7%A3%E9%97%AE%E9%A2%98%EF%BC%9A%E4%BB%8E%E9%9B%B6%E5%BC%80%E5%A7%8B%E7%9A%84%E6%9C%BA%E5%99%A8%E9%98%85%E8%AF%BB%E7%90%86%E8%A7%A3%E5%AE%9E%E8%B7%B5/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="fooSynaptic">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="fooSynaptic">
      <meta itemprop="description" content="Head first to the Truth as Synaptic.">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content=" | fooSynaptic">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2019/11/19/%E5%A6%82%E4%BD%95%E6%95%99%E4%BC%9A%E6%9C%BA%E5%99%A8%E7%90%86%E8%A7%A3%E9%97%AE%E9%A2%98%EF%BC%9A%E4%BB%8E%E9%9B%B6%E5%BC%80%E5%A7%8B%E7%9A%84%E6%9C%BA%E5%99%A8%E9%98%85%E8%AF%BB%E7%90%86%E8%A7%A3%E5%AE%9E%E8%B7%B5/" class="post-title-link" itemprop="url">机器阅读理解实战：从零构建问答系统</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2019-11-19 09:03:04" itemprop="dateCreated datePublished" datetime="2019-11-19T09:03:04+08:00">2019-11-19</time>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <p>本文从零开始实现一个机器阅读理解系统，涵盖数据处理、模型构建、训练和推理的完整流程。</p>
<h2 id="任务定义"><a href="#任务定义" class="headerlink" title="任务定义"></a>任务定义</h2><p>给定上下文 <mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.05ex;" xmlns="http://www.w3.org/2000/svg" width="1.719ex" height="1.645ex" role="img" focusable="false" viewBox="0 -705 760 727"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D436" d="M50 252Q50 367 117 473T286 641T490 704Q580 704 633 653Q642 643 648 636T656 626L657 623Q660 623 684 649Q691 655 699 663T715 679T725 690L740 705H746Q760 705 760 698Q760 694 728 561Q692 422 692 421Q690 416 687 415T669 413H653Q647 419 647 422Q647 423 648 429T650 449T651 481Q651 552 619 605T510 659Q484 659 454 652T382 628T299 572T226 479Q194 422 175 346T156 222Q156 108 232 58Q280 24 350 24Q441 24 512 92T606 240Q610 253 612 255T628 257Q648 257 648 248Q648 243 647 239Q618 132 523 55T319 -22Q206 -22 128 53T50 252Z"></path></g></g></g></svg></mjx-container> 和问题 <mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.439ex;" xmlns="http://www.w3.org/2000/svg" width="1.79ex" height="2.032ex" role="img" focusable="false" viewBox="0 -704 791 898"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D444" d="M399 -80Q399 -47 400 -30T402 -11V-7L387 -11Q341 -22 303 -22Q208 -22 138 35T51 201Q50 209 50 244Q50 346 98 438T227 601Q351 704 476 704Q514 704 524 703Q621 689 680 617T740 435Q740 255 592 107Q529 47 461 16L444 8V3Q444 2 449 -24T470 -66T516 -82Q551 -82 583 -60T625 -3Q631 11 638 11Q647 11 649 2Q649 -6 639 -34T611 -100T557 -165T481 -194Q399 -194 399 -87V-80ZM636 468Q636 523 621 564T580 625T530 655T477 665Q429 665 379 640Q277 591 215 464T153 216Q153 110 207 59Q231 38 236 38V46Q236 86 269 120T347 155Q372 155 390 144T417 114T429 82T435 55L448 64Q512 108 557 185T619 334T636 468ZM314 18Q362 18 404 39L403 49Q399 104 366 115Q354 117 347 117Q344 117 341 117T337 118Q317 118 296 98T274 52Q274 18 314 18Z"></path></g></g></g></svg></mjx-container>，预测答案 <mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: 0;" xmlns="http://www.w3.org/2000/svg" width="1.697ex" height="1.62ex" role="img" focusable="false" viewBox="0 -716 750 716"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D434" d="M208 74Q208 50 254 46Q272 46 272 35Q272 34 270 22Q267 8 264 4T251 0Q249 0 239 0T205 1T141 2Q70 2 50 0H42Q35 7 35 11Q37 38 48 46H62Q132 49 164 96Q170 102 345 401T523 704Q530 716 547 716H555H572Q578 707 578 706L606 383Q634 60 636 57Q641 46 701 46Q726 46 726 36Q726 34 723 22Q720 7 718 4T704 0Q701 0 690 0T651 1T578 2Q484 2 455 0H443Q437 6 437 9T439 27Q443 40 445 43L449 46H469Q523 49 533 63L521 213H283L249 155Q208 86 208 74ZM516 260Q516 271 504 416T490 562L463 519Q447 492 400 412L310 260L413 259Q516 259 516 260Z"></path></g></g></g></svg></mjx-container> 在 <mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.05ex;" xmlns="http://www.w3.org/2000/svg" width="1.719ex" height="1.645ex" role="img" focusable="false" viewBox="0 -705 760 727"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D436" d="M50 252Q50 367 117 473T286 641T490 704Q580 704 633 653Q642 643 648 636T656 626L657 623Q660 623 684 649Q691 655 699 663T715 679T725 690L740 705H746Q760 705 760 698Q760 694 728 561Q692 422 692 421Q690 416 687 415T669 413H653Q647 419 647 422Q647 423 648 429T650 449T651 481Q651 552 619 605T510 659Q484 659 454 652T382 628T299 572T226 479Q194 422 175 346T156 222Q156 108 232 58Q280 24 350 24Q441 24 512 92T606 240Q610 253 612 255T628 257Q648 257 648 248Q648 243 647 239Q618 132 523 55T319 -22Q206 -22 128 53T50 252Z"></path></g></g></g></svg></mjx-container> 中的位置：</p>
<p><mjx-container class="MathJax" jax="SVG" display="true"><svg style="vertical-align: -2.013ex;" xmlns="http://www.w3.org/2000/svg" width="48.253ex" height="3.71ex" role="img" focusable="false" viewBox="0 -750 21328 1639.6"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mo"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="mi" transform="translate(389,0)"><path data-c="1D460" d="M131 289Q131 321 147 354T203 415T300 442Q362 442 390 415T419 355Q419 323 402 308T364 292Q351 292 340 300T328 326Q328 342 337 354T354 372T367 378Q368 378 368 379Q368 382 361 388T336 399T297 405Q249 405 227 379T204 326Q204 301 223 291T278 274T330 259Q396 230 396 163Q396 135 385 107T352 51T289 7T195 -10Q118 -10 86 19T53 87Q53 126 74 143T118 160Q133 160 146 151T160 120Q160 94 142 76T111 58Q109 57 108 57T107 55Q108 52 115 47T146 34T201 27Q237 27 263 38T301 66T318 97T323 122Q323 150 302 164T254 181T195 196T148 231Q131 256 131 289Z"></path></g><g data-mml-node="mi" transform="translate(858,0)"><path data-c="1D461" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path></g><g data-mml-node="mi" transform="translate(1219,0)"><path data-c="1D44E" d="M33 157Q33 258 109 349T280 441Q331 441 370 392Q386 422 416 422Q429 422 439 414T449 394Q449 381 412 234T374 68Q374 43 381 35T402 26Q411 27 422 35Q443 55 463 131Q469 151 473 152Q475 153 483 153H487Q506 153 506 144Q506 138 501 117T481 63T449 13Q436 0 417 -8Q409 -10 393 -10Q359 -10 336 5T306 36L300 51Q299 52 296 50Q294 48 292 46Q233 -10 172 -10Q117 -10 75 30T33 157ZM351 328Q351 334 346 350T323 385T277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q217 26 254 59T298 110Q300 114 325 217T351 328Z"></path></g><g data-mml-node="mi" transform="translate(1748,0)"><path data-c="1D45F" d="M21 287Q22 290 23 295T28 317T38 348T53 381T73 411T99 433T132 442Q161 442 183 430T214 408T225 388Q227 382 228 382T236 389Q284 441 347 441H350Q398 441 422 400Q430 381 430 363Q430 333 417 315T391 292T366 288Q346 288 334 299T322 328Q322 376 378 392Q356 405 342 405Q286 405 239 331Q229 315 224 298T190 165Q156 25 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 114 189T154 366Q154 405 128 405Q107 405 92 377T68 316T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(2199,0)"><path data-c="1D461" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path></g><g data-mml-node="mo" transform="translate(2560,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path></g><g data-mml-node="mi" transform="translate(3004.7,0)"><path data-c="1D452" d="M39 168Q39 225 58 272T107 350T174 402T244 433T307 442H310Q355 442 388 420T421 355Q421 265 310 237Q261 224 176 223Q139 223 138 221Q138 219 132 186T125 128Q125 81 146 54T209 26T302 45T394 111Q403 121 406 121Q410 121 419 112T429 98T420 82T390 55T344 24T281 -1T205 -11Q126 -11 83 42T39 168ZM373 353Q367 405 305 405Q272 405 244 391T199 357T170 316T154 280T149 261Q149 260 169 260Q282 260 327 284T373 353Z"></path></g><g data-mml-node="mi" transform="translate(3470.7,0)"><path data-c="1D45B" d="M21 287Q22 293 24 303T36 341T56 388T89 425T135 442Q171 442 195 424T225 390T231 369Q231 367 232 367L243 378Q304 442 382 442Q436 442 469 415T503 336T465 179T427 52Q427 26 444 26Q450 26 453 27Q482 32 505 65T540 145Q542 153 560 153Q580 153 580 145Q580 144 576 130Q568 101 554 73T508 17T439 -10Q392 -10 371 17T350 73Q350 92 386 193T423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 180T152 343Q153 348 153 366Q153 405 129 405Q91 405 66 305Q60 285 60 284Q58 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(4070.7,0)"><path data-c="1D451" d="M366 683Q367 683 438 688T511 694Q523 694 523 686Q523 679 450 384T375 83T374 68Q374 26 402 26Q411 27 422 35Q443 55 463 131Q469 151 473 152Q475 153 483 153H487H491Q506 153 506 145Q506 140 503 129Q490 79 473 48T445 8T417 -8Q409 -10 393 -10Q359 -10 336 5T306 36L300 51Q299 52 296 50Q294 48 292 46Q233 -10 172 -10Q117 -10 75 30T33 157Q33 205 53 255T101 341Q148 398 195 420T280 442Q336 442 364 400Q369 394 369 396Q370 400 396 505T424 616Q424 629 417 632T378 637H357Q351 643 351 645T353 664Q358 683 366 683ZM352 326Q329 405 277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q233 26 290 98L298 109L352 326Z"></path></g><g data-mml-node="mo" transform="translate(4590.7,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g><g data-mml-node="mo" transform="translate(5257.4,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="mi" transform="translate(6313.2,0)"><path data-c="61" d="M137 305T115 305T78 320T63 359Q63 394 97 421T218 448Q291 448 336 416T396 340Q401 326 401 309T402 194V124Q402 76 407 58T428 40Q443 40 448 56T453 109V145H493V106Q492 66 490 59Q481 29 455 12T400 -6T353 12T329 54V58L327 55Q325 52 322 49T314 40T302 29T287 17T269 6T247 -2T221 -8T190 -11Q130 -11 82 20T34 107Q34 128 41 147T68 188T116 225T194 253T304 268H318V290Q318 324 312 340Q290 411 215 411Q197 411 181 410T156 406T148 403Q170 388 170 359Q170 334 154 320ZM126 106Q126 75 150 51T209 26Q247 26 276 49T315 109Q317 116 318 175Q318 233 317 233Q309 233 296 232T251 223T193 203T147 166T126 106Z"></path><path data-c="72" d="M36 46H50Q89 46 97 60V68Q97 77 97 91T98 122T98 161T98 203Q98 234 98 269T98 328L97 351Q94 370 83 376T38 385H20V408Q20 431 22 431L32 432Q42 433 60 434T96 436Q112 437 131 438T160 441T171 442H174V373Q213 441 271 441H277Q322 441 343 419T364 373Q364 352 351 337T313 322Q288 322 276 338T263 372Q263 381 265 388T270 400T273 405Q271 407 250 401Q234 393 226 386Q179 341 179 207V154Q179 141 179 127T179 101T180 81T180 66V61Q181 59 183 57T188 54T193 51T200 49T207 48T216 47T225 47T235 46T245 46H276V0H267Q249 3 140 3Q37 3 28 0H20V46H36Z" transform="translate(500,0)"></path><path data-c="67" d="M329 409Q373 453 429 453Q459 453 472 434T485 396Q485 382 476 371T449 360Q416 360 412 390Q410 404 415 411Q415 412 416 414V415Q388 412 363 393Q355 388 355 386Q355 385 359 381T368 369T379 351T388 325T392 292Q392 230 343 187T222 143Q172 143 123 171Q112 153 112 133Q112 98 138 81Q147 75 155 75T227 73Q311 72 335 67Q396 58 431 26Q470 -13 470 -72Q470 -139 392 -175Q332 -206 250 -206Q167 -206 107 -175Q29 -140 29 -75Q29 -39 50 -15T92 18L103 24Q67 55 67 108Q67 155 96 193Q52 237 52 292Q52 355 102 398T223 442Q274 442 318 416L329 409ZM299 343Q294 371 273 387T221 404Q192 404 171 388T145 343Q142 326 142 292Q142 248 149 227T179 192Q196 182 222 182Q244 182 260 189T283 207T294 227T299 242Q302 258 302 292T299 343ZM403 -75Q403 -50 389 -34T348 -11T299 -2T245 0H218Q151 0 138 -6Q118 -15 107 -34T95 -74Q95 -84 101 -97T122 -127T170 -155T250 -167Q319 -167 361 -139T403 -75Z" transform="translate(892,0)"></path></g><g data-mml-node="mo" transform="translate(7705.2,0)"><path data-c="2061" d=""></path></g><g data-mml-node="munder" transform="translate(7871.9,0)"><g data-mml-node="mo"><path data-c="6D" d="M41 46H55Q94 46 102 60V68Q102 77 102 91T102 122T103 161T103 203Q103 234 103 269T102 328V351Q99 370 88 376T43 385H25V408Q25 431 27 431L37 432Q47 433 65 434T102 436Q119 437 138 438T167 441T178 442H181V402Q181 364 182 364T187 369T199 384T218 402T247 421T285 437Q305 442 336 442Q351 442 364 440T387 434T406 426T421 417T432 406T441 395T448 384T452 374T455 366L457 361L460 365Q463 369 466 373T475 384T488 397T503 410T523 422T546 432T572 439T603 442Q729 442 740 329Q741 322 741 190V104Q741 66 743 59T754 49Q775 46 803 46H819V0H811L788 1Q764 2 737 2T699 3Q596 3 587 0H579V46H595Q656 46 656 62Q657 64 657 200Q656 335 655 343Q649 371 635 385T611 402T585 404Q540 404 506 370Q479 343 472 315T464 232V168V108Q464 78 465 68T468 55T477 49Q498 46 526 46H542V0H534L510 1Q487 2 460 2T422 3Q319 3 310 0H302V46H318Q379 46 379 62Q380 64 380 200Q379 335 378 343Q372 371 358 385T334 402T308 404Q263 404 229 370Q202 343 195 315T187 232V168V108Q187 78 188 68T191 55T200 49Q221 46 249 46H265V0H257L234 1Q210 2 183 2T145 3Q42 3 33 0H25V46H41Z"></path><path data-c="61" d="M137 305T115 305T78 320T63 359Q63 394 97 421T218 448Q291 448 336 416T396 340Q401 326 401 309T402 194V124Q402 76 407 58T428 40Q443 40 448 56T453 109V145H493V106Q492 66 490 59Q481 29 455 12T400 -6T353 12T329 54V58L327 55Q325 52 322 49T314 40T302 29T287 17T269 6T247 -2T221 -8T190 -11Q130 -11 82 20T34 107Q34 128 41 147T68 188T116 225T194 253T304 268H318V290Q318 324 312 340Q290 411 215 411Q197 411 181 410T156 406T148 403Q170 388 170 359Q170 334 154 320ZM126 106Q126 75 150 51T209 26Q247 26 276 49T315 109Q317 116 318 175Q318 233 317 233Q309 233 296 232T251 223T193 203T147 166T126 106Z" transform="translate(833,0)"></path><path data-c="78" d="M201 0Q189 3 102 3Q26 3 17 0H11V46H25Q48 47 67 52T96 61T121 78T139 96T160 122T180 150L226 210L168 288Q159 301 149 315T133 336T122 351T113 363T107 370T100 376T94 379T88 381T80 383Q74 383 44 385H16V431H23Q59 429 126 429Q219 429 229 431H237V385Q201 381 201 369Q201 367 211 353T239 315T268 274L272 270L297 304Q329 345 329 358Q329 364 327 369T322 376T317 380T310 384L307 385H302V431H309Q324 428 408 428Q487 428 493 431H499V385H492Q443 385 411 368Q394 360 377 341T312 257L296 236L358 151Q424 61 429 57T446 50Q464 46 499 46H516V0H510H502Q494 1 482 1T457 2T432 2T414 3Q403 3 377 3T327 1L304 0H295V46H298Q309 46 320 51T331 63Q331 65 291 120L250 175Q249 174 219 133T185 88Q181 83 181 74Q181 63 188 55T206 46Q208 46 208 23V0H201Z" transform="translate(1333,0)"></path></g><g data-mml-node="TeXAtom" transform="translate(564.6,-645.4) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mo" transform="translate(345,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path></g><g data-mml-node="mi" transform="translate(623,0)"><path data-c="1D457" d="M297 596Q297 627 318 644T361 661Q378 661 389 651T403 623Q403 595 384 576T340 557Q322 557 310 567T297 596ZM288 376Q288 405 262 405Q240 405 220 393T185 362T161 325T144 293L137 279Q135 278 121 278H107Q101 284 101 286T105 299Q126 348 164 391T252 441Q253 441 260 441T272 442Q296 441 316 432Q341 418 354 401T367 348V332L318 133Q267 -67 264 -75Q246 -125 194 -164T75 -204Q25 -204 7 -183T-12 -137Q-12 -110 7 -91T53 -71Q70 -71 82 -81T95 -112Q95 -148 63 -167Q69 -168 77 -168Q111 -168 139 -140T182 -74L193 -32Q204 11 219 72T251 197T278 308T289 365Q289 372 288 376Z"></path></g></g></g><g data-mml-node="mi" transform="translate(9899.6,0)"><path data-c="1D443" d="M287 628Q287 635 230 637Q206 637 199 638T192 648Q192 649 194 659Q200 679 203 681T397 683Q587 682 600 680Q664 669 707 631T751 530Q751 453 685 389Q616 321 507 303Q500 302 402 301H307L277 182Q247 66 247 59Q247 55 248 54T255 50T272 48T305 46H336Q342 37 342 35Q342 19 335 5Q330 0 319 0Q316 0 282 1T182 2Q120 2 87 2T51 1Q33 1 33 11Q33 13 36 25Q40 41 44 43T67 46Q94 46 127 49Q141 52 146 61Q149 65 218 339T287 628ZM645 554Q645 567 643 575T634 597T609 619T560 635Q553 636 480 637Q463 637 445 637T416 636T404 636Q391 635 386 627Q384 621 367 550T332 412T314 344Q314 342 395 342H407H430Q542 342 590 392Q617 419 631 471T645 554Z"></path></g><g data-mml-node="mo" transform="translate(10650.6,0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="mi" transform="translate(11039.6,0)"><path data-c="1D460" d="M131 289Q131 321 147 354T203 415T300 442Q362 442 390 415T419 355Q419 323 402 308T364 292Q351 292 340 300T328 326Q328 342 337 354T354 372T367 378Q368 378 368 379Q368 382 361 388T336 399T297 405Q249 405 227 379T204 326Q204 301 223 291T278 274T330 259Q396 230 396 163Q396 135 385 107T352 51T289 7T195 -10Q118 -10 86 19T53 87Q53 126 74 143T118 160Q133 160 146 151T160 120Q160 94 142 76T111 58Q109 57 108 57T107 55Q108 52 115 47T146 34T201 27Q237 27 263 38T301 66T318 97T323 122Q323 150 302 164T254 181T195 196T148 231Q131 256 131 289Z"></path></g><g data-mml-node="mi" transform="translate(11508.6,0)"><path data-c="1D461" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path></g><g data-mml-node="mi" transform="translate(11869.6,0)"><path data-c="1D44E" d="M33 157Q33 258 109 349T280 441Q331 441 370 392Q386 422 416 422Q429 422 439 414T449 394Q449 381 412 234T374 68Q374 43 381 35T402 26Q411 27 422 35Q443 55 463 131Q469 151 473 152Q475 153 483 153H487Q506 153 506 144Q506 138 501 117T481 63T449 13Q436 0 417 -8Q409 -10 393 -10Q359 -10 336 5T306 36L300 51Q299 52 296 50Q294 48 292 46Q233 -10 172 -10Q117 -10 75 30T33 157ZM351 328Q351 334 346 350T323 385T277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q217 26 254 59T298 110Q300 114 325 217T351 328Z"></path></g><g data-mml-node="mi" transform="translate(12398.6,0)"><path data-c="1D45F" d="M21 287Q22 290 23 295T28 317T38 348T53 381T73 411T99 433T132 442Q161 442 183 430T214 408T225 388Q227 382 228 382T236 389Q284 441 347 441H350Q398 441 422 400Q430 381 430 363Q430 333 417 315T391 292T366 288Q346 288 334 299T322 328Q322 376 378 392Q356 405 342 405Q286 405 239 331Q229 315 224 298T190 165Q156 25 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 114 189T154 366Q154 405 128 405Q107 405 92 377T68 316T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(12849.6,0)"><path data-c="1D461" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path></g><g data-mml-node="mo" transform="translate(13488.3,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="mi" transform="translate(14544.1,0)"><path data-c="1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mo" transform="translate(14889.1,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path></g><g data-mml-node="mi" transform="translate(15333.8,0)"><path data-c="1D452" d="M39 168Q39 225 58 272T107 350T174 402T244 433T307 442H310Q355 442 388 420T421 355Q421 265 310 237Q261 224 176 223Q139 223 138 221Q138 219 132 186T125 128Q125 81 146 54T209 26T302 45T394 111Q403 121 406 121Q410 121 419 112T429 98T420 82T390 55T344 24T281 -1T205 -11Q126 -11 83 42T39 168ZM373 353Q367 405 305 405Q272 405 244 391T199 357T170 316T154 280T149 261Q149 260 169 260Q282 260 327 284T373 353Z"></path></g><g data-mml-node="mi" transform="translate(15799.8,0)"><path data-c="1D45B" d="M21 287Q22 293 24 303T36 341T56 388T89 425T135 442Q171 442 195 424T225 390T231 369Q231 367 232 367L243 378Q304 442 382 442Q436 442 469 415T503 336T465 179T427 52Q427 26 444 26Q450 26 453 27Q482 32 505 65T540 145Q542 153 560 153Q580 153 580 145Q580 144 576 130Q568 101 554 73T508 17T439 -10Q392 -10 371 17T350 73Q350 92 386 193T423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 180T152 343Q153 348 153 366Q153 405 129 405Q91 405 66 305Q60 285 60 284Q58 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(16399.8,0)"><path data-c="1D451" d="M366 683Q367 683 438 688T511 694Q523 694 523 686Q523 679 450 384T375 83T374 68Q374 26 402 26Q411 27 422 35Q443 55 463 131Q469 151 473 152Q475 153 483 153H487H491Q506 153 506 145Q506 140 503 129Q490 79 473 48T445 8T417 -8Q409 -10 393 -10Q359 -10 336 5T306 36L300 51Q299 52 296 50Q294 48 292 46Q233 -10 172 -10Q117 -10 75 30T33 157Q33 205 53 255T101 341Q148 398 195 420T280 442Q336 442 364 400Q369 394 369 396Q370 400 396 505T424 616Q424 629 417 632T378 637H357Q351 643 351 645T353 664Q358 683 366 683ZM352 326Q329 405 277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q233 26 290 98L298 109L352 326Z"></path></g><g data-mml-node="mo" transform="translate(17197.6,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="mi" transform="translate(18253.3,0)"><path data-c="1D457" d="M297 596Q297 627 318 644T361 661Q378 661 389 651T403 623Q403 595 384 576T340 557Q322 557 310 567T297 596ZM288 376Q288 405 262 405Q240 405 220 393T185 362T161 325T144 293L137 279Q135 278 121 278H107Q101 284 101 286T105 299Q126 348 164 391T252 441Q253 441 260 441T272 442Q296 441 316 432Q341 418 354 401T367 348V332L318 133Q267 -67 264 -75Q246 -125 194 -164T75 -204Q25 -204 7 -183T-12 -137Q-12 -110 7 -91T53 -71Q70 -71 82 -81T95 -112Q95 -148 63 -167Q69 -168 77 -168Q111 -168 139 -140T182 -74L193 -32Q204 11 219 72T251 197T278 308T289 365Q289 372 288 376Z"></path></g><g data-mml-node="mo" transform="translate(18665.3,0) translate(0 -0.5)"><path data-c="7C" d="M139 -249H137Q125 -249 119 -235V251L120 737Q130 750 139 750Q152 750 159 735V-235Q151 -249 141 -249H139Z"></path></g><g data-mml-node="mi" transform="translate(18943.3,0)"><path data-c="1D436" d="M50 252Q50 367 117 473T286 641T490 704Q580 704 633 653Q642 643 648 636T656 626L657 623Q660 623 684 649Q691 655 699 663T715 679T725 690L740 705H746Q760 705 760 698Q760 694 728 561Q692 422 692 421Q690 416 687 415T669 413H653Q647 419 647 422Q647 423 648 429T650 449T651 481Q651 552 619 605T510 659Q484 659 454 652T382 628T299 572T226 479Q194 422 175 346T156 222Q156 108 232 58Q280 24 350 24Q441 24 512 92T606 240Q610 253 612 255T628 257Q648 257 648 248Q648 243 647 239Q618 132 523 55T319 -22Q206 -22 128 53T50 252Z"></path></g><g data-mml-node="mo" transform="translate(19703.3,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path></g><g data-mml-node="mi" transform="translate(20148,0)"><path data-c="1D444" d="M399 -80Q399 -47 400 -30T402 -11V-7L387 -11Q341 -22 303 -22Q208 -22 138 35T51 201Q50 209 50 244Q50 346 98 438T227 601Q351 704 476 704Q514 704 524 703Q621 689 680 617T740 435Q740 255 592 107Q529 47 461 16L444 8V3Q444 2 449 -24T470 -66T516 -82Q551 -82 583 -60T625 -3Q631 11 638 11Q647 11 649 2Q649 -6 639 -34T611 -100T557 -165T481 -194Q399 -194 399 -87V-80ZM636 468Q636 523 621 564T580 625T530 655T477 665Q429 665 379 640Q277 591 215 464T153 216Q153 110 207 59Q231 38 236 38V46Q236 86 269 120T347 155Q372 155 390 144T417 114T429 82T435 55L448 64Q512 108 557 185T619 334T636 468ZM314 18Q362 18 404 39L403 49Q399 104 366 115Q354 117 347 117Q344 117 341 117T337 118Q317 118 296 98T274 52Q274 18 314 18Z"></path></g><g data-mml-node="mo" transform="translate(20939,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g></g></g></svg></mjx-container></p>
<h2 id="数据处理"><a href="#数据处理" class="headerlink" title="数据处理"></a>数据处理</h2><h3 id="SQuAD-数据格式"><a href="#SQuAD-数据格式" class="headerlink" title="SQuAD 数据格式"></a>SQuAD 数据格式</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> json</span><br><span class="line"><span class="keyword">from</span> dataclasses <span class="keyword">import</span> dataclass</span><br><span class="line"><span class="keyword">from</span> typing <span class="keyword">import</span> <span class="type">List</span>, <span class="type">Optional</span></span><br><span class="line"></span><br><span class="line"><span class="meta">@dataclass</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Example</span>:</span><br><span class="line">    context: <span class="built_in">str</span></span><br><span class="line">    question: <span class="built_in">str</span></span><br><span class="line">    answer_text: <span class="built_in">str</span></span><br><span class="line">    start_position: <span class="built_in">int</span></span><br><span class="line">    end_position: <span class="built_in">int</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">load_squad</span>(<span class="params">file_path: <span class="built_in">str</span></span>) -&gt; <span class="type">List</span>[Example]:</span><br><span class="line">    <span class="keyword">with</span> <span class="built_in">open</span>(file_path, <span class="string">'r'</span>, encoding=<span class="string">'utf-8'</span>) <span class="keyword">as</span> f:</span><br><span class="line">        data = json.load(f)</span><br><span class="line">    </span><br><span class="line">    examples = []</span><br><span class="line">    <span class="keyword">for</span> article <span class="keyword">in</span> data[<span class="string">'data'</span>]:</span><br><span class="line">        <span class="keyword">for</span> paragraph <span class="keyword">in</span> article[<span class="string">'paragraphs'</span>]:</span><br><span class="line">            context = paragraph[<span class="string">'context'</span>]</span><br><span class="line">            <span class="keyword">for</span> qa <span class="keyword">in</span> paragraph[<span class="string">'qas'</span>]:</span><br><span class="line">                question = qa[<span class="string">'question'</span>]</span><br><span class="line">                <span class="keyword">if</span> qa.get(<span class="string">'is_impossible'</span>, <span class="literal">False</span>):</span><br><span class="line">                    <span class="keyword">continue</span></span><br><span class="line">                answer = qa[<span class="string">'answers'</span>][<span class="number">0</span>]</span><br><span class="line">                examples.append(Example(</span><br><span class="line">                    context=context,</span><br><span class="line">                    question=question,</span><br><span class="line">                    answer_text=answer[<span class="string">'text'</span>],</span><br><span class="line">                    start_position=answer[<span class="string">'answer_start'</span>],</span><br><span class="line">                    end_position=answer[<span class="string">'answer_start'</span>] + <span class="built_in">len</span>(answer[<span class="string">'text'</span>])</span><br><span class="line">                ))</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> examples</span><br></pre></td></tr></table></figure>

<h3 id="Tokenization"><a href="#Tokenization" class="headerlink" title="Tokenization"></a>Tokenization</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> transformers <span class="keyword">import</span> AutoTokenizer</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">MRCTokenizer</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, model_name: <span class="built_in">str</span>, max_length: <span class="built_in">int</span> = <span class="number">384</span>, doc_stride: <span class="built_in">int</span> = <span class="number">128</span></span>):</span><br><span class="line">        <span class="variable language_">self</span>.tokenizer = AutoTokenizer.from_pretrained(model_name)</span><br><span class="line">        <span class="variable language_">self</span>.max_length = max_length</span><br><span class="line">        <span class="variable language_">self</span>.doc_stride = doc_stride</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">encode</span>(<span class="params">self, example: Example</span>):</span><br><span class="line">        <span class="comment"># Tokenize question and context</span></span><br><span class="line">        encoding = <span class="variable language_">self</span>.tokenizer(</span><br><span class="line">            example.question,</span><br><span class="line">            example.context,</span><br><span class="line">            max_length=<span class="variable language_">self</span>.max_length,</span><br><span class="line">            truncation=<span class="string">'only_second'</span>,</span><br><span class="line">            stride=<span class="variable language_">self</span>.doc_stride,</span><br><span class="line">            return_overflowing_tokens=<span class="literal">True</span>,</span><br><span class="line">            return_offsets_mapping=<span class="literal">True</span>,</span><br><span class="line">            padding=<span class="string">'max_length'</span>,</span><br><span class="line">        )</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 找到答案在 token 序列中的位置</span></span><br><span class="line">        offset_mapping = encoding[<span class="string">'offset_mapping'</span>][<span class="number">0</span>]</span><br><span class="line">        </span><br><span class="line">        start_token = <span class="literal">None</span></span><br><span class="line">        end_token = <span class="literal">None</span></span><br><span class="line">        </span><br><span class="line">        <span class="keyword">for</span> idx, (start, end) <span class="keyword">in</span> <span class="built_in">enumerate</span>(offset_mapping):</span><br><span class="line">            <span class="keyword">if</span> start &lt;= example.start_position &lt; end:</span><br><span class="line">                start_token = idx</span><br><span class="line">            <span class="keyword">if</span> start &lt; example.end_position &lt;= end:</span><br><span class="line">                end_token = idx</span><br><span class="line">                <span class="keyword">break</span></span><br><span class="line">        </span><br><span class="line">        <span class="keyword">return</span> {</span><br><span class="line">            <span class="string">'input_ids'</span>: encoding[<span class="string">'input_ids'</span>][<span class="number">0</span>],</span><br><span class="line">            <span class="string">'attention_mask'</span>: encoding[<span class="string">'attention_mask'</span>][<span class="number">0</span>],</span><br><span class="line">            <span class="string">'start_position'</span>: start_token <span class="keyword">or</span> <span class="number">0</span>,</span><br><span class="line">            <span class="string">'end_position'</span>: end_token <span class="keyword">or</span> <span class="number">0</span>,</span><br><span class="line">        }</span><br></pre></td></tr></table></figure>

<h2 id="模型实现"><a href="#模型实现" class="headerlink" title="模型实现"></a>模型实现</h2><h3 id="基于-BERT-的-MRC-模型"><a href="#基于-BERT-的-MRC-模型" class="headerlink" title="基于 BERT 的 MRC 模型"></a>基于 BERT 的 MRC 模型</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">from</span> transformers <span class="keyword">import</span> AutoModel</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">MRCModel</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, model_name: <span class="built_in">str</span>, dropout: <span class="built_in">float</span> = <span class="number">0.1</span></span>):</span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        <span class="variable language_">self</span>.bert = AutoModel.from_pretrained(model_name)</span><br><span class="line">        hidden_size = <span class="variable language_">self</span>.bert.config.hidden_size</span><br><span class="line">        </span><br><span class="line">        <span class="variable language_">self</span>.dropout = nn.Dropout(dropout)</span><br><span class="line">        <span class="variable language_">self</span>.start_classifier = nn.Linear(hidden_size, <span class="number">1</span>)</span><br><span class="line">        <span class="variable language_">self</span>.end_classifier = nn.Linear(hidden_size, <span class="number">1</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params"></span></span><br><span class="line"><span class="params">        self,</span></span><br><span class="line"><span class="params">        input_ids: torch.Tensor,</span></span><br><span class="line"><span class="params">        attention_mask: torch.Tensor,</span></span><br><span class="line"><span class="params">        start_positions: <span class="type">Optional</span>[torch.Tensor] = <span class="literal">None</span>,</span></span><br><span class="line"><span class="params">        end_positions: <span class="type">Optional</span>[torch.Tensor] = <span class="literal">None</span>,</span></span><br><span class="line"><span class="params">    </span>):</span><br><span class="line">        outputs = <span class="variable language_">self</span>.bert(input_ids=input_ids, attention_mask=attention_mask)</span><br><span class="line">        sequence_output = <span class="variable language_">self</span>.dropout(outputs.last_hidden_state)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># (batch, seq_len, 1) -&gt; (batch, seq_len)</span></span><br><span class="line">        start_logits = <span class="variable language_">self</span>.start_classifier(sequence_output).squeeze(-<span class="number">1</span>)</span><br><span class="line">        end_logits = <span class="variable language_">self</span>.end_classifier(sequence_output).squeeze(-<span class="number">1</span>)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># Mask padding tokens</span></span><br><span class="line">        start_logits = start_logits.masked_fill(~attention_mask.<span class="built_in">bool</span>(), -<span class="number">1e9</span>)</span><br><span class="line">        end_logits = end_logits.masked_fill(~attention_mask.<span class="built_in">bool</span>(), -<span class="number">1e9</span>)</span><br><span class="line">        </span><br><span class="line">        loss = <span class="literal">None</span></span><br><span class="line">        <span class="keyword">if</span> start_positions <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span> <span class="keyword">and</span> end_positions <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">            loss_fct = nn.CrossEntropyLoss()</span><br><span class="line">            start_loss = loss_fct(start_logits, start_positions)</span><br><span class="line">            end_loss = loss_fct(end_logits, end_positions)</span><br><span class="line">            loss = (start_loss + end_loss) / <span class="number">2</span></span><br><span class="line">        </span><br><span class="line">        <span class="keyword">return</span> {</span><br><span class="line">            <span class="string">'loss'</span>: loss,</span><br><span class="line">            <span class="string">'start_logits'</span>: start_logits,</span><br><span class="line">            <span class="string">'end_logits'</span>: end_logits,</span><br><span class="line">        }</span><br></pre></td></tr></table></figure>

<h3 id="改进：联合-Start-End-预测"><a href="#改进：联合-Start-End-预测" class="headerlink" title="改进：联合 Start-End 预测"></a>改进：联合 Start-End 预测</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">JointMRCModel</span>(nn.Module):</span><br><span class="line">    <span class="string">"""联合预测 start 和 end，考虑 start-end 依赖"""</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, model_name: <span class="built_in">str</span>, max_answer_length: <span class="built_in">int</span> = <span class="number">30</span></span>):</span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        <span class="variable language_">self</span>.bert = AutoModel.from_pretrained(model_name)</span><br><span class="line">        hidden_size = <span class="variable language_">self</span>.bert.config.hidden_size</span><br><span class="line">        <span class="variable language_">self</span>.max_answer_length = max_answer_length</span><br><span class="line">        </span><br><span class="line">        <span class="variable language_">self</span>.start_classifier = nn.Linear(hidden_size, <span class="number">1</span>)</span><br><span class="line">        <span class="variable language_">self</span>.end_classifier = nn.Linear(hidden_size * <span class="number">2</span>, <span class="number">1</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, input_ids, attention_mask, start_positions=<span class="literal">None</span>, end_positions=<span class="literal">None</span></span>):</span><br><span class="line">        outputs = <span class="variable language_">self</span>.bert(input_ids=input_ids, attention_mask=attention_mask)</span><br><span class="line">        H = outputs.last_hidden_state  <span class="comment"># (batch, seq_len, hidden)</span></span><br><span class="line">        </span><br><span class="line">        <span class="comment"># Start prediction</span></span><br><span class="line">        start_logits = <span class="variable language_">self</span>.start_classifier(H).squeeze(-<span class="number">1</span>)</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">if</span> <span class="variable language_">self</span>.training <span class="keyword">and</span> start_positions <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">            <span class="comment"># 训练时使用真实的 start 位置</span></span><br><span class="line">            start_indices = start_positions.unsqueeze(-<span class="number">1</span>).unsqueeze(-<span class="number">1</span>)</span><br><span class="line">            start_repr = H.gather(<span class="number">1</span>, start_indices.expand(-<span class="number">1</span>, -<span class="number">1</span>, H.size(-<span class="number">1</span>))).squeeze(<span class="number">1</span>)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="comment"># 推理时使用预测的 start 位置</span></span><br><span class="line">            start_indices = start_logits.argmax(dim=-<span class="number">1</span>, keepdim=<span class="literal">True</span>).unsqueeze(-<span class="number">1</span>)</span><br><span class="line">            start_repr = H.gather(<span class="number">1</span>, start_indices.expand(-<span class="number">1</span>, -<span class="number">1</span>, H.size(-<span class="number">1</span>))).squeeze(<span class="number">1</span>)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># End prediction conditioned on start</span></span><br><span class="line">        start_repr_expanded = start_repr.unsqueeze(<span class="number">1</span>).expand(-<span class="number">1</span>, H.size(<span class="number">1</span>), -<span class="number">1</span>)</span><br><span class="line">        end_input = torch.cat([H, start_repr_expanded], dim=-<span class="number">1</span>)</span><br><span class="line">        end_logits = <span class="variable language_">self</span>.end_classifier(end_input).squeeze(-<span class="number">1</span>)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 只允许 end &gt;= start 且在 max_answer_length 范围内</span></span><br><span class="line">        <span class="comment"># 这里简化处理，完整实现需要更复杂的 mask</span></span><br><span class="line">        </span><br><span class="line">        <span class="keyword">return</span> {<span class="string">'start_logits'</span>: start_logits, <span class="string">'end_logits'</span>: end_logits}</span><br></pre></td></tr></table></figure>

<h2 id="训练流程"><a href="#训练流程" class="headerlink" title="训练流程"></a>训练流程</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> DataLoader, Dataset</span><br><span class="line"><span class="keyword">from</span> transformers <span class="keyword">import</span> get_linear_schedule_with_warmup</span><br><span class="line"><span class="keyword">from</span> tqdm <span class="keyword">import</span> tqdm</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">train</span>(<span class="params">model, train_dataloader, val_dataloader, epochs=<span class="number">3</span>, lr=<span class="number">3e-5</span></span>):</span><br><span class="line">    optimizer = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=<span class="number">0.01</span>)</span><br><span class="line">    </span><br><span class="line">    total_steps = <span class="built_in">len</span>(train_dataloader) * epochs</span><br><span class="line">    scheduler = get_linear_schedule_with_warmup(</span><br><span class="line">        optimizer, </span><br><span class="line">        num_warmup_steps=<span class="built_in">int</span>(<span class="number">0.1</span> * total_steps),</span><br><span class="line">        num_training_steps=total_steps</span><br><span class="line">    )</span><br><span class="line">    </span><br><span class="line">    device = torch.device(<span class="string">'cuda'</span> <span class="keyword">if</span> torch.cuda.is_available() <span class="keyword">else</span> <span class="string">'cpu'</span>)</span><br><span class="line">    model.to(device)</span><br><span class="line">    </span><br><span class="line">    best_f1 = <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(epochs):</span><br><span class="line">        model.train()</span><br><span class="line">        total_loss = <span class="number">0</span></span><br><span class="line">        </span><br><span class="line">        <span class="keyword">for</span> batch <span class="keyword">in</span> tqdm(train_dataloader, desc=<span class="string">f'Epoch <span class="subst">{epoch+<span class="number">1</span>}</span>'</span>):</span><br><span class="line">            batch = {k: v.to(device) <span class="keyword">for</span> k, v <span class="keyword">in</span> batch.items()}</span><br><span class="line">            </span><br><span class="line">            outputs = model(**batch)</span><br><span class="line">            loss = outputs[<span class="string">'loss'</span>]</span><br><span class="line">            </span><br><span class="line">            loss.backward()</span><br><span class="line">            torch.nn.utils.clip_grad_norm_(model.parameters(), <span class="number">1.0</span>)</span><br><span class="line">            </span><br><span class="line">            optimizer.step()</span><br><span class="line">            scheduler.step()</span><br><span class="line">            optimizer.zero_grad()</span><br><span class="line">            </span><br><span class="line">            total_loss += loss.item()</span><br><span class="line">        </span><br><span class="line">        avg_loss = total_loss / <span class="built_in">len</span>(train_dataloader)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f'Epoch <span class="subst">{epoch+<span class="number">1</span>}</span>, Loss: <span class="subst">{avg_loss:<span class="number">.4</span>f}</span>'</span>)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># Validation</span></span><br><span class="line">        f1 = evaluate(model, val_dataloader, device)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f'Validation F1: <span class="subst">{f1:<span class="number">.4</span>f}</span>'</span>)</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">if</span> f1 &gt; best_f1:</span><br><span class="line">            best_f1 = f1</span><br><span class="line">            torch.save(model.state_dict(), <span class="string">'best_model.pt'</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> model</span><br></pre></td></tr></table></figure>

<h2 id="评估与推理"><a href="#评估与推理" class="headerlink" title="评估与推理"></a>评估与推理</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> re</span><br><span class="line"><span class="keyword">import</span> string</span><br><span class="line"><span class="keyword">from</span> collections <span class="keyword">import</span> Counter</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">normalize_answer</span>(<span class="params">s</span>):</span><br><span class="line">    <span class="string">"""标准化答案用于评估"""</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">remove_articles</span>(<span class="params">text</span>):</span><br><span class="line">        <span class="keyword">return</span> re.sub(<span class="string">r'\b(a|an|the)\b'</span>, <span class="string">' '</span>, text)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">white_space_fix</span>(<span class="params">text</span>):</span><br><span class="line">        <span class="keyword">return</span> <span class="string">' '</span>.join(text.split())</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">remove_punc</span>(<span class="params">text</span>):</span><br><span class="line">        exclude = <span class="built_in">set</span>(string.punctuation)</span><br><span class="line">        <span class="keyword">return</span> <span class="string">''</span>.join(ch <span class="keyword">for</span> ch <span class="keyword">in</span> text <span class="keyword">if</span> ch <span class="keyword">not</span> <span class="keyword">in</span> exclude)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">lower</span>(<span class="params">text</span>):</span><br><span class="line">        <span class="keyword">return</span> text.lower()</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> white_space_fix(remove_articles(remove_punc(lower(s))))</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">compute_f1</span>(<span class="params">pred: <span class="built_in">str</span>, gold: <span class="built_in">str</span></span>) -&gt; <span class="built_in">float</span>:</span><br><span class="line">    pred_tokens = normalize_answer(pred).split()</span><br><span class="line">    gold_tokens = normalize_answer(gold).split()</span><br><span class="line">    </span><br><span class="line">    common = Counter(pred_tokens) &amp; Counter(gold_tokens)</span><br><span class="line">    num_same = <span class="built_in">sum</span>(common.values())</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">if</span> num_same == <span class="number">0</span>:</span><br><span class="line">        <span class="keyword">return</span> <span class="number">0</span></span><br><span class="line">    </span><br><span class="line">    precision = num_same / <span class="built_in">len</span>(pred_tokens)</span><br><span class="line">    recall = num_same / <span class="built_in">len</span>(gold_tokens)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> <span class="number">2</span> * precision * recall / (precision + recall)</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">predict</span>(<span class="params">model, tokenizer, context: <span class="built_in">str</span>, question: <span class="built_in">str</span>, device</span>):</span><br><span class="line">    <span class="string">"""单条推理"""</span></span><br><span class="line">    model.<span class="built_in">eval</span>()</span><br><span class="line">    </span><br><span class="line">    encoding = tokenizer(</span><br><span class="line">        question, context,</span><br><span class="line">        max_length=<span class="number">384</span>,</span><br><span class="line">        truncation=<span class="string">'only_second'</span>,</span><br><span class="line">        return_tensors=<span class="string">'pt'</span></span><br><span class="line">    )</span><br><span class="line">    </span><br><span class="line">    encoding = {k: v.to(device) <span class="keyword">for</span> k, v <span class="keyword">in</span> encoding.items()}</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">        outputs = model(**encoding)</span><br><span class="line">    </span><br><span class="line">    start_idx = outputs[<span class="string">'start_logits'</span>].argmax().item()</span><br><span class="line">    end_idx = outputs[<span class="string">'end_logits'</span>].argmax().item()</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 确保 end &gt;= start</span></span><br><span class="line">    <span class="keyword">if</span> end_idx &lt; start_idx:</span><br><span class="line">        end_idx = start_idx</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 解码答案</span></span><br><span class="line">    answer_tokens = encoding[<span class="string">'input_ids'</span>][<span class="number">0</span>][start_idx:end_idx+<span class="number">1</span>]</span><br><span class="line">    answer = tokenizer.decode(answer_tokens, skip_special_tokens=<span class="literal">True</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> answer</span><br></pre></td></tr></table></figure>

<h2 id="现代方法：使用-LLM"><a href="#现代方法：使用-LLM" class="headerlink" title="现代方法：使用 LLM"></a>现代方法：使用 LLM</h2><p>对于更复杂的问答需求，可以使用 LLM：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> openai <span class="keyword">import</span> OpenAI</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">llm_qa</span>(<span class="params">context: <span class="built_in">str</span>, question: <span class="built_in">str</span></span>) -&gt; <span class="built_in">str</span>:</span><br><span class="line">    client = OpenAI()</span><br><span class="line">    </span><br><span class="line">    response = client.chat.completions.create(</span><br><span class="line">        model=<span class="string">"gpt-4"</span>,</span><br><span class="line">        messages=[</span><br><span class="line">            {<span class="string">"role"</span>: <span class="string">"system"</span>, <span class="string">"content"</span>: <span class="string">"你是一个问答助手。根据给定的上下文回答问题。如果答案不在上下文中，请说'无法回答'。"</span>},</span><br><span class="line">            {<span class="string">"role"</span>: <span class="string">"user"</span>, <span class="string">"content"</span>: <span class="string">f"上下文：<span class="subst">{context}</span>\n\n问题：<span class="subst">{question}</span>"</span>}</span><br><span class="line">        ],</span><br><span class="line">        temperature=<span class="number">0</span></span><br><span class="line">    )</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> response.choices[<span class="number">0</span>].message.content</span><br></pre></td></tr></table></figure>

<h2 id="延伸阅读"><a href="#延伸阅读" class="headerlink" title="延伸阅读"></a>延伸阅读</h2><ul>
<li><a target="_blank" rel="noopener" href="https://rajpurkar.github.io/SQuAD-explorer/">SQuAD Dataset</a></li>
<li><a target="_blank" rel="noopener" href="https://huggingface.co/docs/transformers/task_summary#question-answering">Hugging Face QA Pipeline</a></li>
<li><a target="_blank" rel="noopener" href="https://ai.google.com/research/NaturalQuestions">Natural Questions</a></li>
</ul>
<hr>
<blockquote>
<p>转载请注明出处</p>
</blockquote>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://foosynaptic.github.io/2019/11/19/%E6%9D%A1%E4%BB%B6%E9%9A%8F%E6%9C%BA%E5%9C%BA%E7%9A%84%E5%8E%9F%E7%90%86%E4%BB%A5%E5%8F%8A%E4%BB%8E%E9%9B%B6%E5%AE%9E%E7%8E%B0/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="fooSynaptic">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="fooSynaptic">
      <meta itemprop="description" content="Head first to the Truth as Synaptic.">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content=" | fooSynaptic">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2019/11/19/%E6%9D%A1%E4%BB%B6%E9%9A%8F%E6%9C%BA%E5%9C%BA%E7%9A%84%E5%8E%9F%E7%90%86%E4%BB%A5%E5%8F%8A%E4%BB%8E%E9%9B%B6%E5%AE%9E%E7%8E%B0/" class="post-title-link" itemprop="url">条件随机场：原理与实现</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2019-11-19 08:51:23" itemprop="dateCreated datePublished" datetime="2019-11-19T08:51:23+08:00">2019-11-19</time>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <p>条件随机场 (CRF) 是序列标注的经典模型，尽管深度学习时代 BERT 等模型大放异彩，CRF 层仍然在 NER、词性标注等任务中发挥关键作用。</p>
<h2 id="为什么需要-CRF？"><a href="#为什么需要-CRF？" class="headerlink" title="为什么需要 CRF？"></a>为什么需要 CRF？</h2><h3 id="独立分类的问题"><a href="#独立分类的问题" class="headerlink" title="独立分类的问题"></a>独立分类的问题</h3><p>如果对每个位置独立分类：</p>
<p><mjx-container class="MathJax" jax="SVG" display="true"><svg style="vertical-align: -1.937ex;" xmlns="http://www.w3.org/2000/svg" width="20.21ex" height="3.769ex" role="img" focusable="false" viewBox="0 -810 8932.8 1666"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="msub"><g data-mml-node="TeXAtom" data-mjx-texclass="ORD"><g data-mml-node="mover"><g data-mml-node="mi"><path data-c="1D466" d="M21 287Q21 301 36 335T84 406T158 442Q199 442 224 419T250 355Q248 336 247 334Q247 331 231 288T198 191T182 105Q182 62 196 45T238 27Q261 27 281 38T312 61T339 94Q339 95 344 114T358 173T377 247Q415 397 419 404Q432 431 462 431Q475 431 483 424T494 412T496 403Q496 390 447 193T391 -23Q363 -106 294 -155T156 -205Q111 -205 77 -183T43 -117Q43 -95 50 -80T69 -58T89 -48T106 -45Q150 -45 150 -87Q150 -107 138 -122T115 -142T102 -147L99 -148Q101 -153 118 -160T152 -167H160Q177 -167 186 -165Q219 -156 247 -127T290 -65T313 -9T321 21L315 17Q309 13 296 6T270 -6Q250 -11 231 -11Q185 -11 150 11T104 82Q103 89 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mo" transform="translate(300.6,16) translate(-250 0)"><path data-c="5E" d="M112 560L249 694L257 686Q387 562 387 560L361 531Q359 532 303 581L250 627L195 580Q182 569 169 557T148 538L140 532Q138 530 125 546L112 560Z"></path></g></g></g><g data-mml-node="mi" transform="translate(523,-150) scale(0.707)"><path data-c="1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path></g></g><g data-mml-node="mo" transform="translate(1094.7,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="mi" transform="translate(2150.5,0)"><path data-c="61" d="M137 305T115 305T78 320T63 359Q63 394 97 421T218 448Q291 448 336 416T396 340Q401 326 401 309T402 194V124Q402 76 407 58T428 40Q443 40 448 56T453 109V145H493V106Q492 66 490 59Q481 29 455 12T400 -6T353 12T329 54V58L327 55Q325 52 322 49T314 40T302 29T287 17T269 6T247 -2T221 -8T190 -11Q130 -11 82 20T34 107Q34 128 41 147T68 188T116 225T194 253T304 268H318V290Q318 324 312 340Q290 411 215 411Q197 411 181 410T156 406T148 403Q170 388 170 359Q170 334 154 320ZM126 106Q126 75 150 51T209 26Q247 26 276 49T315 109Q317 116 318 175Q318 233 317 233Q309 233 296 232T251 223T193 203T147 166T126 106Z"></path><path data-c="72" d="M36 46H50Q89 46 97 60V68Q97 77 97 91T98 122T98 161T98 203Q98 234 98 269T98 328L97 351Q94 370 83 376T38 385H20V408Q20 431 22 431L32 432Q42 433 60 434T96 436Q112 437 131 438T160 441T171 442H174V373Q213 441 271 441H277Q322 441 343 419T364 373Q364 352 351 337T313 322Q288 322 276 338T263 372Q263 381 265 388T270 400T273 405Q271 407 250 401Q234 393 226 386Q179 341 179 207V154Q179 141 179 127T179 101T180 81T180 66V61Q181 59 183 57T188 54T193 51T200 49T207 48T216 47T225 47T235 46T245 46H276V0H267Q249 3 140 3Q37 3 28 0H20V46H36Z" transform="translate(500,0)"></path><path data-c="67" d="M329 409Q373 453 429 453Q459 453 472 434T485 396Q485 382 476 371T449 360Q416 360 412 390Q410 404 415 411Q415 412 416 414V415Q388 412 363 393Q355 388 355 386Q355 385 359 381T368 369T379 351T388 325T392 292Q392 230 343 187T222 143Q172 143 123 171Q112 153 112 133Q112 98 138 81Q147 75 155 75T227 73Q311 72 335 67Q396 58 431 26Q470 -13 470 -72Q470 -139 392 -175Q332 -206 250 -206Q167 -206 107 -175Q29 -140 29 -75Q29 -39 50 -15T92 18L103 24Q67 55 67 108Q67 155 96 193Q52 237 52 292Q52 355 102 398T223 442Q274 442 318 416L329 409ZM299 343Q294 371 273 387T221 404Q192 404 171 388T145 343Q142 326 142 292Q142 248 149 227T179 192Q196 182 222 182Q244 182 260 189T283 207T294 227T299 242Q302 258 302 292T299 343ZM403 -75Q403 -50 389 -34T348 -11T299 -2T245 0H218Q151 0 138 -6Q118 -15 107 -34T95 -74Q95 -84 101 -97T122 -127T170 -155T250 -167Q319 -167 361 -139T403 -75Z" transform="translate(892,0)"></path></g><g data-mml-node="mo" transform="translate(3542.5,0)"><path data-c="2061" d=""></path></g><g data-mml-node="munder" transform="translate(3709.2,0)"><g data-mml-node="mo"><path data-c="6D" d="M41 46H55Q94 46 102 60V68Q102 77 102 91T102 122T103 161T103 203Q103 234 103 269T102 328V351Q99 370 88 376T43 385H25V408Q25 431 27 431L37 432Q47 433 65 434T102 436Q119 437 138 438T167 441T178 442H181V402Q181 364 182 364T187 369T199 384T218 402T247 421T285 437Q305 442 336 442Q351 442 364 440T387 434T406 426T421 417T432 406T441 395T448 384T452 374T455 366L457 361L460 365Q463 369 466 373T475 384T488 397T503 410T523 422T546 432T572 439T603 442Q729 442 740 329Q741 322 741 190V104Q741 66 743 59T754 49Q775 46 803 46H819V0H811L788 1Q764 2 737 2T699 3Q596 3 587 0H579V46H595Q656 46 656 62Q657 64 657 200Q656 335 655 343Q649 371 635 385T611 402T585 404Q540 404 506 370Q479 343 472 315T464 232V168V108Q464 78 465 68T468 55T477 49Q498 46 526 46H542V0H534L510 1Q487 2 460 2T422 3Q319 3 310 0H302V46H318Q379 46 379 62Q380 64 380 200Q379 335 378 343Q372 371 358 385T334 402T308 404Q263 404 229 370Q202 343 195 315T187 232V168V108Q187 78 188 68T191 55T200 49Q221 46 249 46H265V0H257L234 1Q210 2 183 2T145 3Q42 3 33 0H25V46H41Z"></path><path data-c="61" d="M137 305T115 305T78 320T63 359Q63 394 97 421T218 448Q291 448 336 416T396 340Q401 326 401 309T402 194V124Q402 76 407 58T428 40Q443 40 448 56T453 109V145H493V106Q492 66 490 59Q481 29 455 12T400 -6T353 12T329 54V58L327 55Q325 52 322 49T314 40T302 29T287 17T269 6T247 -2T221 -8T190 -11Q130 -11 82 20T34 107Q34 128 41 147T68 188T116 225T194 253T304 268H318V290Q318 324 312 340Q290 411 215 411Q197 411 181 410T156 406T148 403Q170 388 170 359Q170 334 154 320ZM126 106Q126 75 150 51T209 26Q247 26 276 49T315 109Q317 116 318 175Q318 233 317 233Q309 233 296 232T251 223T193 203T147 166T126 106Z" transform="translate(833,0)"></path><path data-c="78" d="M201 0Q189 3 102 3Q26 3 17 0H11V46H25Q48 47 67 52T96 61T121 78T139 96T160 122T180 150L226 210L168 288Q159 301 149 315T133 336T122 351T113 363T107 370T100 376T94 379T88 381T80 383Q74 383 44 385H16V431H23Q59 429 126 429Q219 429 229 431H237V385Q201 381 201 369Q201 367 211 353T239 315T268 274L272 270L297 304Q329 345 329 358Q329 364 327 369T322 376T317 380T310 384L307 385H302V431H309Q324 428 408 428Q487 428 493 431H499V385H492Q443 385 411 368Q394 360 377 341T312 257L296 236L358 151Q424 61 429 57T446 50Q464 46 499 46H516V0H510H502Q494 1 482 1T457 2T432 2T414 3Q403 3 377 3T327 1L304 0H295V46H298Q309 46 320 51T331 63Q331 65 291 120L250 175Q249 174 219 133T185 88Q181 83 181 74Q181 63 188 55T206 46Q208 46 208 23V0H201Z" transform="translate(1333,0)"></path></g><g data-mml-node="mi" transform="translate(757.3,-611) scale(0.707)"><path data-c="1D466" d="M21 287Q21 301 36 335T84 406T158 442Q199 442 224 419T250 355Q248 336 247 334Q247 331 231 288T198 191T182 105Q182 62 196 45T238 27Q261 27 281 38T312 61T339 94Q339 95 344 114T358 173T377 247Q415 397 419 404Q432 431 462 431Q475 431 483 424T494 412T496 403Q496 390 447 193T391 -23Q363 -106 294 -155T156 -205Q111 -205 77 -183T43 -117Q43 -95 50 -80T69 -58T89 -48T106 -45Q150 -45 150 -87Q150 -107 138 -122T115 -142T102 -147L99 -148Q101 -153 118 -160T152 -167H160Q177 -167 186 -165Q219 -156 247 -127T290 -65T313 -9T321 21L315 17Q309 13 296 6T270 -6Q250 -11 231 -11Q185 -11 150 11T104 82Q103 89 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g></g><g data-mml-node="mi" transform="translate(5736.8,0)"><path data-c="1D443" d="M287 628Q287 635 230 637Q206 637 199 638T192 648Q192 649 194 659Q200 679 203 681T397 683Q587 682 600 680Q664 669 707 631T751 530Q751 453 685 389Q616 321 507 303Q500 302 402 301H307L277 182Q247 66 247 59Q247 55 248 54T255 50T272 48T305 46H336Q342 37 342 35Q342 19 335 5Q330 0 319 0Q316 0 282 1T182 2Q120 2 87 2T51 1Q33 1 33 11Q33 13 36 25Q40 41 44 43T67 46Q94 46 127 49Q141 52 146 61Q149 65 218 339T287 628ZM645 554Q645 567 643 575T634 597T609 619T560 635Q553 636 480 637Q463 637 445 637T416 636T404 636Q391 635 386 627Q384 621 367 550T332 412T314 344Q314 342 395 342H407H430Q542 342 590 392Q617 419 631 471T645 554Z"></path></g><g data-mml-node="mo" transform="translate(6487.8,0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="mi" transform="translate(6876.8,0)"><path data-c="1D466" d="M21 287Q21 301 36 335T84 406T158 442Q199 442 224 419T250 355Q248 336 247 334Q247 331 231 288T198 191T182 105Q182 62 196 45T238 27Q261 27 281 38T312 61T339 94Q339 95 344 114T358 173T377 247Q415 397 419 404Q432 431 462 431Q475 431 483 424T494 412T496 403Q496 390 447 193T391 -23Q363 -106 294 -155T156 -205Q111 -205 77 -183T43 -117Q43 -95 50 -80T69 -58T89 -48T106 -45Q150 -45 150 -87Q150 -107 138 -122T115 -142T102 -147L99 -148Q101 -153 118 -160T152 -167H160Q177 -167 186 -165Q219 -156 247 -127T290 -65T313 -9T321 21L315 17Q309 13 296 6T270 -6Q250 -11 231 -11Q185 -11 150 11T104 82Q103 89 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mo" transform="translate(7366.8,0) translate(0 -0.5)"><path data-c="7C" d="M139 -249H137Q125 -249 119 -235V251L120 737Q130 750 139 750Q152 750 159 735V-235Q151 -249 141 -249H139Z"></path></g><g data-mml-node="msub" transform="translate(7644.8,0)"><g data-mml-node="mi"><path data-c="1D465" d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z"></path></g><g data-mml-node="mi" transform="translate(605,-150) scale(0.707)"><path data-c="1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path></g></g><g data-mml-node="mo" transform="translate(8543.8,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g></g></g></svg></mjx-container></p>
<p>会导致<strong>标签不一致</strong>，例如：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">输入: "北 京 是 中 国 首 都"</span><br><span class="line">错误: B-LOC I-PER O B-LOC I-LOC I-LOC I-LOC</span><br><span class="line">正确: B-LOC I-LOC O B-LOC I-LOC I-LOC I-LOC</span><br></pre></td></tr></table></figure>

<h3 id="CRF-的解决方案"><a href="#CRF-的解决方案" class="headerlink" title="CRF 的解决方案"></a>CRF 的解决方案</h3><p>CRF 建模整个序列的联合概率，考虑<strong>标签之间的转移约束</strong>。</p>
<h2 id="数学原理"><a href="#数学原理" class="headerlink" title="数学原理"></a>数学原理</h2><h3 id="条件概率"><a href="#条件概率" class="headerlink" title="条件概率"></a>条件概率</h3><p><mjx-container class="MathJax" jax="SVG" display="true"><svg style="vertical-align: -2.827ex;" xmlns="http://www.w3.org/2000/svg" width="51.803ex" height="6.785ex" role="img" focusable="false" viewBox="0 -1749.5 22896.8 2999"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D443" d="M287 628Q287 635 230 637Q206 637 199 638T192 648Q192 649 194 659Q200 679 203 681T397 683Q587 682 600 680Q664 669 707 631T751 530Q751 453 685 389Q616 321 507 303Q500 302 402 301H307L277 182Q247 66 247 59Q247 55 248 54T255 50T272 48T305 46H336Q342 37 342 35Q342 19 335 5Q330 0 319 0Q316 0 282 1T182 2Q120 2 87 2T51 1Q33 1 33 11Q33 13 36 25Q40 41 44 43T67 46Q94 46 127 49Q141 52 146 61Q149 65 218 339T287 628ZM645 554Q645 567 643 575T634 597T609 619T560 635Q553 636 480 637Q463 637 445 637T416 636T404 636Q391 635 386 627Q384 621 367 550T332 412T314 344Q314 342 395 342H407H430Q542 342 590 392Q617 419 631 471T645 554Z"></path></g><g data-mml-node="mo" transform="translate(751,0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="mi" transform="translate(1140,0)"><path data-c="1D44C" d="M66 637Q54 637 49 637T39 638T32 641T30 647T33 664T42 682Q44 683 56 683Q104 680 165 680Q288 680 306 683H316Q322 677 322 674T320 656Q316 643 310 637H298Q242 637 242 624Q242 619 292 477T343 333L346 336Q350 340 358 349T379 373T411 410T454 461Q546 568 561 587T577 618Q577 634 545 637Q528 637 528 647Q528 649 530 661Q533 676 535 679T549 683Q551 683 578 682T657 680Q684 680 713 681T746 682Q763 682 763 673Q763 669 760 657T755 643Q753 637 734 637Q662 632 617 587Q608 578 477 424L348 273L322 169Q295 62 295 57Q295 46 363 46Q379 46 384 45T390 35Q390 33 388 23Q384 6 382 4T366 1Q361 1 324 1T232 2Q170 2 138 2T102 1Q84 1 84 9Q84 14 87 24Q88 27 89 30T90 35T91 39T93 42T96 44T101 45T107 45T116 46T129 46Q168 47 180 50T198 63Q201 68 227 171L252 274L129 623Q128 624 127 625T125 627T122 629T118 631T113 633T105 634T96 635T83 636T66 637Z"></path></g><g data-mml-node="mo" transform="translate(1903,0) translate(0 -0.5)"><path data-c="7C" d="M139 -249H137Q125 -249 119 -235V251L120 737Q130 750 139 750Q152 750 159 735V-235Q151 -249 141 -249H139Z"></path></g><g data-mml-node="mi" transform="translate(2181,0)"><path data-c="1D44B" d="M42 0H40Q26 0 26 11Q26 15 29 27Q33 41 36 43T55 46Q141 49 190 98Q200 108 306 224T411 342Q302 620 297 625Q288 636 234 637H206Q200 643 200 645T202 664Q206 677 212 683H226Q260 681 347 681Q380 681 408 681T453 682T473 682Q490 682 490 671Q490 670 488 658Q484 643 481 640T465 637Q434 634 411 620L488 426L541 485Q646 598 646 610Q646 628 622 635Q617 635 609 637Q594 637 594 648Q594 650 596 664Q600 677 606 683H618Q619 683 643 683T697 681T738 680Q828 680 837 683H845Q852 676 852 672Q850 647 840 637H824Q790 636 763 628T722 611T698 593L687 584Q687 585 592 480L505 384Q505 383 536 304T601 142T638 56Q648 47 699 46Q734 46 734 37Q734 35 732 23Q728 7 725 4T711 1Q708 1 678 1T589 2Q528 2 496 2T461 1Q444 1 444 10Q444 11 446 25Q448 35 450 39T455 44T464 46T480 47T506 54Q523 62 523 64Q522 64 476 181L429 299Q241 95 236 84Q232 76 232 72Q232 53 261 47Q262 47 267 47T273 46Q276 46 277 46T280 45T283 42T284 35Q284 26 282 19Q279 6 276 4T261 1Q258 1 243 1T201 2T142 2Q64 2 42 0Z"></path></g><g data-mml-node="mo" transform="translate(3033,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g><g data-mml-node="mo" transform="translate(3699.8,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="mfrac" transform="translate(4755.6,0)"><g data-mml-node="mn" transform="translate(1146.5,676)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path></g><g data-mml-node="mrow" transform="translate(220,-710)"><g data-mml-node="mi"><path data-c="1D44D" d="M58 8Q58 23 64 35Q64 36 329 334T596 635L586 637Q575 637 512 637H500H476Q442 637 420 635T365 624T311 598T266 548T228 469Q227 466 226 463T224 458T223 453T222 450L221 448Q218 443 202 443Q185 443 182 453L214 561Q228 606 241 651Q249 679 253 681Q256 683 487 683H718Q723 678 723 675Q723 673 717 649Q189 54 188 52L185 49H274Q369 50 377 51Q452 60 500 100T579 247Q587 272 590 277T603 282H607Q628 282 628 271Q547 5 541 2Q538 0 300 0H124Q58 0 58 8Z"></path></g><g data-mml-node="mo" transform="translate(723,0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="mi" transform="translate(1112,0)"><path data-c="1D44B" d="M42 0H40Q26 0 26 11Q26 15 29 27Q33 41 36 43T55 46Q141 49 190 98Q200 108 306 224T411 342Q302 620 297 625Q288 636 234 637H206Q200 643 200 645T202 664Q206 677 212 683H226Q260 681 347 681Q380 681 408 681T453 682T473 682Q490 682 490 671Q490 670 488 658Q484 643 481 640T465 637Q434 634 411 620L488 426L541 485Q646 598 646 610Q646 628 622 635Q617 635 609 637Q594 637 594 648Q594 650 596 664Q600 677 606 683H618Q619 683 643 683T697 681T738 680Q828 680 837 683H845Q852 676 852 672Q850 647 840 637H824Q790 636 763 628T722 611T698 593L687 584Q687 585 592 480L505 384Q505 383 536 304T601 142T638 56Q648 47 699 46Q734 46 734 37Q734 35 732 23Q728 7 725 4T711 1Q708 1 678 1T589 2Q528 2 496 2T461 1Q444 1 444 10Q444 11 446 25Q448 35 450 39T455 44T464 46T480 47T506 54Q523 62 523 64Q522 64 476 181L429 299Q241 95 236 84Q232 76 232 72Q232 53 261 47Q262 47 267 47T273 46Q276 46 277 46T280 45T283 42T284 35Q284 26 282 19Q279 6 276 4T261 1Q258 1 243 1T201 2T142 2Q64 2 42 0Z"></path></g><g data-mml-node="mo" transform="translate(1964,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g></g><rect width="2553" height="60" x="120" y="220"></rect></g><g data-mml-node="mi" transform="translate(7548.6,0)"><path data-c="65" d="M28 218Q28 273 48 318T98 391T163 433T229 448Q282 448 320 430T378 380T406 316T415 245Q415 238 408 231H126V216Q126 68 226 36Q246 30 270 30Q312 30 342 62Q359 79 369 104L379 128Q382 131 395 131H398Q415 131 415 121Q415 117 412 108Q393 53 349 21T250 -11Q155 -11 92 58T28 218ZM333 275Q322 403 238 411H236Q228 411 220 410T195 402T166 381T143 340T127 274V267H333V275Z"></path><path data-c="78" d="M201 0Q189 3 102 3Q26 3 17 0H11V46H25Q48 47 67 52T96 61T121 78T139 96T160 122T180 150L226 210L168 288Q159 301 149 315T133 336T122 351T113 363T107 370T100 376T94 379T88 381T80 383Q74 383 44 385H16V431H23Q59 429 126 429Q219 429 229 431H237V385Q201 381 201 369Q201 367 211 353T239 315T268 274L272 270L297 304Q329 345 329 358Q329 364 327 369T322 376T317 380T310 384L307 385H302V431H309Q324 428 408 428Q487 428 493 431H499V385H492Q443 385 411 368Q394 360 377 341T312 257L296 236L358 151Q424 61 429 57T446 50Q464 46 499 46H516V0H510H502Q494 1 482 1T457 2T432 2T414 3Q403 3 377 3T327 1L304 0H295V46H298Q309 46 320 51T331 63Q331 65 291 120L250 175Q249 174 219 133T185 88Q181 83 181 74Q181 63 188 55T206 46Q208 46 208 23V0H201Z" transform="translate(444,0)"></path><path data-c="70" d="M36 -148H50Q89 -148 97 -134V-126Q97 -119 97 -107T97 -77T98 -38T98 6T98 55T98 106Q98 140 98 177T98 243T98 296T97 335T97 351Q94 370 83 376T38 385H20V408Q20 431 22 431L32 432Q42 433 61 434T98 436Q115 437 135 438T165 441T176 442H179V416L180 390L188 397Q247 441 326 441Q407 441 464 377T522 216Q522 115 457 52T310 -11Q242 -11 190 33L182 40V-45V-101Q182 -128 184 -134T195 -145Q216 -148 244 -148H260V-194H252L228 -193Q205 -192 178 -192T140 -191Q37 -191 28 -194H20V-148H36ZM424 218Q424 292 390 347T305 402Q234 402 182 337V98Q222 26 294 26Q345 26 384 80T424 218Z" transform="translate(972,0)"></path></g><g data-mml-node="mo" transform="translate(9076.6,0)"><path data-c="2061" d=""></path></g><g data-mml-node="mrow" transform="translate(9243.2,0)"><g data-mml-node="mo" transform="translate(0 -0.5)"><path data-c="28" d="M758 -1237T758 -1240T752 -1249H736Q718 -1249 717 -1248Q711 -1245 672 -1199Q237 -706 237 251T672 1700Q697 1730 716 1749Q718 1750 735 1750H752Q758 1744 758 1741Q758 1737 740 1713T689 1644T619 1537T540 1380T463 1176Q348 802 348 251Q348 -242 441 -599T744 -1218Q758 -1237 758 -1240Z"></path></g><g data-mml-node="munderover" transform="translate(792,0)"><g data-mml-node="mo"><path data-c="2211" d="M60 948Q63 950 665 950H1267L1325 815Q1384 677 1388 669H1348L1341 683Q1320 724 1285 761Q1235 809 1174 838T1033 881T882 898T699 902H574H543H251L259 891Q722 258 724 252Q725 250 724 246Q721 243 460 -56L196 -356Q196 -357 407 -357Q459 -357 548 -357T676 -358Q812 -358 896 -353T1063 -332T1204 -283T1307 -196Q1328 -170 1348 -124H1388Q1388 -125 1381 -145T1356 -210T1325 -294L1267 -449L666 -450Q64 -450 61 -448Q55 -446 55 -439Q55 -437 57 -433L590 177Q590 178 557 222T452 366T322 544L56 909L55 924Q55 945 60 948Z"></path></g><g data-mml-node="TeXAtom" transform="translate(142.5,-1087.9) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="1D461" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path></g><g data-mml-node="mo" transform="translate(361,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="mn" transform="translate(1139,0)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path></g></g><g data-mml-node="TeXAtom" transform="translate(473.1,1150) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="1D447" d="M40 437Q21 437 21 445Q21 450 37 501T71 602L88 651Q93 669 101 677H569H659Q691 677 697 676T704 667Q704 661 687 553T668 444Q668 437 649 437Q640 437 637 437T631 442L629 445Q629 451 635 490T641 551Q641 586 628 604T573 629Q568 630 515 631Q469 631 457 630T439 622Q438 621 368 343T298 60Q298 48 386 46Q418 46 427 45T436 36Q436 31 433 22Q429 4 424 1L422 0Q419 0 415 0Q410 0 363 1T228 2Q99 2 64 0H49Q43 6 43 9T45 27Q49 40 55 46H83H94Q174 46 189 55Q190 56 191 56Q196 59 201 76T241 233Q258 301 269 344Q339 619 339 625Q339 630 310 630H279Q212 630 191 624Q146 614 121 583T67 467Q60 445 57 441T43 437H40Z"></path></g></g></g><g data-mml-node="mrow" transform="translate(2402.7,0)"><g data-mml-node="mo"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="mi" transform="translate(389,0)"><path data-c="1D719" d="M409 688Q413 694 421 694H429H442Q448 688 448 686Q448 679 418 563Q411 535 404 504T392 458L388 442Q388 441 397 441T429 435T477 418Q521 397 550 357T579 260T548 151T471 65T374 11T279 -10H275L251 -105Q245 -128 238 -160Q230 -192 227 -198T215 -205H209Q189 -205 189 -198Q189 -193 211 -103L234 -11Q234 -10 226 -10Q221 -10 206 -8T161 6T107 36T62 89T43 171Q43 231 76 284T157 370T254 422T342 441Q347 441 348 445L378 567Q409 686 409 688ZM122 150Q122 116 134 91T167 53T203 35T237 27H244L337 404Q333 404 326 403T297 395T255 379T211 350T170 304Q152 276 137 237Q122 191 122 150ZM500 282Q500 320 484 347T444 385T405 400T381 404H378L332 217L284 29Q284 27 285 27Q293 27 317 33T357 47Q400 66 431 100T475 170T494 234T500 282Z"></path></g><g data-mml-node="mo" transform="translate(985,0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="msub" transform="translate(1374,0)"><g data-mml-node="mi"><path data-c="1D466" d="M21 287Q21 301 36 335T84 406T158 442Q199 442 224 419T250 355Q248 336 247 334Q247 331 231 288T198 191T182 105Q182 62 196 45T238 27Q261 27 281 38T312 61T339 94Q339 95 344 114T358 173T377 247Q415 397 419 404Q432 431 462 431Q475 431 483 424T494 412T496 403Q496 390 447 193T391 -23Q363 -106 294 -155T156 -205Q111 -205 77 -183T43 -117Q43 -95 50 -80T69 -58T89 -48T106 -45Q150 -45 150 -87Q150 -107 138 -122T115 -142T102 -147L99 -148Q101 -153 118 -160T152 -167H160Q177 -167 186 -165Q219 -156 247 -127T290 -65T313 -9T321 21L315 17Q309 13 296 6T270 -6Q250 -11 231 -11Q185 -11 150 11T104 82Q103 89 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(523,-150) scale(0.707)"><path data-c="1D461" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path></g></g><g data-mml-node="mo" transform="translate(2202.3,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path></g><g data-mml-node="mi" transform="translate(2646.9,0)"><path data-c="1D465" d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z"></path></g><g data-mml-node="mo" transform="translate(3218.9,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path></g><g data-mml-node="mi" transform="translate(3663.6,0)"><path data-c="1D461" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path></g><g data-mml-node="mo" transform="translate(4024.6,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g><g data-mml-node="mo" transform="translate(4635.8,0)"><path data-c="2B" d="M56 237T56 250T70 270H369V420L370 570Q380 583 389 583Q402 583 409 568V270H707Q722 262 722 250T707 230H409V-68Q401 -82 391 -82H389H387Q375 -82 369 -68V230H70Q56 237 56 250Z"></path></g><g data-mml-node="mi" transform="translate(5636,0)"><path data-c="1D713" d="M161 441Q202 441 226 417T250 358Q250 338 218 252T187 127Q190 85 214 61Q235 43 257 37Q275 29 288 29H289L371 360Q455 691 456 692Q459 694 472 694Q492 694 492 687Q492 678 411 356Q329 28 329 27T335 26Q421 26 498 114T576 278Q576 302 568 319T550 343T532 361T524 384Q524 405 541 424T583 443Q602 443 618 425T634 366Q634 337 623 288T605 220Q573 125 492 57T329 -11H319L296 -104Q272 -198 272 -199Q270 -205 252 -205H239Q233 -199 233 -197Q233 -192 256 -102T279 -9Q272 -8 265 -8Q106 14 106 139Q106 174 139 264T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Q21 299 34 333T82 404T161 441Z"></path></g><g data-mml-node="mo" transform="translate(6287,0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="msub" transform="translate(6676,0)"><g data-mml-node="mi"><path data-c="1D466" d="M21 287Q21 301 36 335T84 406T158 442Q199 442 224 419T250 355Q248 336 247 334Q247 331 231 288T198 191T182 105Q182 62 196 45T238 27Q261 27 281 38T312 61T339 94Q339 95 344 114T358 173T377 247Q415 397 419 404Q432 431 462 431Q475 431 483 424T494 412T496 403Q496 390 447 193T391 -23Q363 -106 294 -155T156 -205Q111 -205 77 -183T43 -117Q43 -95 50 -80T69 -58T89 -48T106 -45Q150 -45 150 -87Q150 -107 138 -122T115 -142T102 -147L99 -148Q101 -153 118 -160T152 -167H160Q177 -167 186 -165Q219 -156 247 -127T290 -65T313 -9T321 21L315 17Q309 13 296 6T270 -6Q250 -11 231 -11Q185 -11 150 11T104 82Q103 89 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="TeXAtom" transform="translate(523,-150) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="1D461" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path></g><g data-mml-node="mo" transform="translate(361,0)"><path data-c="2212" d="M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z"></path></g><g data-mml-node="mn" transform="translate(1139,0)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path></g></g></g><g data-mml-node="mo" transform="translate(8408,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path></g><g data-mml-node="msub" transform="translate(8852.7,0)"><g data-mml-node="mi"><path data-c="1D466" d="M21 287Q21 301 36 335T84 406T158 442Q199 442 224 419T250 355Q248 336 247 334Q247 331 231 288T198 191T182 105Q182 62 196 45T238 27Q261 27 281 38T312 61T339 94Q339 95 344 114T358 173T377 247Q415 397 419 404Q432 431 462 431Q475 431 483 424T494 412T496 403Q496 390 447 193T391 -23Q363 -106 294 -155T156 -205Q111 -205 77 -183T43 -117Q43 -95 50 -80T69 -58T89 -48T106 -45Q150 -45 150 -87Q150 -107 138 -122T115 -142T102 -147L99 -148Q101 -153 118 -160T152 -167H160Q177 -167 186 -165Q219 -156 247 -127T290 -65T313 -9T321 21L315 17Q309 13 296 6T270 -6Q250 -11 231 -11Q185 -11 150 11T104 82Q103 89 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(523,-150) scale(0.707)"><path data-c="1D461" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path></g></g><g data-mml-node="mo" transform="translate(9680.9,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g><g data-mml-node="mo" transform="translate(10069.9,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g></g><g data-mml-node="mo" transform="translate(12861.6,0) translate(0 -0.5)"><path data-c="29" d="M33 1741Q33 1750 51 1750H60H65Q73 1750 81 1743T119 1700Q554 1207 554 251Q554 -707 119 -1199Q76 -1250 66 -1250Q65 -1250 62 -1250T56 -1249Q55 -1249 53 -1249T49 -1250Q33 -1250 33 -1239Q33 -1236 50 -1214T98 -1150T163 -1052T238 -910T311 -727Q443 -335 443 251Q443 402 436 532T405 831T339 1142T224 1438T50 1716Q33 1737 33 1741Z"></path></g></g></g></g></svg></mjx-container></p>
<p>其中：</p>
<ul>
<li><mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.566ex;" xmlns="http://www.w3.org/2000/svg" width="9.105ex" height="2.262ex" role="img" focusable="false" viewBox="0 -750 4024.6 1000"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D719" d="M409 688Q413 694 421 694H429H442Q448 688 448 686Q448 679 418 563Q411 535 404 504T392 458L388 442Q388 441 397 441T429 435T477 418Q521 397 550 357T579 260T548 151T471 65T374 11T279 -10H275L251 -105Q245 -128 238 -160Q230 -192 227 -198T215 -205H209Q189 -205 189 -198Q189 -193 211 -103L234 -11Q234 -10 226 -10Q221 -10 206 -8T161 6T107 36T62 89T43 171Q43 231 76 284T157 370T254 422T342 441Q347 441 348 445L378 567Q409 686 409 688ZM122 150Q122 116 134 91T167 53T203 35T237 27H244L337 404Q333 404 326 403T297 395T255 379T211 350T170 304Q152 276 137 237Q122 191 122 150ZM500 282Q500 320 484 347T444 385T405 400T381 404H378L332 217L284 29Q284 27 285 27Q293 27 317 33T357 47Q400 66 431 100T475 170T494 234T500 282Z"></path></g><g data-mml-node="mo" transform="translate(596,0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="msub" transform="translate(985,0)"><g data-mml-node="mi"><path data-c="1D466" d="M21 287Q21 301 36 335T84 406T158 442Q199 442 224 419T250 355Q248 336 247 334Q247 331 231 288T198 191T182 105Q182 62 196 45T238 27Q261 27 281 38T312 61T339 94Q339 95 344 114T358 173T377 247Q415 397 419 404Q432 431 462 431Q475 431 483 424T494 412T496 403Q496 390 447 193T391 -23Q363 -106 294 -155T156 -205Q111 -205 77 -183T43 -117Q43 -95 50 -80T69 -58T89 -48T106 -45Q150 -45 150 -87Q150 -107 138 -122T115 -142T102 -147L99 -148Q101 -153 118 -160T152 -167H160Q177 -167 186 -165Q219 -156 247 -127T290 -65T313 -9T321 21L315 17Q309 13 296 6T270 -6Q250 -11 231 -11Q185 -11 150 11T104 82Q103 89 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(523,-150) scale(0.707)"><path data-c="1D461" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path></g></g><g data-mml-node="mo" transform="translate(1813.3,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path></g><g data-mml-node="mi" transform="translate(2257.9,0)"><path data-c="1D465" d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z"></path></g><g data-mml-node="mo" transform="translate(2829.9,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path></g><g data-mml-node="mi" transform="translate(3274.6,0)"><path data-c="1D461" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path></g><g data-mml-node="mo" transform="translate(3635.6,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g></g></g></svg></mjx-container>：发射分数（emission score）</li>
<li><mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.566ex;" xmlns="http://www.w3.org/2000/svg" width="10.031ex" height="2.262ex" role="img" focusable="false" viewBox="0 -750 4433.9 1000"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D713" d="M161 441Q202 441 226 417T250 358Q250 338 218 252T187 127Q190 85 214 61Q235 43 257 37Q275 29 288 29H289L371 360Q455 691 456 692Q459 694 472 694Q492 694 492 687Q492 678 411 356Q329 28 329 27T335 26Q421 26 498 114T576 278Q576 302 568 319T550 343T532 361T524 384Q524 405 541 424T583 443Q602 443 618 425T634 366Q634 337 623 288T605 220Q573 125 492 57T329 -11H319L296 -104Q272 -198 272 -199Q270 -205 252 -205H239Q233 -199 233 -197Q233 -192 256 -102T279 -9Q272 -8 265 -8Q106 14 106 139Q106 174 139 264T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Q21 299 34 333T82 404T161 441Z"></path></g><g data-mml-node="mo" transform="translate(651,0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="msub" transform="translate(1040,0)"><g data-mml-node="mi"><path data-c="1D466" d="M21 287Q21 301 36 335T84 406T158 442Q199 442 224 419T250 355Q248 336 247 334Q247 331 231 288T198 191T182 105Q182 62 196 45T238 27Q261 27 281 38T312 61T339 94Q339 95 344 114T358 173T377 247Q415 397 419 404Q432 431 462 431Q475 431 483 424T494 412T496 403Q496 390 447 193T391 -23Q363 -106 294 -155T156 -205Q111 -205 77 -183T43 -117Q43 -95 50 -80T69 -58T89 -48T106 -45Q150 -45 150 -87Q150 -107 138 -122T115 -142T102 -147L99 -148Q101 -153 118 -160T152 -167H160Q177 -167 186 -165Q219 -156 247 -127T290 -65T313 -9T321 21L315 17Q309 13 296 6T270 -6Q250 -11 231 -11Q185 -11 150 11T104 82Q103 89 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="TeXAtom" transform="translate(523,-150) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="1D461" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path></g><g data-mml-node="mo" transform="translate(361,0)"><path data-c="2212" d="M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z"></path></g><g data-mml-node="mn" transform="translate(1139,0)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path></g></g></g><g data-mml-node="mo" transform="translate(2771.9,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path></g><g data-mml-node="msub" transform="translate(3216.6,0)"><g data-mml-node="mi"><path data-c="1D466" d="M21 287Q21 301 36 335T84 406T158 442Q199 442 224 419T250 355Q248 336 247 334Q247 331 231 288T198 191T182 105Q182 62 196 45T238 27Q261 27 281 38T312 61T339 94Q339 95 344 114T358 173T377 247Q415 397 419 404Q432 431 462 431Q475 431 483 424T494 412T496 403Q496 390 447 193T391 -23Q363 -106 294 -155T156 -205Q111 -205 77 -183T43 -117Q43 -95 50 -80T69 -58T89 -48T106 -45Q150 -45 150 -87Q150 -107 138 -122T115 -142T102 -147L99 -148Q101 -153 118 -160T152 -167H160Q177 -167 186 -165Q219 -156 247 -127T290 -65T313 -9T321 21L315 17Q309 13 296 6T270 -6Q250 -11 231 -11Q185 -11 150 11T104 82Q103 89 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(523,-150) scale(0.707)"><path data-c="1D461" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path></g></g><g data-mml-node="mo" transform="translate(4044.9,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g></g></g></svg></mjx-container>：转移分数（transition score）</li>
<li><mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.566ex;" xmlns="http://www.w3.org/2000/svg" width="5.324ex" height="2.262ex" role="img" focusable="false" viewBox="0 -750 2353 1000"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D44D" d="M58 8Q58 23 64 35Q64 36 329 334T596 635L586 637Q575 637 512 637H500H476Q442 637 420 635T365 624T311 598T266 548T228 469Q227 466 226 463T224 458T223 453T222 450L221 448Q218 443 202 443Q185 443 182 453L214 561Q228 606 241 651Q249 679 253 681Q256 683 487 683H718Q723 678 723 675Q723 673 717 649Q189 54 188 52L185 49H274Q369 50 377 51Q452 60 500 100T579 247Q587 272 590 277T603 282H607Q628 282 628 271Q547 5 541 2Q538 0 300 0H124Q58 0 58 8Z"></path></g><g data-mml-node="mo" transform="translate(723,0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="mi" transform="translate(1112,0)"><path data-c="1D44B" d="M42 0H40Q26 0 26 11Q26 15 29 27Q33 41 36 43T55 46Q141 49 190 98Q200 108 306 224T411 342Q302 620 297 625Q288 636 234 637H206Q200 643 200 645T202 664Q206 677 212 683H226Q260 681 347 681Q380 681 408 681T453 682T473 682Q490 682 490 671Q490 670 488 658Q484 643 481 640T465 637Q434 634 411 620L488 426L541 485Q646 598 646 610Q646 628 622 635Q617 635 609 637Q594 637 594 648Q594 650 596 664Q600 677 606 683H618Q619 683 643 683T697 681T738 680Q828 680 837 683H845Q852 676 852 672Q850 647 840 637H824Q790 636 763 628T722 611T698 593L687 584Q687 585 592 480L505 384Q505 383 536 304T601 142T638 56Q648 47 699 46Q734 46 734 37Q734 35 732 23Q728 7 725 4T711 1Q708 1 678 1T589 2Q528 2 496 2T461 1Q444 1 444 10Q444 11 446 25Q448 35 450 39T455 44T464 46T480 47T506 54Q523 62 523 64Q522 64 476 181L429 299Q241 95 236 84Q232 76 232 72Q232 53 261 47Q262 47 267 47T273 46Q276 46 277 46T280 45T283 42T284 35Q284 26 282 19Q279 6 276 4T261 1Q258 1 243 1T201 2T142 2Q64 2 42 0Z"></path></g><g data-mml-node="mo" transform="translate(1964,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g></g></g></svg></mjx-container>：配分函数（归一化项）</li>
</ul>
<h3 id="配分函数"><a href="#配分函数" class="headerlink" title="配分函数"></a>配分函数</h3><p><mjx-container class="MathJax" jax="SVG" display="true"><svg style="vertical-align: -3.178ex;" xmlns="http://www.w3.org/2000/svg" width="47.448ex" height="7.136ex" role="img" focusable="false" viewBox="0 -1749.5 20972.1 3154.3"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D44D" d="M58 8Q58 23 64 35Q64 36 329 334T596 635L586 637Q575 637 512 637H500H476Q442 637 420 635T365 624T311 598T266 548T228 469Q227 466 226 463T224 458T223 453T222 450L221 448Q218 443 202 443Q185 443 182 453L214 561Q228 606 241 651Q249 679 253 681Q256 683 487 683H718Q723 678 723 675Q723 673 717 649Q189 54 188 52L185 49H274Q369 50 377 51Q452 60 500 100T579 247Q587 272 590 277T603 282H607Q628 282 628 271Q547 5 541 2Q538 0 300 0H124Q58 0 58 8Z"></path></g><g data-mml-node="mo" transform="translate(723,0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="mi" transform="translate(1112,0)"><path data-c="1D44B" d="M42 0H40Q26 0 26 11Q26 15 29 27Q33 41 36 43T55 46Q141 49 190 98Q200 108 306 224T411 342Q302 620 297 625Q288 636 234 637H206Q200 643 200 645T202 664Q206 677 212 683H226Q260 681 347 681Q380 681 408 681T453 682T473 682Q490 682 490 671Q490 670 488 658Q484 643 481 640T465 637Q434 634 411 620L488 426L541 485Q646 598 646 610Q646 628 622 635Q617 635 609 637Q594 637 594 648Q594 650 596 664Q600 677 606 683H618Q619 683 643 683T697 681T738 680Q828 680 837 683H845Q852 676 852 672Q850 647 840 637H824Q790 636 763 628T722 611T698 593L687 584Q687 585 592 480L505 384Q505 383 536 304T601 142T638 56Q648 47 699 46Q734 46 734 37Q734 35 732 23Q728 7 725 4T711 1Q708 1 678 1T589 2Q528 2 496 2T461 1Q444 1 444 10Q444 11 446 25Q448 35 450 39T455 44T464 46T480 47T506 54Q523 62 523 64Q522 64 476 181L429 299Q241 95 236 84Q232 76 232 72Q232 53 261 47Q262 47 267 47T273 46Q276 46 277 46T280 45T283 42T284 35Q284 26 282 19Q279 6 276 4T261 1Q258 1 243 1T201 2T142 2Q64 2 42 0Z"></path></g><g data-mml-node="mo" transform="translate(1964,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g><g data-mml-node="mo" transform="translate(2630.8,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="munder" transform="translate(3686.6,0)"><g data-mml-node="mo" transform="translate(163.3,0)"><path data-c="2211" d="M60 948Q63 950 665 950H1267L1325 815Q1384 677 1388 669H1348L1341 683Q1320 724 1285 761Q1235 809 1174 838T1033 881T882 898T699 902H574H543H251L259 891Q722 258 724 252Q725 250 724 246Q721 243 460 -56L196 -356Q196 -357 407 -357Q459 -357 548 -357T676 -358Q812 -358 896 -353T1063 -332T1204 -283T1307 -196Q1328 -170 1348 -124H1388Q1388 -125 1381 -145T1356 -210T1325 -294L1267 -449L666 -450Q64 -450 61 -448Q55 -446 55 -439Q55 -437 57 -433L590 177Q590 178 557 222T452 366T322 544L56 909L55 924Q55 945 60 948Z"></path></g><g data-mml-node="TeXAtom" transform="translate(0,-1159.9) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="1D466" d="M21 287Q21 301 36 335T84 406T158 442Q199 442 224 419T250 355Q248 336 247 334Q247 331 231 288T198 191T182 105Q182 62 196 45T238 27Q261 27 281 38T312 61T339 94Q339 95 344 114T358 173T377 247Q415 397 419 404Q432 431 462 431Q475 431 483 424T494 412T496 403Q496 390 447 193T391 -23Q363 -106 294 -155T156 -205Q111 -205 77 -183T43 -117Q43 -95 50 -80T69 -58T89 -48T106 -45Q150 -45 150 -87Q150 -107 138 -122T115 -142T102 -147L99 -148Q101 -153 118 -160T152 -167H160Q177 -167 186 -165Q219 -156 247 -127T290 -65T313 -9T321 21L315 17Q309 13 296 6T270 -6Q250 -11 231 -11Q185 -11 150 11T104 82Q103 89 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mo" transform="translate(490,0)"><path data-c="2208" d="M84 250Q84 372 166 450T360 539Q361 539 377 539T419 540T469 540H568Q583 532 583 520Q583 511 570 501L466 500Q355 499 329 494Q280 482 242 458T183 409T147 354T129 306T124 272V270H568Q583 262 583 250T568 230H124V228Q124 207 134 177T167 112T231 48T328 7Q355 1 466 0H570Q583 -10 583 -20Q583 -32 568 -40H471Q464 -40 446 -40T417 -41Q262 -41 172 45Q84 127 84 250Z"></path></g><g data-mml-node="msup" transform="translate(1157,0)"><g data-mml-node="TeXAtom" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="59" d="M65 599Q65 618 107 650T204 683Q267 683 312 643T380 533T414 385T424 217Q424 186 423 160T422 123Q426 123 468 170T567 304T650 469Q661 503 661 519Q661 546 639 570Q615 591 583 591Q569 591 569 616Q569 640 582 661T613 683Q624 683 638 679T671 664T702 625T714 558Q714 472 639 329T426 45Q361 -21 282 -82T154 -143Q97 -143 64 -104T31 -20Q31 4 44 25T70 46Q78 46 81 39T87 16T97 -9Q127 -51 182 -51Q184 -51 187 -50H190Q233 -41 314 25Q330 36 330 40Q336 79 336 178Q336 508 223 594Q199 614 158 619L148 620L139 611Q111 586 83 586Q65 586 65 599Z"></path></g></g><g data-mml-node="mi" transform="translate(799.3,289) scale(0.707)"><path data-c="1D447" d="M40 437Q21 437 21 445Q21 450 37 501T71 602L88 651Q93 669 101 677H569H659Q691 677 697 676T704 667Q704 661 687 553T668 444Q668 437 649 437Q640 437 637 437T631 442L629 445Q629 451 635 490T641 551Q641 586 628 604T573 629Q568 630 515 631Q469 631 457 630T439 622Q438 621 368 343T298 60Q298 48 386 46Q418 46 427 45T436 36Q436 31 433 22Q429 4 424 1L422 0Q419 0 415 0Q410 0 363 1T228 2Q99 2 64 0H49Q43 6 43 9T45 27Q49 40 55 46H83H94Q174 46 189 55Q190 56 191 56Q196 59 201 76T241 233Q258 301 269 344Q339 619 339 625Q339 630 310 630H279Q212 630 191 624Q146 614 121 583T67 467Q60 445 57 441T43 437H40Z"></path></g></g></g></g><g data-mml-node="mi" transform="translate(5623.9,0)"><path data-c="65" d="M28 218Q28 273 48 318T98 391T163 433T229 448Q282 448 320 430T378 380T406 316T415 245Q415 238 408 231H126V216Q126 68 226 36Q246 30 270 30Q312 30 342 62Q359 79 369 104L379 128Q382 131 395 131H398Q415 131 415 121Q415 117 412 108Q393 53 349 21T250 -11Q155 -11 92 58T28 218ZM333 275Q322 403 238 411H236Q228 411 220 410T195 402T166 381T143 340T127 274V267H333V275Z"></path><path data-c="78" d="M201 0Q189 3 102 3Q26 3 17 0H11V46H25Q48 47 67 52T96 61T121 78T139 96T160 122T180 150L226 210L168 288Q159 301 149 315T133 336T122 351T113 363T107 370T100 376T94 379T88 381T80 383Q74 383 44 385H16V431H23Q59 429 126 429Q219 429 229 431H237V385Q201 381 201 369Q201 367 211 353T239 315T268 274L272 270L297 304Q329 345 329 358Q329 364 327 369T322 376T317 380T310 384L307 385H302V431H309Q324 428 408 428Q487 428 493 431H499V385H492Q443 385 411 368Q394 360 377 341T312 257L296 236L358 151Q424 61 429 57T446 50Q464 46 499 46H516V0H510H502Q494 1 482 1T457 2T432 2T414 3Q403 3 377 3T327 1L304 0H295V46H298Q309 46 320 51T331 63Q331 65 291 120L250 175Q249 174 219 133T185 88Q181 83 181 74Q181 63 188 55T206 46Q208 46 208 23V0H201Z" transform="translate(444,0)"></path><path data-c="70" d="M36 -148H50Q89 -148 97 -134V-126Q97 -119 97 -107T97 -77T98 -38T98 6T98 55T98 106Q98 140 98 177T98 243T98 296T97 335T97 351Q94 370 83 376T38 385H20V408Q20 431 22 431L32 432Q42 433 61 434T98 436Q115 437 135 438T165 441T176 442H179V416L180 390L188 397Q247 441 326 441Q407 441 464 377T522 216Q522 115 457 52T310 -11Q242 -11 190 33L182 40V-45V-101Q182 -128 184 -134T195 -145Q216 -148 244 -148H260V-194H252L228 -193Q205 -192 178 -192T140 -191Q37 -191 28 -194H20V-148H36ZM424 218Q424 292 390 347T305 402Q234 402 182 337V98Q222 26 294 26Q345 26 384 80T424 218Z" transform="translate(972,0)"></path></g><g data-mml-node="mo" transform="translate(7151.9,0)"><path data-c="2061" d=""></path></g><g data-mml-node="mrow" transform="translate(7318.6,0)"><g data-mml-node="mo" transform="translate(0 -0.5)"><path data-c="28" d="M758 -1237T758 -1240T752 -1249H736Q718 -1249 717 -1248Q711 -1245 672 -1199Q237 -706 237 251T672 1700Q697 1730 716 1749Q718 1750 735 1750H752Q758 1744 758 1741Q758 1737 740 1713T689 1644T619 1537T540 1380T463 1176Q348 802 348 251Q348 -242 441 -599T744 -1218Q758 -1237 758 -1240Z"></path></g><g data-mml-node="munderover" transform="translate(792,0)"><g data-mml-node="mo"><path data-c="2211" d="M60 948Q63 950 665 950H1267L1325 815Q1384 677 1388 669H1348L1341 683Q1320 724 1285 761Q1235 809 1174 838T1033 881T882 898T699 902H574H543H251L259 891Q722 258 724 252Q725 250 724 246Q721 243 460 -56L196 -356Q196 -357 407 -357Q459 -357 548 -357T676 -358Q812 -358 896 -353T1063 -332T1204 -283T1307 -196Q1328 -170 1348 -124H1388Q1388 -125 1381 -145T1356 -210T1325 -294L1267 -449L666 -450Q64 -450 61 -448Q55 -446 55 -439Q55 -437 57 -433L590 177Q590 178 557 222T452 366T322 544L56 909L55 924Q55 945 60 948Z"></path></g><g data-mml-node="TeXAtom" transform="translate(142.5,-1087.9) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="1D461" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path></g><g data-mml-node="mo" transform="translate(361,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="mn" transform="translate(1139,0)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path></g></g><g data-mml-node="TeXAtom" transform="translate(473.1,1150) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="1D447" d="M40 437Q21 437 21 445Q21 450 37 501T71 602L88 651Q93 669 101 677H569H659Q691 677 697 676T704 667Q704 661 687 553T668 444Q668 437 649 437Q640 437 637 437T631 442L629 445Q629 451 635 490T641 551Q641 586 628 604T573 629Q568 630 515 631Q469 631 457 630T439 622Q438 621 368 343T298 60Q298 48 386 46Q418 46 427 45T436 36Q436 31 433 22Q429 4 424 1L422 0Q419 0 415 0Q410 0 363 1T228 2Q99 2 64 0H49Q43 6 43 9T45 27Q49 40 55 46H83H94Q174 46 189 55Q190 56 191 56Q196 59 201 76T241 233Q258 301 269 344Q339 619 339 625Q339 630 310 630H279Q212 630 191 624Q146 614 121 583T67 467Q60 445 57 441T43 437H40Z"></path></g></g></g><g data-mml-node="mrow" transform="translate(2402.7,0)"><g data-mml-node="mo"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="mi" transform="translate(389,0)"><path data-c="1D719" d="M409 688Q413 694 421 694H429H442Q448 688 448 686Q448 679 418 563Q411 535 404 504T392 458L388 442Q388 441 397 441T429 435T477 418Q521 397 550 357T579 260T548 151T471 65T374 11T279 -10H275L251 -105Q245 -128 238 -160Q230 -192 227 -198T215 -205H209Q189 -205 189 -198Q189 -193 211 -103L234 -11Q234 -10 226 -10Q221 -10 206 -8T161 6T107 36T62 89T43 171Q43 231 76 284T157 370T254 422T342 441Q347 441 348 445L378 567Q409 686 409 688ZM122 150Q122 116 134 91T167 53T203 35T237 27H244L337 404Q333 404 326 403T297 395T255 379T211 350T170 304Q152 276 137 237Q122 191 122 150ZM500 282Q500 320 484 347T444 385T405 400T381 404H378L332 217L284 29Q284 27 285 27Q293 27 317 33T357 47Q400 66 431 100T475 170T494 234T500 282Z"></path></g><g data-mml-node="mo" transform="translate(985,0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="msub" transform="translate(1374,0)"><g data-mml-node="mi"><path data-c="1D466" d="M21 287Q21 301 36 335T84 406T158 442Q199 442 224 419T250 355Q248 336 247 334Q247 331 231 288T198 191T182 105Q182 62 196 45T238 27Q261 27 281 38T312 61T339 94Q339 95 344 114T358 173T377 247Q415 397 419 404Q432 431 462 431Q475 431 483 424T494 412T496 403Q496 390 447 193T391 -23Q363 -106 294 -155T156 -205Q111 -205 77 -183T43 -117Q43 -95 50 -80T69 -58T89 -48T106 -45Q150 -45 150 -87Q150 -107 138 -122T115 -142T102 -147L99 -148Q101 -153 118 -160T152 -167H160Q177 -167 186 -165Q219 -156 247 -127T290 -65T313 -9T321 21L315 17Q309 13 296 6T270 -6Q250 -11 231 -11Q185 -11 150 11T104 82Q103 89 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(523,-150) scale(0.707)"><path data-c="1D461" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path></g></g><g data-mml-node="mo" transform="translate(2202.3,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path></g><g data-mml-node="mi" transform="translate(2646.9,0)"><path data-c="1D465" d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z"></path></g><g data-mml-node="mo" transform="translate(3218.9,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path></g><g data-mml-node="mi" transform="translate(3663.6,0)"><path data-c="1D461" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path></g><g data-mml-node="mo" transform="translate(4024.6,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g><g data-mml-node="mo" transform="translate(4635.8,0)"><path data-c="2B" d="M56 237T56 250T70 270H369V420L370 570Q380 583 389 583Q402 583 409 568V270H707Q722 262 722 250T707 230H409V-68Q401 -82 391 -82H389H387Q375 -82 369 -68V230H70Q56 237 56 250Z"></path></g><g data-mml-node="mi" transform="translate(5636,0)"><path data-c="1D713" d="M161 441Q202 441 226 417T250 358Q250 338 218 252T187 127Q190 85 214 61Q235 43 257 37Q275 29 288 29H289L371 360Q455 691 456 692Q459 694 472 694Q492 694 492 687Q492 678 411 356Q329 28 329 27T335 26Q421 26 498 114T576 278Q576 302 568 319T550 343T532 361T524 384Q524 405 541 424T583 443Q602 443 618 425T634 366Q634 337 623 288T605 220Q573 125 492 57T329 -11H319L296 -104Q272 -198 272 -199Q270 -205 252 -205H239Q233 -199 233 -197Q233 -192 256 -102T279 -9Q272 -8 265 -8Q106 14 106 139Q106 174 139 264T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Q21 299 34 333T82 404T161 441Z"></path></g><g data-mml-node="mo" transform="translate(6287,0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="msub" transform="translate(6676,0)"><g data-mml-node="mi"><path data-c="1D466" d="M21 287Q21 301 36 335T84 406T158 442Q199 442 224 419T250 355Q248 336 247 334Q247 331 231 288T198 191T182 105Q182 62 196 45T238 27Q261 27 281 38T312 61T339 94Q339 95 344 114T358 173T377 247Q415 397 419 404Q432 431 462 431Q475 431 483 424T494 412T496 403Q496 390 447 193T391 -23Q363 -106 294 -155T156 -205Q111 -205 77 -183T43 -117Q43 -95 50 -80T69 -58T89 -48T106 -45Q150 -45 150 -87Q150 -107 138 -122T115 -142T102 -147L99 -148Q101 -153 118 -160T152 -167H160Q177 -167 186 -165Q219 -156 247 -127T290 -65T313 -9T321 21L315 17Q309 13 296 6T270 -6Q250 -11 231 -11Q185 -11 150 11T104 82Q103 89 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="TeXAtom" transform="translate(523,-150) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="1D461" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path></g><g data-mml-node="mo" transform="translate(361,0)"><path data-c="2212" d="M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z"></path></g><g data-mml-node="mn" transform="translate(1139,0)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path></g></g></g><g data-mml-node="mo" transform="translate(8408,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path></g><g data-mml-node="msub" transform="translate(8852.7,0)"><g data-mml-node="mi"><path data-c="1D466" d="M21 287Q21 301 36 335T84 406T158 442Q199 442 224 419T250 355Q248 336 247 334Q247 331 231 288T198 191T182 105Q182 62 196 45T238 27Q261 27 281 38T312 61T339 94Q339 95 344 114T358 173T377 247Q415 397 419 404Q432 431 462 431Q475 431 483 424T494 412T496 403Q496 390 447 193T391 -23Q363 -106 294 -155T156 -205Q111 -205 77 -183T43 -117Q43 -95 50 -80T69 -58T89 -48T106 -45Q150 -45 150 -87Q150 -107 138 -122T115 -142T102 -147L99 -148Q101 -153 118 -160T152 -167H160Q177 -167 186 -165Q219 -156 247 -127T290 -65T313 -9T321 21L315 17Q309 13 296 6T270 -6Q250 -11 231 -11Q185 -11 150 11T104 82Q103 89 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(523,-150) scale(0.707)"><path data-c="1D461" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path></g></g><g data-mml-node="mo" transform="translate(9680.9,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g><g data-mml-node="mo" transform="translate(10069.9,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g></g><g data-mml-node="mo" transform="translate(12861.6,0) translate(0 -0.5)"><path data-c="29" d="M33 1741Q33 1750 51 1750H60H65Q73 1750 81 1743T119 1700Q554 1207 554 251Q554 -707 119 -1199Q76 -1250 66 -1250Q65 -1250 62 -1250T56 -1249Q55 -1249 53 -1249T49 -1250Q33 -1250 33 -1239Q33 -1236 50 -1214T98 -1150T163 -1052T238 -910T311 -727Q443 -335 443 251Q443 402 436 532T405 831T339 1142T224 1438T50 1716Q33 1737 33 1741Z"></path></g></g></g></g></svg></mjx-container></p>
<p>直接计算复杂度为 <mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.566ex;" xmlns="http://www.w3.org/2000/svg" width="7.674ex" height="2.47ex" role="img" focusable="false" viewBox="0 -841.7 3391.8 1091.7"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D442" d="M740 435Q740 320 676 213T511 42T304 -22Q207 -22 138 35T51 201Q50 209 50 244Q50 346 98 438T227 601Q351 704 476 704Q514 704 524 703Q621 689 680 617T740 435ZM637 476Q637 565 591 615T476 665Q396 665 322 605Q242 542 200 428T157 216Q157 126 200 73T314 19Q404 19 485 98T608 313Q637 408 637 476Z"></path></g><g data-mml-node="mo" transform="translate(763,0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="mo" transform="translate(1152,0) translate(0 -0.5)"><path data-c="7C" d="M139 -249H137Q125 -249 119 -235V251L120 737Q130 750 139 750Q152 750 159 735V-235Q151 -249 141 -249H139Z"></path></g><g data-mml-node="TeXAtom" data-mjx-texclass="ORD" transform="translate(1430,0)"><g data-mml-node="mi"><path data-c="59" d="M65 599Q65 618 107 650T204 683Q267 683 312 643T380 533T414 385T424 217Q424 186 423 160T422 123Q426 123 468 170T567 304T650 469Q661 503 661 519Q661 546 639 570Q615 591 583 591Q569 591 569 616Q569 640 582 661T613 683Q624 683 638 679T671 664T702 625T714 558Q714 472 639 329T426 45Q361 -21 282 -82T154 -143Q97 -143 64 -104T31 -20Q31 4 44 25T70 46Q78 46 81 39T87 16T97 -9Q127 -51 182 -51Q184 -51 187 -50H190Q233 -41 314 25Q330 36 330 40Q336 79 336 178Q336 508 223 594Q199 614 158 619L148 620L139 611Q111 586 83 586Q65 586 65 599Z"></path></g></g><g data-mml-node="msup" transform="translate(2144,0)"><g data-mml-node="mo" transform="translate(0 -0.5)"><path data-c="7C" d="M139 -249H137Q125 -249 119 -235V251L120 737Q130 750 139 750Q152 750 159 735V-235Q151 -249 141 -249H139Z"></path></g><g data-mml-node="mi" transform="translate(311,363) scale(0.707)"><path data-c="1D447" d="M40 437Q21 437 21 445Q21 450 37 501T71 602L88 651Q93 669 101 677H569H659Q691 677 697 676T704 667Q704 661 687 553T668 444Q668 437 649 437Q640 437 637 437T631 442L629 445Q629 451 635 490T641 551Q641 586 628 604T573 629Q568 630 515 631Q469 631 457 630T439 622Q438 621 368 343T298 60Q298 48 386 46Q418 46 427 45T436 36Q436 31 433 22Q429 4 424 1L422 0Q419 0 415 0Q410 0 363 1T228 2Q99 2 64 0H49Q43 6 43 9T45 27Q49 40 55 46H83H94Q174 46 189 55Q190 56 191 56Q196 59 201 76T241 233Q258 301 269 344Q339 619 339 625Q339 630 310 630H279Q212 630 191 624Q146 614 121 583T67 467Q60 445 57 441T43 437H40Z"></path></g></g><g data-mml-node="mo" transform="translate(3002.8,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g></g></g></svg></mjx-container>，使用<strong>前向算法</strong>可降至 <mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.566ex;" xmlns="http://www.w3.org/2000/svg" width="10.575ex" height="2.452ex" role="img" focusable="false" viewBox="0 -833.9 4674 1083.9"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D442" d="M740 435Q740 320 676 213T511 42T304 -22Q207 -22 138 35T51 201Q50 209 50 244Q50 346 98 438T227 601Q351 704 476 704Q514 704 524 703Q621 689 680 617T740 435ZM637 476Q637 565 591 615T476 665Q396 665 322 605Q242 542 200 428T157 216Q157 126 200 73T314 19Q404 19 485 98T608 313Q637 408 637 476Z"></path></g><g data-mml-node="mo" transform="translate(763,0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="mi" transform="translate(1152,0)"><path data-c="1D447" d="M40 437Q21 437 21 445Q21 450 37 501T71 602L88 651Q93 669 101 677H569H659Q691 677 697 676T704 667Q704 661 687 553T668 444Q668 437 649 437Q640 437 637 437T631 442L629 445Q629 451 635 490T641 551Q641 586 628 604T573 629Q568 630 515 631Q469 631 457 630T439 622Q438 621 368 343T298 60Q298 48 386 46Q418 46 427 45T436 36Q436 31 433 22Q429 4 424 1L422 0Q419 0 415 0Q410 0 363 1T228 2Q99 2 64 0H49Q43 6 43 9T45 27Q49 40 55 46H83H94Q174 46 189 55Q190 56 191 56Q196 59 201 76T241 233Q258 301 269 344Q339 619 339 625Q339 630 310 630H279Q212 630 191 624Q146 614 121 583T67 467Q60 445 57 441T43 437H40Z"></path></g><g data-mml-node="mo" transform="translate(2078.2,0)"><path data-c="22C5" d="M78 250Q78 274 95 292T138 310Q162 310 180 294T199 251Q199 226 182 208T139 190T96 207T78 250Z"></path></g><g data-mml-node="mo" transform="translate(2578.4,0) translate(0 -0.5)"><path data-c="7C" d="M139 -249H137Q125 -249 119 -235V251L120 737Q130 750 139 750Q152 750 159 735V-235Q151 -249 141 -249H139Z"></path></g><g data-mml-node="TeXAtom" data-mjx-texclass="ORD" transform="translate(2856.4,0)"><g data-mml-node="mi"><path data-c="59" d="M65 599Q65 618 107 650T204 683Q267 683 312 643T380 533T414 385T424 217Q424 186 423 160T422 123Q426 123 468 170T567 304T650 469Q661 503 661 519Q661 546 639 570Q615 591 583 591Q569 591 569 616Q569 640 582 661T613 683Q624 683 638 679T671 664T702 625T714 558Q714 472 639 329T426 45Q361 -21 282 -82T154 -143Q97 -143 64 -104T31 -20Q31 4 44 25T70 46Q78 46 81 39T87 16T97 -9Q127 -51 182 -51Q184 -51 187 -50H190Q233 -41 314 25Q330 36 330 40Q336 79 336 178Q336 508 223 594Q199 614 158 619L148 620L139 611Q111 586 83 586Q65 586 65 599Z"></path></g></g><g data-mml-node="msup" transform="translate(3570.4,0)"><g data-mml-node="mo" transform="translate(0 -0.5)"><path data-c="7C" d="M139 -249H137Q125 -249 119 -235V251L120 737Q130 750 139 750Q152 750 159 735V-235Q151 -249 141 -249H139Z"></path></g><g data-mml-node="mn" transform="translate(311,363) scale(0.707)"><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z"></path></g></g><g data-mml-node="mo" transform="translate(4285,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g></g></g></svg></mjx-container>。</p>
<h2 id="PyTorch-实现"><a href="#PyTorch-实现" class="headerlink" title="PyTorch 实现"></a>PyTorch 实现</h2><h3 id="CRF-Layer"><a href="#CRF-Layer" class="headerlink" title="CRF Layer"></a>CRF Layer</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">CRF</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, num_tags, batch_first=<span class="literal">True</span></span>):</span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        <span class="variable language_">self</span>.num_tags = num_tags</span><br><span class="line">        <span class="variable language_">self</span>.batch_first = batch_first</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 转移矩阵: transitions[i, j] = 从标签 j 转移到标签 i 的分数</span></span><br><span class="line">        <span class="variable language_">self</span>.transitions = nn.Parameter(torch.randn(num_tags, num_tags))</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 起始和结束转移</span></span><br><span class="line">        <span class="variable language_">self</span>.start_transitions = nn.Parameter(torch.randn(num_tags))</span><br><span class="line">        <span class="variable language_">self</span>.end_transitions = nn.Parameter(torch.randn(num_tags))</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, emissions, tags, mask=<span class="literal">None</span></span>):</span><br><span class="line">        <span class="string">"""计算负对数似然损失"""</span></span><br><span class="line">        <span class="keyword">if</span> mask <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">            mask = torch.ones_like(tags, dtype=torch.<span class="built_in">bool</span>)</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">if</span> <span class="variable language_">self</span>.batch_first:</span><br><span class="line">            emissions = emissions.transpose(<span class="number">0</span>, <span class="number">1</span>)</span><br><span class="line">            tags = tags.transpose(<span class="number">0</span>, <span class="number">1</span>)</span><br><span class="line">            mask = mask.transpose(<span class="number">0</span>, <span class="number">1</span>)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 计算分子（正确路径的分数）</span></span><br><span class="line">        numerator = <span class="variable language_">self</span>._compute_score(emissions, tags, mask)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 计算分母（配分函数）</span></span><br><span class="line">        denominator = <span class="variable language_">self</span>._compute_normalizer(emissions, mask)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 负对数似然</span></span><br><span class="line">        <span class="keyword">return</span> (denominator - numerator).mean()</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">_compute_score</span>(<span class="params">self, emissions, tags, mask</span>):</span><br><span class="line">        <span class="string">"""计算给定标签序列的分数"""</span></span><br><span class="line">        seq_len, batch_size = tags.shape</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 起始分数</span></span><br><span class="line">        score = <span class="variable language_">self</span>.start_transitions[tags[<span class="number">0</span>]]</span><br><span class="line">        score += emissions[<span class="number">0</span>, torch.arange(batch_size), tags[<span class="number">0</span>]]</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, seq_len):</span><br><span class="line">            <span class="comment"># 转移分数 + 发射分数</span></span><br><span class="line">            score += <span class="variable language_">self</span>.transitions[tags[i], tags[i-<span class="number">1</span>]] * mask[i]</span><br><span class="line">            score += emissions[i, torch.arange(batch_size), tags[i]] * mask[i]</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 结束分数</span></span><br><span class="line">        last_tag_idx = mask.<span class="built_in">sum</span>(dim=<span class="number">0</span>) - <span class="number">1</span></span><br><span class="line">        last_tags = tags.gather(<span class="number">0</span>, last_tag_idx.unsqueeze(<span class="number">0</span>)).squeeze(<span class="number">0</span>)</span><br><span class="line">        score += <span class="variable language_">self</span>.end_transitions[last_tags]</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">return</span> score</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">_compute_normalizer</span>(<span class="params">self, emissions, mask</span>):</span><br><span class="line">        <span class="string">"""前向算法计算配分函数"""</span></span><br><span class="line">        seq_len, batch_size, num_tags = emissions.shape</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 初始化</span></span><br><span class="line">        score = <span class="variable language_">self</span>.start_transitions + emissions[<span class="number">0</span>]</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, seq_len):</span><br><span class="line">            <span class="comment"># broadcast: (batch, num_tags, 1) + (num_tags, num_tags) + (batch, 1, num_tags)</span></span><br><span class="line">            broadcast_score = score.unsqueeze(<span class="number">2</span>)</span><br><span class="line">            broadcast_emissions = emissions[i].unsqueeze(<span class="number">1</span>)</span><br><span class="line">            </span><br><span class="line">            next_score = broadcast_score + <span class="variable language_">self</span>.transitions + broadcast_emissions</span><br><span class="line">            next_score = torch.logsumexp(next_score, dim=<span class="number">1</span>)</span><br><span class="line">            </span><br><span class="line">            <span class="comment"># 应用 mask</span></span><br><span class="line">            score = torch.where(mask[i].unsqueeze(<span class="number">1</span>), next_score, score)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 添加结束分数</span></span><br><span class="line">        score += <span class="variable language_">self</span>.end_transitions</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">return</span> torch.logsumexp(score, dim=<span class="number">1</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">decode</span>(<span class="params">self, emissions, mask=<span class="literal">None</span></span>):</span><br><span class="line">        <span class="string">"""Viterbi 解码"""</span></span><br><span class="line">        <span class="keyword">if</span> mask <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">            mask = torch.ones(emissions.shape[:<span class="number">2</span>], dtype=torch.<span class="built_in">bool</span>, device=emissions.device)</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">if</span> <span class="variable language_">self</span>.batch_first:</span><br><span class="line">            emissions = emissions.transpose(<span class="number">0</span>, <span class="number">1</span>)</span><br><span class="line">            mask = mask.transpose(<span class="number">0</span>, <span class="number">1</span>)</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">return</span> <span class="variable language_">self</span>._viterbi_decode(emissions, mask)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">_viterbi_decode</span>(<span class="params">self, emissions, mask</span>):</span><br><span class="line">        <span class="string">"""Viterbi 算法"""</span></span><br><span class="line">        seq_len, batch_size, num_tags = emissions.shape</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 初始化</span></span><br><span class="line">        score = <span class="variable language_">self</span>.start_transitions + emissions[<span class="number">0</span>]</span><br><span class="line">        history = []</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, seq_len):</span><br><span class="line">            broadcast_score = score.unsqueeze(<span class="number">2</span>)</span><br><span class="line">            broadcast_emissions = emissions[i].unsqueeze(<span class="number">1</span>)</span><br><span class="line">            </span><br><span class="line">            next_score = broadcast_score + <span class="variable language_">self</span>.transitions + broadcast_emissions</span><br><span class="line">            next_score, indices = next_score.<span class="built_in">max</span>(dim=<span class="number">1</span>)</span><br><span class="line">            </span><br><span class="line">            score = torch.where(mask[i].unsqueeze(<span class="number">1</span>), next_score, score)</span><br><span class="line">            history.append(indices)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 添加结束分数</span></span><br><span class="line">        score += <span class="variable language_">self</span>.end_transitions</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 回溯</span></span><br><span class="line">        best_tags_list = []</span><br><span class="line">        _, best_last_tag = score.<span class="built_in">max</span>(dim=<span class="number">1</span>)</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">for</span> idx <span class="keyword">in</span> <span class="built_in">range</span>(batch_size):</span><br><span class="line">            best_tags = [best_last_tag[idx].item()]</span><br><span class="line">            seq_length = <span class="built_in">int</span>(mask[:, idx].<span class="built_in">sum</span>().item())</span><br><span class="line">            </span><br><span class="line">            <span class="keyword">for</span> hist <span class="keyword">in</span> <span class="built_in">reversed</span>(history[:seq_length-<span class="number">1</span>]):</span><br><span class="line">                best_last_tag_idx = best_tags[-<span class="number">1</span>]</span><br><span class="line">                best_tags.append(hist[idx, best_last_tag_idx].item())</span><br><span class="line">            </span><br><span class="line">            best_tags.reverse()</span><br><span class="line">            best_tags_list.append(best_tags)</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">return</span> best_tags_list</span><br></pre></td></tr></table></figure>

<h3 id="与-BiLSTM-结合"><a href="#与-BiLSTM-结合" class="headerlink" title="与 BiLSTM 结合"></a>与 BiLSTM 结合</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">BiLSTM_CRF</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, vocab_size, embed_dim, hidden_dim, num_tags</span>):</span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        <span class="variable language_">self</span>.embedding = nn.Embedding(vocab_size, embed_dim)</span><br><span class="line">        <span class="variable language_">self</span>.lstm = nn.LSTM(embed_dim, hidden_dim // <span class="number">2</span>, </span><br><span class="line">                           num_layers=<span class="number">2</span>, bidirectional=<span class="literal">True</span>, batch_first=<span class="literal">True</span>)</span><br><span class="line">        <span class="variable language_">self</span>.fc = nn.Linear(hidden_dim, num_tags)</span><br><span class="line">        <span class="variable language_">self</span>.crf = CRF(num_tags)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x, tags, mask=<span class="literal">None</span></span>):</span><br><span class="line">        embeddings = <span class="variable language_">self</span>.embedding(x)</span><br><span class="line">        lstm_out, _ = <span class="variable language_">self</span>.lstm(embeddings)</span><br><span class="line">        emissions = <span class="variable language_">self</span>.fc(lstm_out)</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">return</span> <span class="variable language_">self</span>.crf(emissions, tags, mask)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">predict</span>(<span class="params">self, x, mask=<span class="literal">None</span></span>):</span><br><span class="line">        embeddings = <span class="variable language_">self</span>.embedding(x)</span><br><span class="line">        lstm_out, _ = <span class="variable language_">self</span>.lstm(embeddings)</span><br><span class="line">        emissions = <span class="variable language_">self</span>.fc(lstm_out)</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">return</span> <span class="variable language_">self</span>.crf.decode(emissions, mask)</span><br></pre></td></tr></table></figure>

<h2 id="现代应用：BERT-CRF"><a href="#现代应用：BERT-CRF" class="headerlink" title="现代应用：BERT + CRF"></a>现代应用：BERT + CRF</h2><p>尽管 BERT 已经很强大，但 CRF 层仍能带来一致性提升：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> transformers <span class="keyword">import</span> BertModel</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">BERT_CRF</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, bert_name, num_tags</span>):</span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        <span class="variable language_">self</span>.bert = BertModel.from_pretrained(bert_name)</span><br><span class="line">        <span class="variable language_">self</span>.dropout = nn.Dropout(<span class="number">0.1</span>)</span><br><span class="line">        <span class="variable language_">self</span>.fc = nn.Linear(<span class="variable language_">self</span>.bert.config.hidden_size, num_tags)</span><br><span class="line">        <span class="variable language_">self</span>.crf = CRF(num_tags)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, input_ids, attention_mask, tags=<span class="literal">None</span></span>):</span><br><span class="line">        outputs = <span class="variable language_">self</span>.bert(input_ids, attention_mask=attention_mask)</span><br><span class="line">        sequence_output = <span class="variable language_">self</span>.dropout(outputs.last_hidden_state)</span><br><span class="line">        emissions = <span class="variable language_">self</span>.fc(sequence_output)</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">if</span> tags <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">            <span class="keyword">return</span> <span class="variable language_">self</span>.crf(emissions, tags, attention_mask.<span class="built_in">bool</span>())</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">return</span> <span class="variable language_">self</span>.crf.decode(emissions, attention_mask.<span class="built_in">bool</span>())</span><br></pre></td></tr></table></figure>

<h3 id="性能对比（CoNLL-2003-NER）"><a href="#性能对比（CoNLL-2003-NER）" class="headerlink" title="性能对比（CoNLL-2003 NER）"></a>性能对比（CoNLL-2003 NER）</h3><table>
<thead>
<tr>
<th>模型</th>
<th>F1</th>
</tr>
</thead>
<tbody><tr>
<td>BiLSTM</td>
<td>88.2</td>
</tr>
<tr>
<td>BiLSTM + CRF</td>
<td>90.1</td>
</tr>
<tr>
<td>BERT</td>
<td>92.4</td>
</tr>
<tr>
<td>BERT + CRF</td>
<td>92.8</td>
</tr>
<tr>
<td>RoBERTa + CRF</td>
<td>93.2</td>
</tr>
</tbody></table>
<h2 id="训练技巧"><a href="#训练技巧" class="headerlink" title="训练技巧"></a>训练技巧</h2><h3 id="1-标签平滑"><a href="#1-标签平滑" class="headerlink" title="1. 标签平滑"></a>1. 标签平滑</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">label_smoothing_loss</span>(<span class="params">crf, emissions, tags, mask, epsilon=<span class="number">0.1</span></span>):</span><br><span class="line">    <span class="string">"""带标签平滑的 CRF 损失"""</span></span><br><span class="line">    nll_loss = crf(emissions, tags, mask)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 均匀分布的损失</span></span><br><span class="line">    uniform_loss = -torch.logsumexp(emissions, dim=-<span class="number">1</span>).mean()</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> (<span class="number">1</span> - epsilon) * nll_loss + epsilon * uniform_loss</span><br></pre></td></tr></table></figure>

<h3 id="2-约束解码"><a href="#2-约束解码" class="headerlink" title="2. 约束解码"></a>2. 约束解码</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 添加硬约束：B-X 后面只能接 I-X 或 O</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">add_constraints</span>(<span class="params">transitions, tag2idx</span>):</span><br><span class="line">    <span class="keyword">for</span> tag_from, idx_from <span class="keyword">in</span> tag2idx.items():</span><br><span class="line">        <span class="keyword">for</span> tag_to, idx_to <span class="keyword">in</span> tag2idx.items():</span><br><span class="line">            <span class="keyword">if</span> tag_from.startswith(<span class="string">'B-'</span>) <span class="keyword">or</span> tag_from.startswith(<span class="string">'I-'</span>):</span><br><span class="line">                entity = tag_from[<span class="number">2</span>:]</span><br><span class="line">                <span class="keyword">if</span> tag_to.startswith(<span class="string">'I-'</span>) <span class="keyword">and</span> tag_to[<span class="number">2</span>:] != entity:</span><br><span class="line">                    transitions.data[idx_to, idx_from] = -<span class="number">1e9</span></span><br></pre></td></tr></table></figure>

<h2 id="延伸阅读"><a href="#延伸阅读" class="headerlink" title="延伸阅读"></a>延伸阅读</h2><ul>
<li>Lafferty et al., <em>Conditional Random Fields</em> (2001)</li>
<li>Huang et al., <em>Bidirectional LSTM-CRF Models for Sequence Tagging</em> (2015)</li>
<li><a target="_blank" rel="noopener" href="https://pytorch-crf.readthedocs.io/">pytorch-crf Documentation</a></li>
</ul>
<hr>
<blockquote>
<p>转载请注明出处</p>
</blockquote>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




  <nav class="pagination">
    <span class="page-number current">1</span><a class="page-number" href="/page/2/">2</a><a class="extend next" rel="next" title="下一页" aria-label="下一页" href="/page/2/"><i class="fa fa-angle-right"></i></a>
  </nav>

</div>
  </main>

  <footer class="footer">
    <div class="footer-inner">

  <div class="copyright">
    &copy; 2019 – 
    <span itemprop="copyrightYear">2025</span>
    <span class="with-love">
      <i class="fa fa-heart"></i>
    </span>
    <span class="author" itemprop="copyrightHolder">fooSynaptic's Blog</span>
  </div>

    </div>
  </footer>

  
  <div class="toggle sidebar-toggle" role="button">
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
  </div>
  <div class="sidebar-dimmer"></div>
  <div class="back-to-top" role="button" aria-label="返回顶部">
    <i class="fa fa-arrow-up fa-lg"></i>
    <span>0%</span>
  </div>

<noscript>
  <div class="noscript-warning">Theme NexT works best with JavaScript enabled</div>
</noscript>

</body>
</html>
