---
title: "当我们把目光放在机器阅读理解，我们的期望到底是什么？"
date: 2019-10-04T07:41:50+08:00
tags:
  - MRC
  - Deep learning
  - Information retrive
---

> **机器阅读理解不是一个端到端的任务。当你把目光投向机器阅读理解时，你需要非常谨慎地考虑：自己的问题是否定义得足够清晰？**

## 什么是机器阅读理解

机器阅读理解在学术圈是一个端到端的任务，总体可以分成两类：

1. **开放领域的机器阅读理解**：被 Google 用于搜索技术中
2. **针对文档库的机器阅读理解**：传统使用检索系统，现在由于深度学习火热，大家都用阅读理解考试试题来模拟这部分任务

两者从技术原理上并没有太大分歧，只是第一种稍难。第二种虽然在开放数据上被各种刷新 SOTA，但远达不到公众对于深度学习能够理解文本信息的期望。

## 发展历程

早期最著名的作品之一是 Lehnert (1977) 中详细描述的 QUALM。基于脚本和计划框架，Lehnert 设计了一个问答理论，专注于语用问题和故事上下文在问答中的重要性，作为对人类阅读理解的建模。这个早期工作为语言理解设置了强大的愿景，但当时构建的系统非常小，仅限于手工编码的脚本，难以推广到更广泛的领域。

由于问题的复杂性，这方面的研究在 80-90 年代大多被忽视。90 年代末，阅读理解研究有了一些复苏，例如 Hirschman 等人 (1999) 创建了一个阅读理解数据集。

参考：[机器阅读理解发展历程](https://mp.weixin.qq.com/s/2gUhlgIaL_Qi0M8iPbWMkA)

## 深度学习时代的 MRC 模型演进

深度学习 MRC 必须介绍 SQuAD 数据集。在早期 span detection 任务上，F1 已经刷到超过 90%，但大家对包括 BERT 在内的模型能否真正理解文本仍不抱太大期望，所以推出了更具挑战性的 SQuAD 2.0。

**模型演进**（q 和 c 分别对应问题和文本内容）：

| 模型 | 特点 |
|------|------|
| **Match-LSTM** | 先把 q 和 c 分别经过双向 LSTM，再通过 attention 得到 c 中每个词对 q 里所有词的权重 |
| **BiDAF** | 分别计算 q→c 和 c→q 的 attention 权重，concat 做 fusion |
| **R-Net** | 利用 self-attention（2017年5月，在 Transformer 之后） |
| **QANet** | 利用 CNN 和 self-attention，结构类似 Transformer encoder |
| **BERT** | 开始刷榜 |

## MRC 任务分类

| 类型 | 描述 |
|------|------|
| **完形填空** (Cloze style) | 问题包含一个占位符 |
| **多项选择** (Multiple choice) | 从 k 个候选答案中选择 |
| **范围预测** (Span prediction) | 答案是文本中的一个片段 (start, end) |
| **自由形式回答** (Free-form answer) | 答案可以是任意形式的文本 |

现有模型做得相对好的只有完形填空和范围预测。前者是预测 token，后者是 CrossEntropy(p-end, p-start)。

**本质上，机器阅读理解就是更复杂的文本检索**。如果你期望它能做推理任务（比如数人数、计算时间差），目前是不可能完成的。

## 为什么不用 BM25？

事实上，BM25 在这些任务上不会比 MRC 差太多。一个中规中矩的深度学习 baseline 不一定比 BM25 加上更多文本特征工程更好（仅限于范围预测）。

但深度学习的优势是：它会给出一个短语或几个词，而不像 BM25 那样返回整句话。

我的实验结果：使用 self-attention + Match-LSTM + BiDAF + Pointer Network 结构，比 BM25 召回的文本序列短很多，但 BLEU 和 ROUGE 更高。

代码参考：[transformer_RC](https://github.com/fooSynaptic/transfromer_NN_Block/tree/master/transformer_RC)

## 实践经验

1. **问题分类**：如果问题中问到数字、人名，记录这部分信息
2. **命名实体识别**：对文章进行 NER，提高匹配实体的权重
3. **最长公共子串**：用 LCS 找到后续内容 [代码](https://github.com/fooSynaptic/exam/blob/master/Coding/LCS_string.py)
4. **数字和特殊字符**：保留完整信息并正确分词

如果你仍然觉得机器阅读理解不够好，请重新定义你的问题，或者不要期望阅读理解能做更多。
