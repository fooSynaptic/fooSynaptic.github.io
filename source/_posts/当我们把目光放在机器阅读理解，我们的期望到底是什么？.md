---
title: "当我们把目光放在机器阅读理解，我们的期望到底是什么？"
date: 2019-10-04T07:41:50+08:00
tags:
  - MRC
  - Deep learning
  - Information retrive
---

=========  
转载请注明出处  
=========  
**_机器阅读理解不是一个end2end的任务，当你把目光看向了机器阅读理解，你需要非常的谨慎，自己的问题是否定义的足够清晰_**

好了我想我们首先还是要先介绍一下机器阅读理解这个任务，在学术圈这是一个端到端的任务，并且总体可以分成两类：

  * 开放领域的机器阅读理解，这个被google用于搜索技术中。
  * 针对于文档库的机器阅读理解，这个传统都是用检索系统，现在由于深度学习非常火热，所以大家都拿阅读理解的考试试题的模拟这部分任务。



两者从技术原理上并没有太大的分歧，只是第一种稍难，第二种虽然说开放数据上被各种刷新SOTA（state of the art），但是远达不到公共对于深度学习能够理解文本信息的程度。  
那么具体来看机器阅读理解经历了一个什么样的发展历程呢？
    
    
    最著名的早期作品之一是 Lehnert ( 1977 ) 中详细描述的 QUALM。基于脚本和计划框架，Lehnert ( 1977 ) 设计了一个问答的理论，并且专注于语用问题和故事上下文在问答中的重要性，来作为对人类阅读理解的建模 ( Schank and Abelson， 1977 )。这个早期工作为语言理解设置了一个强大的愿景，但是当时构建的实际系统非常小，仅限于手工编码的脚本，并且很难推广到更广泛的领域。
    
    由于问题的复杂性，这方面的研究在20世纪80年代和90年代大多被忽视。在20世纪90年代末，人们对阅读理解的兴趣有了一些小小的复苏，例如 Hirschman 等人 ( 1999 ) 创建了一个阅读理解数据集，以及随后在 ANLP/NAACL 2000年举办了一个关于阅读理解测试作为基于计算机的理解系统评估的研讨会。数据集包括60个用于开发的故事和60个用于测试的三至六年级的故事，附有一些简单的 who，what，when，where，why 这样的简单问题。它只需要系统返回包含正确答案的句子。这一阶段开发的系统主要是基于规则的词包方法。例如 DEEP READ 系统 ( Hirschman et al. 1999 ) 中进行词干分析、语义类识别和代词解析等浅层语言处理，或者像是 QUARC 系统 ( Riloff and THElen，2000 ) 中手动生成基于词汇和语义对应的规则或者是以上两个的组合体 ( Charnizak et al.， 2000 )。这些系统在检索正确句子时达到了30%-40%的准确率。

[ref](https://mp.weixin.qq.com/s/2gUhlgIaL_Qi0M8iPbWMkA)  
早期的工作者看到这个任务，首选的就是系统，这很符合直觉也和本文的观点一致，不管是设计qa问答机器人还是文本检索系统，其本身必定是一个系统，需要一定的特征设计和结合数据的程序设计。

那么现在基于深度学习设计的阅读理解模型是如何做的呢？  
涉及到深度学习模型的MRC就一定要介绍SQUAD这个数据集了，在早期span detection这个数据f1已经刷到了超过90%，但是大家任然对包括Bert在内的这些机器阅读理解模型不抱太大期望能够做到理解文本，所以现在也已经推出了更新的SQUAD2。。。  
根据笔者的经验，机器阅读理解这个任务，在深度学习里面经历了这么几个过程  
denote： q和c分别对应阅读理解中的问题和文本内容

  * Match-LSTM 先把q和c分别经过双向的LSTM，再通过attention机制，得到c中每个词q里所有词的权重，得到新的q的向量
  * BIDAF 分别计算q到c和c到q的attention 权重，利用这个权重乘以q和c得到q-wise的c和c-wise的q，concat起来做fusion
  * R-net 利用了self-attention，这边文章在 May. 6, 2017，在transformer之后，很显然self-attention的借鉴打破了之前到处attend的局势
  * QA-net 利用了CNN，和self-attention一直cnn也能够捕捉到并行的词依赖特征，虽然不如self-attention那么棒，但是QAnet经过了精心设计的让他好transformer的encoder结构很像。
  * Bert bert开始刷榜



* * *

我们介绍的这些模型都不差，但是存在的问题也很明显，首先阅读理解这个任务分为好几个任务

  * 完形填空类型 ( Cloze style )：问题包含一个 placeholder ( 占位符 )。
  * 多项选择类型 ( Multiple choice )：在这个类别下，正确答案从 k 个假设答案中选择 ( 比如：k=4 ) 
  * 范围预测类型 ( Span prediction )：这个类别也被称为抽取式问答 ( extractive question answering ) 并且答案必须是文本中的一个范围。因此，答案可以表示为( astart，aend )，其中 1 ≤ astart ≤ aend ≤ lp。并且答案对英语 pastart, . . . , paend。
  * 自由形式回答类型 ( Free-form answer )：最后一种类型允许答案是任何形式的文本 ( 即，任意长度的单词序列 )，形式上：a ∈ V∗。



那么现有的模型能够做的相对好的，只有完形填空和范围预测，前者是predict token，后者是CrossEntry(p-end,p-start)，我不知道读者现在脑海里想的是什么，我想到的就是检索，机器阅读理解就是更家复杂的文本检索，这既是当今机器阅读理解的全部，如果你期望他能够做一些推理的任务，比如帮你数多少个人，时间差，在当前是不可能完成的。  
那么我们能够用检索来完成，为何不用传统的方法BM25？  
事实上，BM25在这些任务上不会比机器阅读理解差太多，一个中规中矩的深度学习baseline不会比BM25加上更多的文本特征工程更好（仅限于范围预测），但是深度学习带来的优势是，他真的是在帮你做阅读理解，他会抛出一个短语，几个词，而不是像BM25那样给出一句一句话。  
根据我的个人实验，我使用了self-attention+Match_lstm+BIDAF+pointer_network的结构实现了一个阅读理解模型，比BM25召回的文本序列要短非常多，但是BLEU和Rouge要比BM25高。[ref](https://github.com/fooSynaptic/transfromer_NN_Block/tree/master/transformer_RC)

经验：

  * 把问题分类，如果问题中详细的问道数字，人名，记录这部分信息。
  * 对文章进行命名实体识别，把能够对应上的实体特征，提高该部分词的权重。
  * 用最长的匹配字符串去找到后面的内容[lcs_continue_string](https://github.com/fooSynaptic/exam/blob/master/Coding/LCS_string.py)
  * 数字和特殊字符一定要保留完整信息并且成词



如果您仍然觉得机器阅读理解不够棒，不能满足您的需求，请重新定义您的问题，或者不要期望阅读理解为您做更多。
