<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width">
<meta name="theme-color" content="#222"><meta name="generator" content="Hexo 8.1.1">

  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/jojo_median.ico">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/jojo_small.ico">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">



<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/7.0.0/css/all.min.css" integrity="sha256-VHqXKFhhMxcpubYf9xiWdCiojEbY9NexQ4jh8AxbvcM=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/animate.css/3.1.1/animate.min.css" integrity="sha256-PR7ttpcvz8qrF57fur/yAx1qXMFJeJFiA6pSzWi0OIE=" crossorigin="anonymous">

<script class="next-config" data-name="main" type="application/json">{"hostname":"foosynaptic.github.io","root":"/","images":"/images","scheme":"Muse","darkmode":false,"version":"8.26.0","exturl":false,"sidebar":{"position":"left","width_expanded":320,"width_dual_column":240,"display":"post","padding":18,"offset":12},"hljswrap":true,"codeblock":{"theme":{"light":"default","dark":"dark"},"prism":{"light":"prism","dark":"prism-dark"},"copy_button":{"enable":true,"style":null},"fold":{"enable":false,"height":500},"language":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"stickytabs":false,"motion":{"enable":true,"async":false,"duration":200,"transition":{"menu_item":"fadeInDown","post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},"i18n":{"placeholder":"搜索...","empty":"没有找到任何搜索结果：${query}","hits_time":"找到 ${hits} 个搜索结果（用时 ${time} 毫秒）","hits":"找到 ${hits} 个搜索结果"},"path":"/search.json","localsearch":{"enable":true,"top_n_per_article":1,"unescape":false,"preload":false,"trigger":"auto"}}</script><script src="/js/config.js" defer></script>

    <meta name="description" content="本文综述神经网络在机器阅读理解和对话系统中的发展历程，从早期的注意力机制到现代大语言模型。 发展时间线12345678910111213142015-2016: 注意力机制兴起    └── Attentive Reader, Impatient Reader, BiDAF2017-2018: 深度交互与预训练    └── R-Net, QANet, BERT2019-2020: 大规模预训练">
<meta property="og:type" content="article">
<meta property="og:title" content="神经网络机器阅读理解：从 Attention 到 LLM">
<meta property="og:url" content="https://foosynaptic.github.io/2019/11/22/Nuural-Approaches-to-Machine-Reading-Comprehension-and-Dialogue/index.html">
<meta property="og:site_name" content="fooSynaptic">
<meta property="og:description" content="本文综述神经网络在机器阅读理解和对话系统中的发展历程，从早期的注意力机制到现代大语言模型。 发展时间线12345678910111213142015-2016: 注意力机制兴起    └── Attentive Reader, Impatient Reader, BiDAF2017-2018: 深度交互与预训练    └── R-Net, QANet, BERT2019-2020: 大规模预训练">
<meta property="og:locale" content="zh_CN">
<meta property="article:published_time" content="2019-11-21T21:31:56.000Z">
<meta property="article:modified_time" content="2025-12-28T01:55:57.060Z">
<meta property="article:author" content="fooSynaptic">
<meta property="article:tag" content="Deep learning">
<meta property="article:tag" content="KBQA">
<meta property="article:tag" content="LLM">
<meta property="article:tag" content="MRC">
<meta name="twitter:card" content="summary">


<link rel="canonical" href="https://foosynaptic.github.io/2019/11/22/Nuural-Approaches-to-Machine-Reading-Comprehension-and-Dialogue/">


<script class="next-config" data-name="page" type="application/json">{"sidebar":"","isHome":false,"isPost":true,"lang":"zh-CN","comments":true,"permalink":"https://foosynaptic.github.io/2019/11/22/Nuural-Approaches-to-Machine-Reading-Comprehension-and-Dialogue/","path":"2019/11/22/Nuural-Approaches-to-Machine-Reading-Comprehension-and-Dialogue/","title":"神经网络机器阅读理解：从 Attention 到 LLM"}</script>

<script class="next-config" data-name="calendar" type="application/json">""</script>
<title>神经网络机器阅读理解：从 Attention 到 LLM | fooSynaptic</title>
  








  
  <script src="https://cdnjs.cloudflare.com/ajax/libs/animejs/3.2.1/anime.min.js" integrity="sha256-XL2inqUJaslATFnHdJOi9GfQ60on8Wx1C2H8DYiN1xY=" crossorigin="anonymous" defer></script>
<script src="/js/utils.js" defer></script><script src="/js/motion.js" defer></script><script src="/js/sidebar.js" defer></script><script src="/js/next-boot.js" defer></script>

  <script src="https://cdnjs.cloudflare.com/ajax/libs/hexo-generator-searchdb/1.5.0/search.js" integrity="sha256-xFC6PJ82SL9b3WkGjFavNiA9gm5z6UBxWPiu4CYjptg=" crossorigin="anonymous" defer></script>
<script src="/js/third-party/search/local-search.js" defer></script>







  




  

  <script class="next-config" data-name="enableMath" type="application/json">true</script><script class="next-config" data-name="mathjax" type="application/json">{"enable":true,"tags":"none","js":{"url":"https://cdnjs.cloudflare.com/ajax/libs/mathjax/3.2.2/es5/tex-mml-chtml.js","integrity":"sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI="}}</script>
<script src="/js/third-party/math/mathjax.js" defer></script>



  <noscript>
    <link rel="stylesheet" href="/css/noscript.css">
  </noscript>
<style>mjx-container[jax="SVG"] {
  direction: ltr;
}

mjx-container[jax="SVG"] > svg {
  overflow: visible;
}

mjx-container[jax="SVG"][display="true"] {
  display: block;
  text-align: center;
  margin: 1em 0;
}

mjx-container[jax="SVG"][justify="left"] {
  text-align: left;
}

mjx-container[jax="SVG"][justify="right"] {
  text-align: right;
}

g[data-mml-node="merror"] > g {
  fill: red;
  stroke: red;
}

g[data-mml-node="merror"] > rect[data-background] {
  fill: yellow;
  stroke: none;
}

g[data-mml-node="mtable"] > line[data-line] {
  stroke-width: 70px;
  fill: none;
}

g[data-mml-node="mtable"] > rect[data-frame] {
  stroke-width: 70px;
  fill: none;
}

g[data-mml-node="mtable"] > .mjx-dashed {
  stroke-dasharray: 140;
}

g[data-mml-node="mtable"] > .mjx-dotted {
  stroke-linecap: round;
  stroke-dasharray: 0,140;
}

g[data-mml-node="mtable"] > svg {
  overflow: visible;
}

[jax="SVG"] mjx-tool {
  display: inline-block;
  position: relative;
  width: 0;
  height: 0;
}

[jax="SVG"] mjx-tool > mjx-tip {
  position: absolute;
  top: 0;
  left: 0;
}

mjx-tool > mjx-tip {
  display: inline-block;
  padding: .2em;
  border: 1px solid #888;
  font-size: 70%;
  background-color: #F8F8F8;
  color: black;
  box-shadow: 2px 2px 5px #AAAAAA;
}

g[data-mml-node="maction"][data-toggle] {
  cursor: pointer;
}

mjx-status {
  display: block;
  position: fixed;
  left: 1em;
  bottom: 1em;
  min-width: 25%;
  padding: .2em .4em;
  border: 1px solid #888;
  font-size: 90%;
  background-color: #F8F8F8;
  color: black;
}

foreignObject[data-mjx-xml] {
  font-family: initial;
  line-height: normal;
  overflow: visible;
}

.MathJax path {
  stroke-width: 3;
}

mjx-container[display="true"] {
  overflow: auto hidden;
}

mjx-container[display="true"] + br {
  display: none;
}
</style></head>

<body itemscope itemtype="http://schema.org/WebPage" class="use-motion">
  <div class="headband"></div>

  <main class="main">
    <div class="column">
      <header class="header" itemscope itemtype="http://schema.org/WPHeader"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏" role="button">
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <i class="logo-line"></i>
      <p class="site-title">fooSynaptic</p>
      <i class="logo-line"></i>
    </a>
      <p class="site-subtitle" itemprop="description">Any problem, please Contact me: 2313990450@qq.com</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger" aria-label="搜索" role="button">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>



<nav class="site-nav">
  <ul class="main-menu menu"><li class="menu-item menu-item-home"><a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a></li><li class="menu-item menu-item-about"><a href="/about/" rel="section"><i class="fa fa-user fa-fw"></i>关于</a></li><li class="menu-item menu-item-archives"><a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档</a></li><li class="menu-item menu-item-tags"><a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>标签</a></li><li class="menu-item menu-item-categories"><a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>分类</a></li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>搜索
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup">
      <div class="search-header">
        <span class="search-icon">
          <i class="fa fa-search"></i>
        </span>
        <div class="search-input-container">
          <input autocomplete="off" autocapitalize="off" maxlength="80"
                placeholder="搜索..." spellcheck="false"
                type="search" class="search-input">
        </div>
        <span class="popup-btn-close" role="button">
          <i class="fa fa-times-circle"></i>
        </span>
      </div>
      <div class="search-result-container">
        <div class="search-result-icon">
          <i class="fa fa-spinner fa-pulse fa-5x"></i>
        </div>
      </div>
    </div>
  </div>

</header>
        
  
  <aside class="sidebar">

    <div class="sidebar-inner sidebar-nav-active sidebar-toc-active">
      <ul class="sidebar-nav">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <div class="sidebar-panel-container">
        <!--noindex-->
        <div class="post-toc-wrap sidebar-panel">
            <div class="post-toc animated"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%8F%91%E5%B1%95%E6%97%B6%E9%97%B4%E7%BA%BF"><span class="nav-number">1.</span> <span class="nav-text">发展时间线</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AF%E6%BC%94%E8%BF%9B"><span class="nav-number">2.</span> <span class="nav-text">核心技术演进</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E9%98%B6%E6%AE%B5%E4%B8%80%EF%BC%9A%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6-2015-2017"><span class="nav-number">2.1.</span> <span class="nav-text">阶段一：注意力机制 (2015-2017)</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E9%98%B6%E6%AE%B5%E4%BA%8C%EF%BC%9A%E6%B7%B1%E5%BA%A6%E4%BA%A4%E4%BA%92-2017-2018"><span class="nav-number">2.2.</span> <span class="nav-text">阶段二：深度交互 (2017-2018)</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E9%98%B6%E6%AE%B5%E4%B8%89%EF%BC%9A%E9%A2%84%E8%AE%AD%E7%BB%83%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B-2018-2020"><span class="nav-number">2.3.</span> <span class="nav-text">阶段三：预训练语言模型 (2018-2020)</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E9%98%B6%E6%AE%B5%E5%9B%9B%EF%BC%9A%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B-2020-%E8%87%B3%E4%BB%8A"><span class="nav-number">2.4.</span> <span class="nav-text">阶段四：大语言模型 (2020-至今)</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%9E%B6%E6%9E%84%E5%AF%B9%E6%AF%94"><span class="nav-number">3.</span> <span class="nav-text">架构对比</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E7%8E%B0%E4%BB%A3-MRC-%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1"><span class="nav-number">4.</span> <span class="nav-text">现代 MRC 系统设计</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#RAG-%E6%9E%B6%E6%9E%84"><span class="nav-number">4.1.</span> <span class="nav-text">RAG 架构</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%A4%9A%E8%B7%B3%E6%8E%A8%E7%90%86"><span class="nav-number">4.2.</span> <span class="nav-text">多跳推理</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%AF%B9%E8%AF%9D%E7%B3%BB%E7%BB%9F%E4%B8%AD%E7%9A%84-MRC"><span class="nav-number">5.</span> <span class="nav-text">对话系统中的 MRC</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%AF%B9%E8%AF%9D%E5%BC%8F%E9%97%AE%E7%AD%94"><span class="nav-number">5.1.</span> <span class="nav-text">对话式问答</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E8%AF%84%E4%BC%B0%E4%BD%93%E7%B3%BB"><span class="nav-number">6.</span> <span class="nav-text">评估体系</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E4%BC%A0%E7%BB%9F%E6%8C%87%E6%A0%87"><span class="nav-number">6.1.</span> <span class="nav-text">传统指标</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#LLM-%E6%97%B6%E4%BB%A3%E6%8C%87%E6%A0%87"><span class="nav-number">6.2.</span> <span class="nav-text">LLM 时代指标</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%BB%B6%E4%BC%B8%E9%98%85%E8%AF%BB"><span class="nav-number">7.</span> <span class="nav-text">延伸阅读</span></a></li></ol></div>
        </div>
        <!--/noindex-->

        <div class="site-overview-wrap sidebar-panel">
          <div class="site-author animated" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="fooSynaptic"
      src="/images/avatar.gif">
  <p class="site-author-name" itemprop="name">fooSynaptic</p>
  <div class="site-description" itemprop="description">Head first to the Truth as Synaptic.</div>
</div>
<div class="site-state-wrap animated">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
        <a href="/archives/">
          <span class="site-state-item-count">17</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
          <a href="/categories/">
        <span class="site-state-item-count">2</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
      <div class="site-state-item site-state-tags">
          <a href="/tags/">
        <span class="site-state-item-count">38</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author animated">
      <span class="links-of-author-item">
        <a href="https://github.com/fooSynaptic" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;fooSynaptic" rel="noopener me" target="_blank"><i class="fab fa-github fa-fw"></i>GitHub</a>
      </span>
      <span class="links-of-author-item">
        <a href="mailto:2313990450@qq.com" title="E-Mail → mailto:2313990450@qq.com" rel="noopener me" target="_blank"><i class="fa fa-envelope fa-fw"></i>E-Mail</a>
      </span>
  </div>

        </div>
      </div>
    </div>

    
  </aside>


    </div>

    <div class="main-inner post posts-expand">


  


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://foosynaptic.github.io/2019/11/22/Nuural-Approaches-to-Machine-Reading-Comprehension-and-Dialogue/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="fooSynaptic">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="fooSynaptic">
      <meta itemprop="description" content="Head first to the Truth as Synaptic.">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="神经网络机器阅读理解：从 Attention 到 LLM | fooSynaptic">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          神经网络机器阅读理解：从 Attention 到 LLM
        </h1>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2019-11-22 05:31:56" itemprop="dateCreated datePublished" datetime="2019-11-22T05:31:56+08:00">2019-11-22</time>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody"><p>本文综述神经网络在机器阅读理解和对话系统中的发展历程，从早期的注意力机制到现代大语言模型。</p>
<h2 id="发展时间线"><a href="#发展时间线" class="headerlink" title="发展时间线"></a>发展时间线</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">2015-2016: 注意力机制兴起</span><br><span class="line">    └── Attentive Reader, Impatient Reader, BiDAF</span><br><span class="line"></span><br><span class="line">2017-2018: 深度交互与预训练</span><br><span class="line">    └── R-Net, QANet, BERT</span><br><span class="line"></span><br><span class="line">2019-2020: 大规模预训练</span><br><span class="line">    └── RoBERTa, ALBERT, T5</span><br><span class="line"></span><br><span class="line">2021-2023: 大语言模型时代</span><br><span class="line">    └── GPT-3, ChatGPT, GPT-4, LLaMA</span><br><span class="line"></span><br><span class="line">2024-: 检索增强与多模态</span><br><span class="line">    └── RAG, Vision-Language Models</span><br></pre></td></tr></table></figure>

<h2 id="核心技术演进"><a href="#核心技术演进" class="headerlink" title="核心技术演进"></a>核心技术演进</h2><h3 id="阶段一：注意力机制-2015-2017"><a href="#阶段一：注意力机制-2015-2017" class="headerlink" title="阶段一：注意力机制 (2015-2017)"></a>阶段一：注意力机制 (2015-2017)</h3><p><strong>问题</strong>：如何让模型”关注”与问题相关的上下文？</p>
<p><mjx-container class="MathJax" jax="SVG" display="true"><svg style="vertical-align: -0.566ex;" xmlns="http://www.w3.org/2000/svg" width="21.681ex" height="2.262ex" role="img" focusable="false" viewBox="0 -750 9583.1 1000"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="msub"><g data-mml-node="mi"><path data-c="1D6FC" d="M34 156Q34 270 120 356T309 442Q379 442 421 402T478 304Q484 275 485 237V208Q534 282 560 374Q564 388 566 390T582 393Q603 393 603 385Q603 376 594 346T558 261T497 161L486 147L487 123Q489 67 495 47T514 26Q528 28 540 37T557 60Q559 67 562 68T577 70Q597 70 597 62Q597 56 591 43Q579 19 556 5T512 -10H505Q438 -10 414 62L411 69L400 61Q390 53 370 41T325 18T267 -2T203 -11Q124 -11 79 39T34 156ZM208 26Q257 26 306 47T379 90L403 112Q401 255 396 290Q382 405 304 405Q235 405 183 332Q156 292 139 224T121 120Q121 71 146 49T208 26Z"></path></g><g data-mml-node="mi" transform="translate(673,-150) scale(0.707)"><path data-c="1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path></g></g><g data-mml-node="mo" transform="translate(1244.7,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="mtext" transform="translate(2300.5,0)"><path data-c="73" d="M295 316Q295 356 268 385T190 414Q154 414 128 401Q98 382 98 349Q97 344 98 336T114 312T157 287Q175 282 201 278T245 269T277 256Q294 248 310 236T342 195T359 133Q359 71 321 31T198 -10H190Q138 -10 94 26L86 19L77 10Q71 4 65 -1L54 -11H46H42Q39 -11 33 -5V74V132Q33 153 35 157T45 162H54Q66 162 70 158T75 146T82 119T101 77Q136 26 198 26Q295 26 295 104Q295 133 277 151Q257 175 194 187T111 210Q75 227 54 256T33 318Q33 357 50 384T93 424T143 442T187 447H198Q238 447 268 432L283 424L292 431Q302 440 314 448H322H326Q329 448 335 442V310L329 304H301Q295 310 295 316Z"></path><path data-c="6F" d="M28 214Q28 309 93 378T250 448Q340 448 405 380T471 215Q471 120 407 55T250 -10Q153 -10 91 57T28 214ZM250 30Q372 30 372 193V225V250Q372 272 371 288T364 326T348 362T317 390T268 410Q263 411 252 411Q222 411 195 399Q152 377 139 338T126 246V226Q126 130 145 91Q177 30 250 30Z" transform="translate(394,0)"></path><path data-c="66" d="M273 0Q255 3 146 3Q43 3 34 0H26V46H42Q70 46 91 49Q99 52 103 60Q104 62 104 224V385H33V431H104V497L105 564L107 574Q126 639 171 668T266 704Q267 704 275 704T289 705Q330 702 351 679T372 627Q372 604 358 590T321 576T284 590T270 627Q270 647 288 667H284Q280 668 273 668Q245 668 223 647T189 592Q183 572 182 497V431H293V385H185V225Q185 63 186 61T189 57T194 54T199 51T206 49T213 48T222 47T231 47T241 46T251 46H282V0H273Z" transform="translate(894,0)"></path><path data-c="74" d="M27 422Q80 426 109 478T141 600V615H181V431H316V385H181V241Q182 116 182 100T189 68Q203 29 238 29Q282 29 292 100Q293 108 293 146V181H333V146V134Q333 57 291 17Q264 -10 221 -10Q187 -10 162 2T124 33T105 68T98 100Q97 107 97 248V385H18V422H27Z" transform="translate(1200,0)"></path><path data-c="6D" d="M41 46H55Q94 46 102 60V68Q102 77 102 91T102 122T103 161T103 203Q103 234 103 269T102 328V351Q99 370 88 376T43 385H25V408Q25 431 27 431L37 432Q47 433 65 434T102 436Q119 437 138 438T167 441T178 442H181V402Q181 364 182 364T187 369T199 384T218 402T247 421T285 437Q305 442 336 442Q351 442 364 440T387 434T406 426T421 417T432 406T441 395T448 384T452 374T455 366L457 361L460 365Q463 369 466 373T475 384T488 397T503 410T523 422T546 432T572 439T603 442Q729 442 740 329Q741 322 741 190V104Q741 66 743 59T754 49Q775 46 803 46H819V0H811L788 1Q764 2 737 2T699 3Q596 3 587 0H579V46H595Q656 46 656 62Q657 64 657 200Q656 335 655 343Q649 371 635 385T611 402T585 404Q540 404 506 370Q479 343 472 315T464 232V168V108Q464 78 465 68T468 55T477 49Q498 46 526 46H542V0H534L510 1Q487 2 460 2T422 3Q319 3 310 0H302V46H318Q379 46 379 62Q380 64 380 200Q379 335 378 343Q372 371 358 385T334 402T308 404Q263 404 229 370Q202 343 195 315T187 232V168V108Q187 78 188 68T191 55T200 49Q221 46 249 46H265V0H257L234 1Q210 2 183 2T145 3Q42 3 33 0H25V46H41Z" transform="translate(1589,0)"></path><path data-c="61" d="M137 305T115 305T78 320T63 359Q63 394 97 421T218 448Q291 448 336 416T396 340Q401 326 401 309T402 194V124Q402 76 407 58T428 40Q443 40 448 56T453 109V145H493V106Q492 66 490 59Q481 29 455 12T400 -6T353 12T329 54V58L327 55Q325 52 322 49T314 40T302 29T287 17T269 6T247 -2T221 -8T190 -11Q130 -11 82 20T34 107Q34 128 41 147T68 188T116 225T194 253T304 268H318V290Q318 324 312 340Q290 411 215 411Q197 411 181 410T156 406T148 403Q170 388 170 359Q170 334 154 320ZM126 106Q126 75 150 51T209 26Q247 26 276 49T315 109Q317 116 318 175Q318 233 317 233Q309 233 296 232T251 223T193 203T147 166T126 106Z" transform="translate(2422,0)"></path><path data-c="78" d="M201 0Q189 3 102 3Q26 3 17 0H11V46H25Q48 47 67 52T96 61T121 78T139 96T160 122T180 150L226 210L168 288Q159 301 149 315T133 336T122 351T113 363T107 370T100 376T94 379T88 381T80 383Q74 383 44 385H16V431H23Q59 429 126 429Q219 429 229 431H237V385Q201 381 201 369Q201 367 211 353T239 315T268 274L272 270L297 304Q329 345 329 358Q329 364 327 369T322 376T317 380T310 384L307 385H302V431H309Q324 428 408 428Q487 428 493 431H499V385H492Q443 385 411 368Q394 360 377 341T312 257L296 236L358 151Q424 61 429 57T446 50Q464 46 499 46H516V0H510H502Q494 1 482 1T457 2T432 2T414 3Q403 3 377 3T327 1L304 0H295V46H298Q309 46 320 51T331 63Q331 65 291 120L250 175Q249 174 219 133T185 88Q181 83 181 74Q181 63 188 55T206 46Q208 46 208 23V0H201Z" transform="translate(2922,0)"></path></g><g data-mml-node="mo" transform="translate(5750.5,0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="mi" transform="translate(6139.5,0)"><path data-c="1D460" d="M131 289Q131 321 147 354T203 415T300 442Q362 442 390 415T419 355Q419 323 402 308T364 292Q351 292 340 300T328 326Q328 342 337 354T354 372T367 378Q368 378 368 379Q368 382 361 388T336 399T297 405Q249 405 227 379T204 326Q204 301 223 291T278 274T330 259Q396 230 396 163Q396 135 385 107T352 51T289 7T195 -10Q118 -10 86 19T53 87Q53 126 74 143T118 160Q133 160 146 151T160 120Q160 94 142 76T111 58Q109 57 108 57T107 55Q108 52 115 47T146 34T201 27Q237 27 263 38T301 66T318 97T323 122Q323 150 302 164T254 181T195 196T148 231Q131 256 131 289Z"></path></g><g data-mml-node="mo" transform="translate(6608.5,0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="msub" transform="translate(6997.5,0)"><g data-mml-node="mi"><path data-c="210E" d="M137 683Q138 683 209 688T282 694Q294 694 294 685Q294 674 258 534Q220 386 220 383Q220 381 227 388Q288 442 357 442Q411 442 444 415T478 336Q478 285 440 178T402 50Q403 36 407 31T422 26Q450 26 474 56T513 138Q516 149 519 151T535 153Q555 153 555 145Q555 144 551 130Q535 71 500 33Q466 -10 419 -10H414Q367 -10 346 17T325 74Q325 90 361 192T398 345Q398 404 354 404H349Q266 404 205 306L198 293L164 158Q132 28 127 16Q114 -11 83 -11Q69 -11 59 -2T48 16Q48 30 121 320L195 616Q195 629 188 632T149 637H128Q122 643 122 645T124 664Q129 683 137 683Z"></path></g><g data-mml-node="mi" transform="translate(609,-150) scale(0.707)"><path data-c="1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path></g></g><g data-mml-node="mo" transform="translate(7900.5,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path></g><g data-mml-node="mi" transform="translate(8345.1,0)"><path data-c="1D45E" d="M33 157Q33 258 109 349T280 441Q340 441 372 389Q373 390 377 395T388 406T404 418Q438 442 450 442Q454 442 457 439T460 434Q460 425 391 149Q320 -135 320 -139Q320 -147 365 -148H390Q396 -156 396 -157T393 -175Q389 -188 383 -194H370Q339 -192 262 -192Q234 -192 211 -192T174 -192T157 -193Q143 -193 143 -185Q143 -182 145 -170Q149 -154 152 -151T172 -148Q220 -148 230 -141Q238 -136 258 -53T279 32Q279 33 272 29Q224 -10 172 -10Q117 -10 75 30T33 157ZM352 326Q329 405 277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q233 26 290 98L298 109L352 326Z"></path></g><g data-mml-node="mo" transform="translate(8805.1,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g><g data-mml-node="mo" transform="translate(9194.1,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g></g></g></svg></mjx-container></p>
<p><mjx-container class="MathJax" jax="SVG" display="true"><svg style="vertical-align: -2.697ex;" xmlns="http://www.w3.org/2000/svg" width="11.871ex" height="4.847ex" role="img" focusable="false" viewBox="0 -950 5247.1 2142.2"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D450" d="M34 159Q34 268 120 355T306 442Q362 442 394 418T427 355Q427 326 408 306T360 285Q341 285 330 295T319 325T330 359T352 380T366 386H367Q367 388 361 392T340 400T306 404Q276 404 249 390Q228 381 206 359Q162 315 142 235T121 119Q121 73 147 50Q169 26 205 26H209Q321 26 394 111Q403 121 406 121Q410 121 419 112T429 98T420 83T391 55T346 25T282 0T202 -11Q127 -11 81 37T34 159Z"></path></g><g data-mml-node="mo" transform="translate(710.8,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="munder" transform="translate(1766.6,0)"><g data-mml-node="mo"><path data-c="2211" d="M60 948Q63 950 665 950H1267L1325 815Q1384 677 1388 669H1348L1341 683Q1320 724 1285 761Q1235 809 1174 838T1033 881T882 898T699 902H574H543H251L259 891Q722 258 724 252Q725 250 724 246Q721 243 460 -56L196 -356Q196 -357 407 -357Q459 -357 548 -357T676 -358Q812 -358 896 -353T1063 -332T1204 -283T1307 -196Q1328 -170 1348 -124H1388Q1388 -125 1381 -145T1356 -210T1325 -294L1267 -449L666 -450Q64 -450 61 -448Q55 -446 55 -439Q55 -437 57 -433L590 177Q590 178 557 222T452 366T322 544L56 909L55 924Q55 945 60 948Z"></path></g><g data-mml-node="mi" transform="translate(600,-1084.4) scale(0.707)"><path data-c="1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path></g></g><g data-mml-node="msub" transform="translate(3377.2,0)"><g data-mml-node="mi"><path data-c="1D6FC" d="M34 156Q34 270 120 356T309 442Q379 442 421 402T478 304Q484 275 485 237V208Q534 282 560 374Q564 388 566 390T582 393Q603 393 603 385Q603 376 594 346T558 261T497 161L486 147L487 123Q489 67 495 47T514 26Q528 28 540 37T557 60Q559 67 562 68T577 70Q597 70 597 62Q597 56 591 43Q579 19 556 5T512 -10H505Q438 -10 414 62L411 69L400 61Q390 53 370 41T325 18T267 -2T203 -11Q124 -11 79 39T34 156ZM208 26Q257 26 306 47T379 90L403 112Q401 255 396 290Q382 405 304 405Q235 405 183 332Q156 292 139 224T121 120Q121 71 146 49T208 26Z"></path></g><g data-mml-node="mi" transform="translate(673,-150) scale(0.707)"><path data-c="1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path></g></g><g data-mml-node="msub" transform="translate(4344.2,0)"><g data-mml-node="mi"><path data-c="210E" d="M137 683Q138 683 209 688T282 694Q294 694 294 685Q294 674 258 534Q220 386 220 383Q220 381 227 388Q288 442 357 442Q411 442 444 415T478 336Q478 285 440 178T402 50Q403 36 407 31T422 26Q450 26 474 56T513 138Q516 149 519 151T535 153Q555 153 555 145Q555 144 551 130Q535 71 500 33Q466 -10 419 -10H414Q367 -10 346 17T325 74Q325 90 361 192T398 345Q398 404 354 404H349Q266 404 205 306L198 293L164 158Q132 28 127 16Q114 -11 83 -11Q69 -11 59 -2T48 16Q48 30 121 320L195 616Q195 629 188 632T149 637H128Q122 643 122 645T124 664Q129 683 137 683Z"></path></g><g data-mml-node="mi" transform="translate(609,-150) scale(0.707)"><path data-c="1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path></g></g></g></g></svg></mjx-container></p>
<p><strong>代表模型</strong>：Attentive Reader, BiDAF</p>
<h3 id="阶段二：深度交互-2017-2018"><a href="#阶段二：深度交互-2017-2018" class="headerlink" title="阶段二：深度交互 (2017-2018)"></a>阶段二：深度交互 (2017-2018)</h3><p><strong>问题</strong>：如何建模问题和上下文的复杂交互？</p>
<p><strong>技术</strong>：多轮注意力、自注意力、门控机制</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 多轮推理 (R-Net 风格)</span></span><br><span class="line"><span class="keyword">for</span> layer <span class="keyword">in</span> <span class="built_in">range</span>(num_layers):</span><br><span class="line">    <span class="comment"># 自注意力</span></span><br><span class="line">    context = self_attention(context, context)</span><br><span class="line">    <span class="comment"># 交叉注意力</span></span><br><span class="line">    context = cross_attention(context, question)</span><br></pre></td></tr></table></figure>

<h3 id="阶段三：预训练语言模型-2018-2020"><a href="#阶段三：预训练语言模型-2018-2020" class="headerlink" title="阶段三：预训练语言模型 (2018-2020)"></a>阶段三：预训练语言模型 (2018-2020)</h3><p><strong>范式转变</strong>：从 task-specific 到 pretrain-finetune</p>
<p>$$<br>\theta^* = \arg\min_\theta \mathcal{L}<em>{task}(\text{PLM}</em>\theta(x), y)<br>$$</p>
<p><strong>代表模型</strong>：BERT, RoBERTa, ALBERT</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> transformers <span class="keyword">import</span> AutoModelForQuestionAnswering</span><br><span class="line"></span><br><span class="line">model = AutoModelForQuestionAnswering.from_pretrained(<span class="string">"bert-base-uncased"</span>)</span><br><span class="line"><span class="comment"># Fine-tune on SQuAD</span></span><br></pre></td></tr></table></figure>

<h3 id="阶段四：大语言模型-2020-至今"><a href="#阶段四：大语言模型-2020-至今" class="headerlink" title="阶段四：大语言模型 (2020-至今)"></a>阶段四：大语言模型 (2020-至今)</h3><p><strong>范式转变</strong>：从 fine-tuning 到 prompting</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Few-shot prompting</span></span><br><span class="line">prompt = <span class="string">"""</span></span><br><span class="line"><span class="string">Context: The Eiffel Tower was built in 1889.</span></span><br><span class="line"><span class="string">Question: When was the Eiffel Tower built?</span></span><br><span class="line"><span class="string">Answer: 1889</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">Context: {context}</span></span><br><span class="line"><span class="string">Question: {question}</span></span><br><span class="line"><span class="string">Answer:"""</span></span><br></pre></td></tr></table></figure>

<h2 id="架构对比"><a href="#架构对比" class="headerlink" title="架构对比"></a>架构对比</h2><table>
<thead>
<tr>
<th>模型</th>
<th>参数量</th>
<th>训练范式</th>
<th>SQuAD 2.0 F1</th>
</tr>
</thead>
<tbody><tr>
<td>BiDAF</td>
<td>~2M</td>
<td>从零训练</td>
<td>77.3</td>
</tr>
<tr>
<td>BERT-base</td>
<td>110M</td>
<td>预训练+微调</td>
<td>88.5</td>
</tr>
<tr>
<td>BERT-large</td>
<td>340M</td>
<td>预训练+微调</td>
<td>90.9</td>
</tr>
<tr>
<td>RoBERTa-large</td>
<td>355M</td>
<td>预训练+微调</td>
<td>91.4</td>
</tr>
<tr>
<td>GPT-3</td>
<td>175B</td>
<td>Few-shot</td>
<td>~88</td>
</tr>
<tr>
<td>GPT-4</td>
<td>~1.8T</td>
<td>Zero-shot</td>
<td>~95</td>
</tr>
</tbody></table>
<h2 id="现代-MRC-系统设计"><a href="#现代-MRC-系统设计" class="headerlink" title="现代 MRC 系统设计"></a>现代 MRC 系统设计</h2><h3 id="RAG-架构"><a href="#RAG-架构" class="headerlink" title="RAG 架构"></a>RAG 架构</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">ModernMRC</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, retriever, reader</span>):</span><br><span class="line">        <span class="variable language_">self</span>.retriever = retriever  <span class="comment"># Dense retriever</span></span><br><span class="line">        <span class="variable language_">self</span>.reader = reader        <span class="comment"># LLM</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">answer</span>(<span class="params">self, question: <span class="built_in">str</span>, knowledge_base: <span class="built_in">str</span> = <span class="literal">None</span></span>):</span><br><span class="line">        <span class="comment"># 1. 检索</span></span><br><span class="line">        <span class="keyword">if</span> knowledge_base:</span><br><span class="line">            docs = <span class="variable language_">self</span>.retriever.retrieve(question, knowledge_base)</span><br><span class="line">            context = <span class="string">"\n\n"</span>.join([d.text <span class="keyword">for</span> d <span class="keyword">in</span> docs])</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            context = <span class="string">""</span></span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 2. 阅读理解/生成</span></span><br><span class="line">        prompt = <span class="variable language_">self</span>._build_prompt(question, context)</span><br><span class="line">        answer = <span class="variable language_">self</span>.reader.generate(prompt)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 3. 后处理（可选：验证、引用）</span></span><br><span class="line">        <span class="keyword">return</span> <span class="variable language_">self</span>._postprocess(answer, docs)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">_build_prompt</span>(<span class="params">self, question, context</span>):</span><br><span class="line">        <span class="keyword">if</span> context:</span><br><span class="line">            <span class="keyword">return</span> <span class="string">f"""Based on the following context, answer the question.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">Context:</span></span><br><span class="line"><span class="string"><span class="subst">{context}</span></span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">Question: <span class="subst">{question}</span></span></span><br><span class="line"><span class="string">Answer:"""</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">return</span> <span class="string">f"Question: <span class="subst">{question}</span>\nAnswer:"</span></span><br></pre></td></tr></table></figure>

<h3 id="多跳推理"><a href="#多跳推理" class="headerlink" title="多跳推理"></a>多跳推理</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">MultiHopReasoner</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, retriever, llm, max_hops=<span class="number">3</span></span>):</span><br><span class="line">        <span class="variable language_">self</span>.retriever = retriever</span><br><span class="line">        <span class="variable language_">self</span>.llm = llm</span><br><span class="line">        <span class="variable language_">self</span>.max_hops = max_hops</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">reason</span>(<span class="params">self, question</span>):</span><br><span class="line">        reasoning_chain = []</span><br><span class="line">        current_query = question</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">for</span> hop <span class="keyword">in</span> <span class="built_in">range</span>(<span class="variable language_">self</span>.max_hops):</span><br><span class="line">            <span class="comment"># 检索</span></span><br><span class="line">            docs = <span class="variable language_">self</span>.retriever.retrieve(current_query)</span><br><span class="line">            </span><br><span class="line">            <span class="comment"># 生成中间推理</span></span><br><span class="line">            intermediate = <span class="variable language_">self</span>.llm.generate(</span><br><span class="line">                <span class="string">f"Based on: <span class="subst">{docs}</span>\nQuestion: <span class="subst">{current_query}</span>\n"</span></span><br><span class="line">                <span class="string">f"Provide intermediate reasoning or the final answer:"</span></span><br><span class="line">            )</span><br><span class="line">            </span><br><span class="line">            reasoning_chain.append({</span><br><span class="line">                <span class="string">'query'</span>: current_query,</span><br><span class="line">                <span class="string">'docs'</span>: docs,</span><br><span class="line">                <span class="string">'reasoning'</span>: intermediate</span><br><span class="line">            })</span><br><span class="line">            </span><br><span class="line">            <span class="comment"># 检查是否已得到答案</span></span><br><span class="line">            <span class="keyword">if</span> <span class="variable language_">self</span>._is_final_answer(intermediate):</span><br><span class="line">                <span class="keyword">break</span></span><br><span class="line">            </span><br><span class="line">            <span class="comment"># 生成下一跳查询</span></span><br><span class="line">            current_query = <span class="variable language_">self</span>._generate_next_query(question, reasoning_chain)</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">return</span> <span class="variable language_">self</span>._synthesize_answer(question, reasoning_chain)</span><br></pre></td></tr></table></figure>

<h2 id="对话系统中的-MRC"><a href="#对话系统中的-MRC" class="headerlink" title="对话系统中的 MRC"></a>对话系统中的 MRC</h2><h3 id="对话式问答"><a href="#对话式问答" class="headerlink" title="对话式问答"></a>对话式问答</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">ConversationalQA</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, mrc_model, history_length=<span class="number">5</span></span>):</span><br><span class="line">        <span class="variable language_">self</span>.mrc_model = mrc_model</span><br><span class="line">        <span class="variable language_">self</span>.history = []</span><br><span class="line">        <span class="variable language_">self</span>.history_length = history_length</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">ask</span>(<span class="params">self, question, context=<span class="literal">None</span></span>):</span><br><span class="line">        <span class="comment"># 将对话历史纳入问题</span></span><br><span class="line">        contextualized_question = <span class="variable language_">self</span>._contextualize(question)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 获取答案</span></span><br><span class="line">        answer = <span class="variable language_">self</span>.mrc_model.answer(contextualized_question, context)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 更新历史</span></span><br><span class="line">        <span class="variable language_">self</span>.history.append({<span class="string">'q'</span>: question, <span class="string">'a'</span>: answer})</span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">len</span>(<span class="variable language_">self</span>.history) &gt; <span class="variable language_">self</span>.history_length:</span><br><span class="line">            <span class="variable language_">self</span>.history.pop(<span class="number">0</span>)</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">return</span> answer</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">_contextualize</span>(<span class="params">self, question</span>):</span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> <span class="variable language_">self</span>.history:</span><br><span class="line">            <span class="keyword">return</span> question</span><br><span class="line">        </span><br><span class="line">        history_text = <span class="string">"\n"</span>.join([</span><br><span class="line">            <span class="string">f"Q: <span class="subst">{turn[<span class="string">'q'</span>]}</span>\nA: <span class="subst">{turn[<span class="string">'a'</span>]}</span>"</span></span><br><span class="line">            <span class="keyword">for</span> turn <span class="keyword">in</span> <span class="variable language_">self</span>.history</span><br><span class="line">        ])</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">return</span> <span class="string">f"Conversation history:\n<span class="subst">{history_text}</span>\n\nCurrent question: <span class="subst">{question}</span>"</span></span><br></pre></td></tr></table></figure>

<h2 id="评估体系"><a href="#评估体系" class="headerlink" title="评估体系"></a>评估体系</h2><h3 id="传统指标"><a href="#传统指标" class="headerlink" title="传统指标"></a>传统指标</h3><table>
<thead>
<tr>
<th>指标</th>
<th>定义</th>
<th>适用场景</th>
</tr>
</thead>
<tbody><tr>
<td>EM</td>
<td>精确匹配</td>
<td>抽取式 QA</td>
</tr>
<tr>
<td>F1</td>
<td>Token 重叠</td>
<td>抽取式 QA</td>
</tr>
<tr>
<td>BLEU</td>
<td>N-gram 重叠</td>
<td>生成式 QA</td>
</tr>
<tr>
<td>ROUGE</td>
<td>召回导向重叠</td>
<td>摘要、长答案</td>
</tr>
</tbody></table>
<h3 id="LLM-时代指标"><a href="#LLM-时代指标" class="headerlink" title="LLM 时代指标"></a>LLM 时代指标</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># LLM-as-Judge</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">llm_evaluate</span>(<span class="params">question, reference, prediction</span>):</span><br><span class="line">    prompt = <span class="string">f"""Evaluate the answer quality on a scale of 1-5:</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">Question: <span class="subst">{question}</span></span></span><br><span class="line"><span class="string">Reference Answer: <span class="subst">{reference}</span></span></span><br><span class="line"><span class="string">Model Answer: <span class="subst">{prediction}</span></span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">Criteria:</span></span><br><span class="line"><span class="string">- Correctness: Is the information accurate?</span></span><br><span class="line"><span class="string">- Completeness: Does it fully answer the question?</span></span><br><span class="line"><span class="string">- Conciseness: Is it appropriately brief?</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">Score (1-5):"""</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> llm.generate(prompt)</span><br></pre></td></tr></table></figure>

<h2 id="延伸阅读"><a href="#延伸阅读" class="headerlink" title="延伸阅读"></a>延伸阅读</h2><ul>
<li><a target="_blank" rel="noopener" href="https://arxiv.org/abs/1704.00051">Reading Wikipedia to Answer Open-Domain Questions</a></li>
<li><a target="_blank" rel="noopener" href="https://arxiv.org/abs/2005.11401">RAG Paper</a></li>
<li><a target="_blank" rel="noopener" href="https://arxiv.org/abs/1809.09600">HotpotQA: Multi-hop Reasoning</a></li>
<li><a target="_blank" rel="noopener" href="https://arxiv.org/abs/2005.11401">Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks</a></li>
</ul>
<hr>
<blockquote>
<p>转载请注明出处</p>
</blockquote>

    </div>

    
    
    

    <footer class="post-footer">
          <div class="post-tags">
              <a href="/tags/LLM/" rel="tag"><i class="fa fa-tag"></i> LLM</a>
              <a href="/tags/MRC/" rel="tag"><i class="fa fa-tag"></i> MRC</a>
              <a href="/tags/KBQA/" rel="tag"><i class="fa fa-tag"></i> KBQA</a>
              <a href="/tags/Deep-learning/" rel="tag"><i class="fa fa-tag"></i> Deep learning</a>
          </div>

        

          <div class="post-nav">
            <div class="post-nav-item">
                <a href="/2019/11/19/%E5%A6%82%E4%BD%95%E6%95%99%E4%BC%9A%E6%9C%BA%E5%99%A8%E7%90%86%E8%A7%A3%E9%97%AE%E9%A2%98%EF%BC%9A%E4%BB%8E%E9%9B%B6%E5%BC%80%E5%A7%8B%E7%9A%84%E6%9C%BA%E5%99%A8%E9%98%85%E8%AF%BB%E7%90%86%E8%A7%A3%E5%AE%9E%E8%B7%B5/" rel="prev" title="机器阅读理解实战：从零构建问答系统">
                  <i class="fa fa-angle-left"></i> 机器阅读理解实战：从零构建问答系统
                </a>
            </div>
            <div class="post-nav-item">
                <a href="/2025/12/28/DDIA-%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0-%E6%80%BB%E8%A7%88/" rel="next" title="DDIA 读书笔记：数据密集型应用系统设计">
                  DDIA 读书笔记：数据密集型应用系统设计 <i class="fa fa-angle-right"></i>
                </a>
            </div>
          </div>
    </footer>
  </article>
</div>






</div>
  </main>

  <footer class="footer">
    <div class="footer-inner">

  <div class="copyright">
    &copy; 2019 – 
    <span itemprop="copyrightYear">2025</span>
    <span class="with-love">
      <i class="fa fa-heart"></i>
    </span>
    <span class="author" itemprop="copyrightHolder">fooSynaptic's Blog</span>
  </div>

    </div>
  </footer>

  
  <div class="toggle sidebar-toggle" role="button">
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
  </div>
  <div class="sidebar-dimmer"></div>
  <div class="back-to-top" role="button" aria-label="返回顶部">
    <i class="fa fa-arrow-up fa-lg"></i>
    <span>0%</span>
  </div>

<noscript>
  <div class="noscript-warning">Theme NexT works best with JavaScript enabled</div>
</noscript>

</body>
</html>
