[{"title":"DDIA è¯»ä¹¦ç¬”è®°ï¼šæ•°æ®å¯†é›†å‹åº”ç”¨ç³»ç»Ÿè®¾è®¡","url":"/2025/12/28/DDIA-%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0-%E6%80%BB%E8%A7%88/","content":"\nDesigning Data-Intensive Applications: The Big Ideas Behind Reliable, Scalable, and Maintainable Systems\n\nè¿™æ˜¯ä¸€ä»½å…³äºã€Šæ•°æ®å¯†é›†å‹åº”ç”¨ç³»ç»Ÿè®¾è®¡ã€‹(DDIA) çš„å®Œæ•´è¯»ä¹¦ç¬”è®°ï¼Œæœ¬ä¹¦è¢«èª‰ä¸ºâ€æ•°æ®ç³»ç»Ÿé¢†åŸŸçš„åœ£ç»â€ã€‚\nä¹¦ç±ä¿¡æ¯\n\n\né¡¹ç›®\nå†…å®¹\n\n\n\nä¹¦å\nDesigning Data-Intensive Applications (DDIA)\n\n\nä¸­æ–‡å\næ•°æ®å¯†é›†å‹åº”ç”¨ç³»ç»Ÿè®¾è®¡\n\n\nä½œè€…\nMartin Kleppmannï¼ˆå‰‘æ¡¥å¤§å­¦åˆ†å¸ƒå¼ç³»ç»Ÿç ”ç©¶å‘˜ï¼‰\n\n\nå‡ºç‰ˆæ—¶é—´\n2017å¹´3æœˆ\n\n\næ ¸å¿ƒä¸»é¢˜æœ¬ä¹¦å›´ç»•ä¸‰ä¸ªæ ¸å¿ƒæ¦‚å¿µå±•å¼€ï¼š\n\nå¯é æ€§ (Reliability)ï¼šç³»ç»Ÿåœ¨é‡åˆ°æ•…éšœæ—¶ä»èƒ½æ­£ç¡®å·¥ä½œ\nå¯æ‰©å±•æ€§ (Scalability)ï¼šç³»ç»Ÿèƒ½å¤Ÿåº”å¯¹è´Ÿè½½å¢é•¿\nå¯ç»´æŠ¤æ€§ (Maintainability)ï¼šç³»ç»Ÿæ˜“äºç†è§£ã€ä¿®æ”¹å’Œæ‰©å±•\n\nå…¨ä¹¦ç»“æ„ç¬¬ä¸€éƒ¨åˆ†ï¼šæ•°æ®ç³»ç»ŸåŸºç¡€\næŸ¥çœ‹è¯¦ç»†ç¬”è®°\n\n\n\n\nç« èŠ‚\næ ¸å¿ƒå†…å®¹\n\n\n\nç¬¬1ç« \nå¯é æ€§ã€å¯æ‰©å±•æ€§ã€å¯ç»´æŠ¤æ€§çš„å®šä¹‰ä¸å®è·µ\n\n\nç¬¬2ç« \nå…³ç³»æ¨¡å‹ã€æ–‡æ¡£æ¨¡å‹ã€å›¾æ¨¡å‹çš„å¯¹æ¯”ä¸é€‰æ‹©\n\n\nç¬¬3ç« \nå­˜å‚¨å¼•æ“åŸç†ï¼šB-Treeã€LSM-Treeã€OLTP vs OLAP\n\n\nç¬¬4ç« \næ•°æ®ç¼–ç æ ¼å¼ä¸æ¨¡å¼æ¼”åŒ–ï¼šJSONã€Protobufã€Avro\n\n\nç¬¬äºŒéƒ¨åˆ†ï¼šåˆ†å¸ƒå¼æ•°æ®\næŸ¥çœ‹è¯¦ç»†ç¬”è®°\n\n\n\n\nç« èŠ‚\næ ¸å¿ƒå†…å®¹\n\n\n\nç¬¬5ç« \næ•°æ®å¤åˆ¶ï¼šä¸»ä»ã€å¤šä¸»ã€æ— ä¸»å¤åˆ¶ç­–ç•¥\n\n\nç¬¬6ç« \næ•°æ®åˆ†åŒºï¼šåˆ†åŒºç­–ç•¥ã€å†å¹³è¡¡ã€è¯·æ±‚è·¯ç”±\n\n\nç¬¬7ç« \näº‹åŠ¡ï¼šACIDã€éš”ç¦»çº§åˆ«ã€åˆ†å¸ƒå¼äº‹åŠ¡\n\n\nç¬¬8ç« \nåˆ†å¸ƒå¼ç³»ç»ŸæŒ‘æˆ˜ï¼šç½‘ç»œã€æ—¶é’Ÿã€æ•…éšœæ¨¡å‹\n\n\nç¬¬9ç« \nä¸€è‡´æ€§ä¸å…±è¯†ï¼šCAPã€Paxosã€Raft\n\n\nç¬¬ä¸‰éƒ¨åˆ†ï¼šè¡ç”Ÿæ•°æ®\næŸ¥çœ‹è¯¦ç»†ç¬”è®°\n\n\n\n\nç« èŠ‚\næ ¸å¿ƒå†…å®¹\n\n\n\nç¬¬10ç« \næ‰¹å¤„ç†ï¼šMapReduceã€Sparkã€æ•°æ®æµå¼•æ“\n\n\nç¬¬11ç« \næµå¤„ç†ï¼šKafkaã€Flinkã€äº‹ä»¶æ—¶é—´ä¸æ°´ä½çº¿\n\n\nç¬¬12ç« \næ•°æ®ç³»ç»Ÿæœªæ¥ï¼šæ•°æ®é›†æˆã€ç«¯åˆ°ç«¯æ­£ç¡®æ€§ã€ä¼¦ç†\n\n\nå­¦ä¹ è·¯çº¿å…¥é—¨è·¯çº¿ï¼ˆé€‚åˆåˆå­¦è€…ï¼‰ç¬¬1ç«  â†’ ç¬¬2ç«  â†’ ç¬¬3ç«  â†’ ç¬¬4ç« ï¼ˆå»ºç«‹åŸºç¡€ï¼‰    â†“ç¬¬5ç«  â†’ ç¬¬6ç« ï¼ˆç†è§£åˆ†å¸ƒå¼åŸºç¡€ï¼‰    â†“ç¬¬10ç«  â†’ ç¬¬11ç« ï¼ˆäº†è§£æ•°æ®å¤„ç†ï¼‰\n\nè¿›é˜¶è·¯çº¿ï¼ˆé€‚åˆæœ‰ç»éªŒçš„å¼€å‘è€…ï¼‰ç¬¬7ç«  â†’ ç¬¬8ç«  â†’ ç¬¬9ç« ï¼ˆæ·±å…¥åˆ†å¸ƒå¼ï¼‰    â†“ç¬¬12ç« ï¼ˆå±•æœ›æœªæ¥ï¼‰    â†“å›é¡¾ç¬¬1-4ç« å¡«è¡¥çŸ¥è¯†ç©ºç™½\n\nä¸“é¢˜è·¯çº¿\n\n\næ–¹å‘\næ¨èé˜…è¯»é¡ºåº\n\n\n\næ•°æ®åº“\n2 â†’ 3 â†’ 5 â†’ 6 â†’ 7\n\n\nåˆ†å¸ƒå¼ç³»ç»Ÿ\n5 â†’ 6 â†’ 8 â†’ 9\n\n\næ•°æ®å·¥ç¨‹\n3 â†’ 10 â†’ 11 â†’ 12\n\n\næ ¸å¿ƒè¦ç‚¹é€Ÿè§ˆæ•°æ®æ¨¡å‹é€‰æ‹©å…³ç³»æ¨¡å‹ â”€â”€â”€â”€ ç»“æ„åŒ–æ•°æ®ã€å¤æ‚æŸ¥è¯¢ã€äº‹åŠ¡æ”¯æŒ     â†“æ–‡æ¡£æ¨¡å‹ â”€â”€â”€â”€ çµæ´»æ¨¡å¼ã€æ ‘çŠ¶ç»“æ„ã€å±€éƒ¨æ€§å¥½     â†“å›¾æ¨¡å‹ â”€â”€â”€â”€â”€ å¤æ‚å…³ç³»ã€ç¤¾äº¤ç½‘ç»œã€çŸ¥è¯†å›¾è°±\n\nå­˜å‚¨å¼•æ“å¯¹æ¯”\n\n\nå¼•æ“\nä¼˜åŒ–ç›®æ ‡\nå…¸å‹åº”ç”¨\n\n\n\nB-Tree\nè¯»å–ä¼˜åŒ–\nOLTP æ•°æ®åº“\n\n\nLSM-Tree\nå†™å…¥ä¼˜åŒ–\næ—¥å¿—ã€æ—¶åºæ•°æ®\n\n\nåˆ—å­˜å‚¨\nåˆ†æä¼˜åŒ–\nOLAPã€æ•°æ®ä»“åº“\n\n\nåˆ†å¸ƒå¼ç³»ç»Ÿæ ¸å¿ƒæƒè¡¡å®šç†ï¼šç½‘ç»œåˆ†åŒºæ—¶ï¼Œä¸€è‡´æ€§ä¸å¯ç”¨æ€§ä¸å¯å…¼å¾—\nå¤„ç†èŒƒå¼å¯¹æ¯”\n\n\nèŒƒå¼\næ•°æ®ç‰¹æ€§\nå»¶è¿Ÿ\nå…¸å‹æ¡†æ¶\n\n\n\næ‰¹å¤„ç†\næœ‰ç•Œã€é™æ€\nåˆ†é’Ÿ~å°æ—¶\nSpark, Hadoop\n\n\næµå¤„ç†\næ— ç•Œã€æŒç»­\næ¯«ç§’~ç§’\nFlink, Kafka Streams\n\n\nå»¶ä¼¸èµ„æº\nå®˜æ–¹ç½‘ç«™ï¼šdataintensive.net\nä¸­æ–‡ç¿»è¯‘ï¼šddia.vonng.com\nä½œè€…åšå®¢ï¼šmartin.kleppmann.com\n\n\næœ¬è¯»ä¹¦ç¬”è®°æ•´ç†äº 2025å¹´ï¼ŒåŸºäº DDIA ç¬¬ä¸€ç‰ˆå†…å®¹ç¼–å†™\n","categories":["è¯»ä¹¦ç¬”è®°"],"tags":["DDIA","åˆ†å¸ƒå¼ç³»ç»Ÿ","æ•°æ®åº“","ç³»ç»Ÿè®¾è®¡"]},{"title":"DDIA Part 3ï¼šè¡ç”Ÿæ•°æ®","url":"/2025/12/28/DDIA-Part3-%E8%A1%8D%E7%94%9F%E6%95%B0%E6%8D%AE/","content":"æœ¬æ–‡æ˜¯ DDIA ç¬¬ä¸‰éƒ¨åˆ†çš„è¯»ä¹¦ç¬”è®°ï¼Œæ¶µç›–ç¬¬ 10-12 ç« ï¼šæ‰¹å¤„ç†ã€æµå¤„ç†ã€æ•°æ®ç³»ç»Ÿçš„æœªæ¥ã€‚\n\nç¬¬10ç« ï¼šæ‰¹å¤„ç†ä¸‰ç§ç³»ç»Ÿç±»å‹\n\n\nç±»å‹\nç‰¹ç‚¹\nå»¶è¿Ÿ\nç¤ºä¾‹\n\n\n\nåœ¨çº¿æœåŠ¡\nè¯·æ±‚-å“åº”\næ¯«ç§’\nWeb API\n\n\næ‰¹å¤„ç†\nå¤§é‡æ•°æ®ï¼Œé«˜åå\nåˆ†é’Ÿ~å°æ—¶\nMapReduce\n\n\næµå¤„ç†\næŒç»­å¤„ç†æ•°æ®æµ\næ¯«ç§’~ç§’\nKafka Streams\n\n\nUnix å“²å­¦\næ¯ä¸ªç¨‹åºåšå¥½ä¸€ä»¶äº‹ï¼Œè¾“å‡ºå¯æˆä¸ºå¦ä¸€ç¨‹åºçš„è¾“å…¥\n\ncat access.log |   awk '{print $7}' |    # æå– URL  sort | uniq -c |      # è®¡æ•°  sort -rn | head -10   # å–å‰10\n\nMapReduceè¾“å…¥ â†’ Map â†’ Shuffle(æŒ‰é”®åˆ†ç»„) â†’ Reduce â†’ è¾“å‡ºç¤ºä¾‹ï¼ˆè¯é¢‘ç»Ÿè®¡ï¼‰:è¾“å…¥: \"hello world hello\"Map:  (hello,1) (world,1) (hello,1)Shuffle: hello:[1,1], world:[1]Reduce: (hello,2) (world,1)\n\nåˆ†å¸ƒå¼æ‰§è¡Œï¼šæ•°æ®æœ¬åœ°æ€§åŸåˆ™ï¼Œå°½é‡åœ¨æ•°æ®æ‰€åœ¨èŠ‚ç‚¹æ‰§è¡Œ Map\nJoin ç±»å‹\n\n\nç±»å‹\nè¯´æ˜\né€‚ç”¨åœºæ™¯\n\n\n\nReduce ç«¯ Join\nShuffle åæŒ‰é”®åˆå¹¶\né€šç”¨\n\n\nå¹¿æ’­ Join\nå°è¡¨å¹¿æ’­åˆ°æ‰€æœ‰ Map\nå¤§è¡¨ Join å°è¡¨\n\n\nåˆ†åŒº Join\nä¸¤è¡¨ç›¸åŒåˆ†åŒºç­–ç•¥\né¢„åˆ†åŒºæ•°æ®\n\n\nç°ä»£æ‰¹å¤„ç†æ¡†æ¶\n\n\næ¡†æ¶\nç‰¹ç‚¹\n\n\n\nSpark\nRDD æŠ½è±¡ï¼Œå†…å­˜ç¼“å­˜ï¼Œè¿­ä»£å‹å¥½\n\n\nFlink\næµæ‰¹ä¸€ä½“ï¼Œå¢é‡å¤„ç†\n\n\nvs MapReduceï¼š\n\n\n\næ–¹é¢\nMapReduce\næ•°æ®æµå¼•æ“\n\n\n\nç¼–ç¨‹æ¨¡å‹\nMap/Reduce\nä»»æ„ DAG\n\n\nä¸­é—´æ•°æ®\nå†™å…¥ HDFS\nå†…å­˜æµè½¬\n\n\nè¿­ä»£æ”¯æŒ\næ•ˆç‡ä½\né«˜æ•ˆ\n\n\n\nç¬¬11ç« ï¼šæµå¤„ç†æ‰¹å¤„ç† vs æµå¤„ç†\n\n\næ–¹é¢\næ‰¹å¤„ç†\næµå¤„ç†\n\n\n\næ•°æ®\næœ‰ç•Œï¼Œé™æ€\næ— ç•Œï¼ŒæŒç»­åˆ°è¾¾\n\n\nå»¶è¿Ÿ\nåˆ†é’Ÿ~å°æ—¶\næ¯«ç§’~ç§’\n\n\nç»“æœ\nä¸€æ¬¡æ€§è¾“å‡º\næŒç»­æ›´æ–°\n\n\næ¶ˆæ¯ç³»ç»Ÿä¼ ç»Ÿæ¶ˆæ¯é˜Ÿåˆ— (RabbitMQ)ï¼š\n\næ¶ˆæ¯å¤„ç†ååˆ é™¤\næ¯æ¡æ¶ˆæ¯åªè¢«ä¸€ä¸ªæ¶ˆè´¹è€…å¤„ç†\n\næ—¥å¿—å‹æ¶ˆæ¯ç³»ç»Ÿ (Kafka)ï¼š\n\næ¶ˆæ¯æŒä¹…åŒ–ï¼Œå¯é‡æ”¾\nåˆ†åŒºä¿åº\nå¤šæ¶ˆè´¹è€…ç»„ç‹¬ç«‹æ¶ˆè´¹\n\nåˆ†åŒº0: [msg0][msg3][msg6] â†’ æ¶ˆè´¹è€…Aåˆ†åŒº1: [msg1][msg4][msg7] â†’ æ¶ˆè´¹è€…Båˆ†åŒº2: [msg2][msg5][msg8] â†’ æ¶ˆè´¹è€…C\n\nå˜æ›´æ•°æ®æ•è· (CDC)åº”ç”¨ â†’ æ•°æ®åº“ â†’ CDCå·¥å…·(Debezium) â†’ Kafka â†’ æ´¾ç”Ÿç³»ç»Ÿ\n\nåº”ç”¨ï¼šåŒæ­¥æœç´¢ç´¢å¼•ã€å¾®æœåŠ¡é›†æˆã€å®æ—¶ ETL\näº‹ä»¶æº¯æºä¼ ç»Ÿæ–¹å¼ï¼šåªå­˜å½“å‰çŠ¶æ€â”Œ balance = 1000 â”äº‹ä»¶æº¯æºï¼šå­˜å‚¨æ‰€æœ‰äº‹ä»¶â”‚ 1. åˆ›å»ºè´¦æˆ· balance=0    â”‚â”‚ 2. å­˜æ¬¾ +500             â”‚â”‚ 3. å­˜æ¬¾ +800             â”‚â”‚ 4. å–æ¬¾ -300             â”‚â”” å½“å‰: 0+500+800-300=1000 â”˜\n\nä¼˜åŠ¿ï¼šå®Œæ•´å®¡è®¡ã€å¯é‡æ”¾ã€è°ƒè¯•å‹å¥½\næ—¶é—´è¯­ä¹‰\n\n\nç±»å‹\nå®šä¹‰\n\n\n\näº‹ä»¶æ—¶é—´\näº‹ä»¶å®é™…å‘ç”Ÿçš„æ—¶é—´\n\n\nå¤„ç†æ—¶é—´\näº‹ä»¶åˆ°è¾¾å¤„ç†å™¨çš„æ—¶é—´\n\n\nçª—å£ç±»å‹æ»šåŠ¨çª—å£ï¼šâ”Œâ”€â”€â”â”Œâ”€â”€â”â”Œâ”€â”€â” (å›ºå®šå¤§å°ï¼Œä¸é‡å )æ»‘åŠ¨çª—å£ï¼šâ”Œâ”€â”€â”€â”€â”            â”Œâ”€â”€â”€â”€â”              â”Œâ”€â”€â”€â”€â”  (å›ºå®šå¤§å°ï¼Œå¯é‡å )ä¼šè¯çª—å£ï¼šâ”Œâ”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”  â”Œâ”€â” (åŸºäºæ´»åŠ¨é—´éš™)\n\næ°´ä½çº¿ (Watermark)\nä¸ä¼šå†æœ‰ â‰¤ è¯¥æ—¶é—´çš„äº‹ä»¶åˆ°è¾¾\n\nè¿Ÿåˆ°äº‹ä»¶å¤„ç†ï¼šä¸¢å¼ƒã€æ›´æ–°ç»“æœã€ä¾§è¾“å‡º\næµå¤„ç†æ¡†æ¶\n\n\næ¡†æ¶\nç‰¹ç‚¹\n\n\n\nKafka Streams\nè½»é‡çº§åº“ï¼Œä¸ Kafka ç´§å¯†é›†æˆ\n\n\nFlink\nçœŸæ­£çš„æµå¤„ç†ï¼Œå¼ºä¸€è‡´æ€§\n\n\nSpark Streaming\nå¾®æ‰¹å¤„ç†\n\n\næµè¡¨å¯¹å¶æµ â†’ è¡¨ï¼šèšåˆ/ç´¯ç§¯ï¼ˆç‰©åŒ–è§†å›¾ï¼‰è¡¨ â†’ æµï¼šæ•è·å˜æ›´ï¼ˆå˜æ›´æ—¥å¿—ï¼‰\n\n-- KSQL: æµè½¬è¡¨CREATE TABLE page_counts AS  SELECT page_id, COUNT(*) as views  FROM pageviews  GROUP BY page_id;\n\n\nç¬¬12ç« ï¼šæ•°æ®ç³»ç»Ÿçš„æœªæ¥æ•°æ®é›†æˆç°çŠ¶ï¼šå¤šç§ä¸“ç”¨å·¥å…·ï¼ˆPostgreSQL + Redis + ES + Kafkaï¼‰\nä»¥æ—¥å¿—ä¸ºä¸­å¿ƒçš„æ¶æ„ï¼š\nå†™å…¥ â†’ äº‹ä»¶æ—¥å¿—(Kafka) â†’ æ•°æ®åº“              â†“        â†’ æœç´¢ç´¢å¼•                       â†’ ç¼“å­˜\n\nLambda vs Kappaï¼š\n\n\n\næ¶æ„\nç‰¹ç‚¹\n\n\n\nLambda\næ‰¹å¤„ç†+æµå¤„ç†åŒè·¯å¾„ï¼Œéœ€ç»´æŠ¤ä¸¤å¥—ä»£ç \n\n\nKappa\nåªç”¨æµå¤„ç†ï¼Œæ—¥å¿—ä¿ç•™è¶³å¤Ÿé•¿æ”¯æŒé‡æ”¾\n\n\nåˆ†æ‹†æ•°æ®åº“ä¼ ç»Ÿæ•°æ®åº“ = å­˜å‚¨ + äº‹åŠ¡ + ç´¢å¼• + å¤åˆ¶ + æŸ¥è¯¢ä¼˜åŒ–åˆ†æ‹†åï¼šKafka(æ—¥å¿—) â†’ Flink(å¤„ç†) â†’ RocksDB(å­˜å‚¨)æ¯ä¸ªç»„ä»¶ä¸“æ³¨ä¸€ä»¶äº‹\n\nä¸»æ•°æ® vs è¡ç”Ÿæ•°æ®ï¼š\n\n\n\nç±»å‹\nè¯´æ˜\n\n\n\nä¸»æ•°æ®\nçœŸç›¸æ¥æºï¼Œå†™å…¥æ—¶çš„è¾“å…¥\n\n\nè¡ç”Ÿæ•°æ®\nä»ä¸»æ•°æ®è®¡ç®—ï¼Œå¯é‡å»ºï¼ˆç´¢å¼•ã€ç¼“å­˜ï¼‰\n\n\nç«¯åˆ°ç«¯æ­£ç¡®æ€§å¹‚ç­‰æ€§ï¼šæ‰§è¡Œå¤šæ¬¡ä¸æ‰§è¡Œä¸€æ¬¡æ•ˆæœç›¸åŒ\nå¹‚ç­‰ï¼šSET x = 5éå¹‚ç­‰ï¼šINCR xï¼ˆéœ€è¦å»é‡ï¼‰\n\nç«¯åˆ°ç«¯è®ºè¯ï¼šåªåœ¨æ¯å±‚ä¿è¯æ­£ç¡®ä¸å¤Ÿï¼Œéœ€åœ¨æœ€ç»ˆç”¨æˆ·å±‚é¢éªŒè¯\nå®¡è®¡ä¸å¯è¿½æº¯ä¸å¯å˜æ—¥å¿—çš„ä¼˜åŠ¿ï¼š\nä¼ ç»Ÿï¼šUPDATE email='new@...'ï¼ˆå†å²ä¸¢å¤±ï¼‰äº‹ä»¶æ—¥å¿—ï¼š  1. æ³¨å†Œ email='old@...'  2. æ›´æ–° email='new@...'ï¼ˆå®Œæ•´å†å²ï¼‰\n\nä¼¦ç†è€ƒé‡\n\n\né—®é¢˜\nè€ƒé‡\n\n\n\néšç§\næ”¶é›†ä»€ä¹ˆæ•°æ®ï¼Ÿç”¨äºä»€ä¹ˆï¼Ÿ\n\n\nåè§\nç®—æ³•æ˜¯å¦å­˜åœ¨æ­§è§†ï¼Ÿ\n\n\né€æ˜åº¦\nç”¨æˆ·èƒ½å¦ç†è§£å†³ç­–è¿‡ç¨‹ï¼Ÿ\n\n\né—®è´£\nå‡ºé”™æ—¶è°è´Ÿè´£ï¼Ÿ\n\n\nè®¾è®¡åŸåˆ™\n\n\nåŸåˆ™\nè¯´æ˜\n\n\n\nç®€å•æ€§\né¿å…ä¸å¿…è¦çš„å¤æ‚æ€§\n\n\nå¯ç»„åˆæ€§\nä½¿ç”¨å¯ç»„åˆçš„ç»„ä»¶\n\n\nå¯è§‚æµ‹æ€§\nä¾¿äºç†è§£ç³»ç»Ÿè¡Œä¸º\n\n\nå¯æ¼”åŒ–æ€§\nèƒ½é€‚åº”å˜åŒ–çš„éœ€æ±‚\n\n\næœªæ¥è¶‹åŠ¿1. æµæ‰¹ä¸€ä½“ï¼šæ‰¹å¤„ç† = æœ‰ç•Œæµ2. å£°æ˜å¼æ•°æ®ç®¡ç†ï¼šæè¿°æƒ³è¦ä»€ä¹ˆ3. è‡ªåŠ¨åŒ–è¿ç»´ï¼šè‡ªåŠ¨è°ƒä¼˜ã€æ‰©ç¼©å®¹4. è¾¹ç¼˜è®¡ç®—ï¼šæ•°æ®å¤„ç†é è¿‘äº§ç”Ÿåœ°\n\n\nå…¨ä¹¦æ€»ç»“æ ¸å¿ƒä¸»é¢˜\n\n\nä¸»é¢˜\nç« èŠ‚\nè¦ç‚¹\n\n\n\næ•°æ®å­˜å‚¨\n2, 3, 4\né€‰æ‹©åˆé€‚çš„æ•°æ®æ¨¡å‹å’Œå­˜å‚¨å¼•æ“\n\n\nåˆ†å¸ƒå¼\n5-9\nç†è§£åˆ†å¸ƒå¼ç³»ç»Ÿçš„æƒè¡¡\n\n\næ•°æ®å¤„ç†\n10, 11\næ‰¹å¤„ç†ä¸æµå¤„ç†çš„ç»Ÿä¸€\n\n\nç³»ç»Ÿè®¾è®¡\n1, 12\nå¯é ã€å¯æ‰©å±•ã€å¯ç»´æŠ¤\n\n\nå…³é”®è¦ç‚¹\næ²¡æœ‰é“¶å¼¹ï¼šä¸åŒå·¥å…·é€‚åˆä¸åŒåœºæ™¯\næ—¥å¿—æ˜¯å…³é”®ï¼šäº‹ä»¶æ—¥å¿—æ˜¯æ•°æ®é›†æˆçš„åŸºç¡€\nè¡ç”Ÿæ•°æ®å¯é‡å»ºï¼šä¸»æ•°æ®æ˜¯çœŸç›¸æ¥æº\nç«¯åˆ°ç«¯æ­£ç¡®æ€§ï¼šåªåœ¨æŸä¸€å±‚ä¿è¯ä¸å¤Ÿ\næŠ€æœ¯é€‰æ‹©æœ‰ç¤¾ä¼šå½±å“ï¼šéœ€è¦è€ƒè™‘ä¼¦ç†é—®é¢˜\nç®€å•æ€§æ˜¯ç¾å¾·ï¼šé¿å…ä¸å¿…è¦çš„å¤æ‚æ€§\n\n\næ¨èé˜…è¯»\n\n\nä¹¦ç±\nä¸»é¢˜\n\n\n\nã€ŠDatabase Internalsã€‹\næ•°æ®åº“å†…éƒ¨åŸç†\n\n\nã€ŠStreaming Systemsã€‹\næµå¤„ç†æ·±å…¥\n\n\nã€ŠBuilding Microservicesã€‹\nå¾®æœåŠ¡æ¶æ„\n\n\nã€ŠClean Architectureã€‹\nè½¯ä»¶æ¶æ„\n\n\n\nä¸Šä¸€éƒ¨åˆ†ï¼šåˆ†å¸ƒå¼æ•°æ® | è¿”å›æ€»è§ˆ\n","categories":["è¯»ä¹¦ç¬”è®°"],"tags":["DDIA","æ‰¹å¤„ç†","æµå¤„ç†","æ•°æ®å·¥ç¨‹"]},{"title":"DDIA Part 2ï¼šåˆ†å¸ƒå¼æ•°æ®","url":"/2025/12/28/DDIA-Part2-%E5%88%86%E5%B8%83%E5%BC%8F%E6%95%B0%E6%8D%AE/","content":"æœ¬æ–‡æ˜¯ DDIA ç¬¬äºŒéƒ¨åˆ†çš„è¯»ä¹¦ç¬”è®°ï¼Œæ¶µç›–ç¬¬ 5-9 ç« ï¼šæ•°æ®å¤åˆ¶ã€åˆ†åŒºã€äº‹åŠ¡ã€åˆ†å¸ƒå¼æŒ‘æˆ˜ã€ä¸€è‡´æ€§ä¸å…±è¯†ã€‚\n\nç¬¬5ç« ï¼šæ•°æ®å¤åˆ¶å¤åˆ¶çš„ç›®çš„\n\n\nç›®çš„\nè¯´æ˜\n\n\n\né«˜å¯ç”¨æ€§\néƒ¨åˆ†èŠ‚ç‚¹æ•…éšœæ—¶ç³»ç»Ÿä»å¯ç”¨\n\n\né™ä½å»¶è¿Ÿ\næ•°æ®æ”¾åœ¨ç¦»ç”¨æˆ·æ›´è¿‘çš„åœ°æ–¹\n\n\næé«˜è¯»åå\nå¤šä¸ªå‰¯æœ¬å¹¶è¡Œå¤„ç†è¯»è¯·æ±‚\n\n\nä¸»ä»å¤åˆ¶å®¢æˆ·ç«¯ â”€â”€å†™å…¥â”€â”€&gt; ä¸»èŠ‚ç‚¹ â”€â”€å¤åˆ¶æ—¥å¿—â”€â”€&gt; ä»èŠ‚ç‚¹1                              â””â”€â”€&gt; ä»èŠ‚ç‚¹2\n\nåŒæ­¥ vs å¼‚æ­¥å¤åˆ¶ï¼š\n\n\n\næ–¹å¼\nä¼˜ç‚¹\nç¼ºç‚¹\n\n\n\nåŒæ­¥\næ•°æ®ä¸€è‡´\nå»¶è¿Ÿé«˜ï¼Œå¯ç”¨æ€§å·®\n\n\nå¼‚æ­¥\nå»¶è¿Ÿä½\nå¯èƒ½æ•°æ®ä¸¢å¤±\n\n\nåŠåŒæ­¥\nå¹³è¡¡\nå®ç°å¤æ‚\n\n\nå¤åˆ¶å»¶è¿Ÿé—®é¢˜\n\n\né—®é¢˜\nè¯´æ˜\nè§£å†³æ–¹æ¡ˆ\n\n\n\nè¯»å·±ä¹‹å†™\nå†™åè¯»å¯èƒ½è¯»åˆ°æ—§æ•°æ®\nä¿®æ”¹çš„æ•°æ®ä»ä¸»èŠ‚ç‚¹è¯»\n\n\nå•è°ƒè¯»\nåˆ·æ–°åå¯èƒ½çœ‹åˆ°æ›´æ—§çš„æ•°æ®\næ¯ä¸ªç”¨æˆ·å›ºå®šå‰¯æœ¬\n\n\nä¸€è‡´å‰ç¼€è¯»\nå› æœå…³ç³»è¢«æ‰“ä¹±\nç›¸å…³å†™å…¥åŒä¸€åˆ†åŒº\n\n\nå¤šä¸»å¤åˆ¶é€‚ç”¨åœºæ™¯ï¼šå¤šæ•°æ®ä¸­å¿ƒã€ç¦»çº¿å®¢æˆ·ç«¯ã€åä½œç¼–è¾‘\nå†™å†²çªè§£å†³ï¼š\n\n\n\nç­–ç•¥\nè¯´æ˜\n\n\n\næœ€åå†™å…¥èƒœå‡º (LWW)\næ—¶é—´æˆ³æœ€æ–°çš„è¦†ç›–\n\n\nåˆå¹¶å€¼\nå¦‚æ‹¼æ¥ â€œA/Bâ€\n\n\nCRDT\nç‰¹æ®Šæ•°æ®ç»“æ„è‡ªåŠ¨åˆå¹¶\n\n\næç¤ºç”¨æˆ·\nç±»ä¼¼ Git å†²çª\n\n\næ— ä¸»å¤åˆ¶ (Dynamo é£æ ¼)Quorum å…¬å¼ï¼š\nN=3, W=2, R=2:å†™å…¥éœ€è¦ 2 ä¸ªå‰¯æœ¬ç¡®è®¤è¯»å–éœ€è¦æŸ¥è¯¢ 2 ä¸ªå‰¯æœ¬è‡³å°‘ 1 ä¸ªå‰¯æœ¬æ—¢å†™å…¥åˆè¯»å–ï¼Œä¿è¯è¯»åˆ°æœ€æ–°å€¼\n\n\nç¬¬6ç« ï¼šæ•°æ®åˆ†åŒºåˆ†åŒºç­–ç•¥\n\n\nç­–ç•¥\nä¼˜ç‚¹\nç¼ºç‚¹\n\n\n\næŒ‰é”®èŒƒå›´\næ”¯æŒèŒƒå›´æŸ¥è¯¢\nå¯èƒ½çƒ­ç‚¹\n\n\næŒ‰é”®å“ˆå¸Œ\nåˆ†å¸ƒå‡åŒ€\nå¤±å»èŒƒå›´æŸ¥è¯¢\n\n\nä¸€è‡´æ€§å“ˆå¸Œï¼šæ·»åŠ /åˆ é™¤èŠ‚ç‚¹åªå½±å“ç›¸é‚»åŒºé—´\nçƒ­ç‚¹é—®é¢˜æ˜æ˜Ÿå‘å¾®åš â†’ æ‰€æœ‰è¯·æ±‚å‘å¾€åŒä¸€åˆ†åŒº\n\nè§£å†³æ–¹æ¡ˆï¼šæ‹†åˆ†çƒ­é”®ï¼ˆæ·»åŠ éšæœºåç¼€ï¼‰ã€æœ¬åœ°ç¼“å­˜ã€é™æµ\näºŒçº§ç´¢å¼•åˆ†åŒº\n\n\nç±»å‹\nç‰¹ç‚¹\n\n\n\næœ¬åœ°ç´¢å¼•\næ¯åˆ†åŒºç»´æŠ¤è‡ªå·±çš„ç´¢å¼•ï¼ŒæŸ¥è¯¢éœ€ scatter/gather\n\n\nå…¨å±€ç´¢å¼•\nç´¢å¼•æœ¬èº«åˆ†åŒºï¼Œè¯»å¿«å†™æ…¢ï¼ˆå¼‚æ­¥æ›´æ–°ï¼‰\n\n\nå†å¹³è¡¡ç­–ç•¥\n\n\nç­–ç•¥\nè¯´æ˜\näº§å“ç¤ºä¾‹\n\n\n\nå›ºå®šåˆ†åŒºæ•°\né¢„åˆ›å»ºå¤§é‡åˆ†åŒº\nElasticsearch\n\n\nåŠ¨æ€åˆ†åŒº\nè‡ªåŠ¨æ‹†åˆ†åˆå¹¶\nHBase\n\n\næŒ‰èŠ‚ç‚¹æ¯”ä¾‹\næ¯èŠ‚ç‚¹å›ºå®šåˆ†åŒºæ•°\nCassandra\n\n\nè¯·æ±‚è·¯ç”±æ–¹æ¡ˆ1: å®¢æˆ·ç«¯ç›´è¿ä»»æ„èŠ‚ç‚¹ â†’ è½¬å‘æ–¹æ¡ˆ2: è·¯ç”±å±‚ï¼ˆçŸ¥é“åˆ†åŒºæ˜ å°„ï¼‰æ–¹æ¡ˆ3: å®¢æˆ·ç«¯æ„ŸçŸ¥åˆ†åŒºï¼ˆå¦‚ä½¿ç”¨ ZooKeeperï¼‰\n\n\nç¬¬7ç« ï¼šäº‹åŠ¡ACID ç‰¹æ€§\n\n\nç‰¹æ€§\nå«ä¹‰\n\n\n\nåŸå­æ€§\nå…¨éƒ¨æˆåŠŸæˆ–å…¨éƒ¨å¤±è´¥\n\n\nä¸€è‡´æ€§\nä»æœ‰æ•ˆçŠ¶æ€åˆ°æœ‰æ•ˆçŠ¶æ€\n\n\néš”ç¦»æ€§\nå¹¶å‘äº‹åŠ¡äº’ä¸å¹²æ‰°\n\n\næŒä¹…æ€§\næäº¤åæ•°æ®ä¸ä¸¢å¤±\n\n\néš”ç¦»çº§åˆ«\n\n\nçº§åˆ«\né˜²æ­¢é—®é¢˜\n\n\n\nè¯»å·²æäº¤\nè„è¯»ã€è„å†™\n\n\nå¿«ç…§éš”ç¦»\nä¸å¯é‡å¤è¯»\n\n\nä¸²è¡ŒåŒ–\næ‰€æœ‰å¹¶å‘å¼‚å¸¸\n\n\nä¸¢å¤±æ›´æ–°é—®é¢˜äº‹åŠ¡1: è¯»å– counter=10     å†™å…¥ counter=11äº‹åŠ¡2:      è¯»å– counter=10        å†™å…¥ counter=11æœŸæœ›: 12ï¼Œå®é™…: 11ï¼ˆäº‹åŠ¡1çš„æ›´æ–°ä¸¢å¤±ï¼‰\n\nè§£å†³ï¼šåŸå­æ“ä½œã€æ˜¾å¼é”å®šã€Compare-and-Set\nå†™åæ–œåŒ»é™¢è§„åˆ™ï¼šè‡³å°‘1ååŒ»ç”Ÿå€¼ç­Alice æŸ¥è¯¢ï¼š2äººå€¼ç­ï¼Œå–æ¶ˆè‡ªå·±Bob åŒæ—¶ï¼š2äººå€¼ç­ï¼Œå–æ¶ˆè‡ªå·±ç»“æœï¼šæ— äººå€¼ç­ï¼\n\nè§£å†³ï¼šä¸²è¡ŒåŒ–éš”ç¦»ã€ç‰©åŒ–å†²çªã€æ˜¾å¼é”å®š\nä¸²è¡ŒåŒ–å®ç°\n\n\næ–¹å¼\nç‰¹ç‚¹\näº§å“\n\n\n\nå®é™…ä¸²è¡Œ\nå•çº¿ç¨‹æ‰§è¡Œ\nRedis, VoltDB\n\n\nä¸¤é˜¶æ®µé” (2PL)\nè¯»å†™äº’æ–¥\nä¼ ç»Ÿæ•°æ®åº“\n\n\nä¸²è¡ŒåŒ–å¿«ç…§éš”ç¦» (SSI)\nä¹è§‚å¹¶å‘\nPostgreSQL 9.1+\n\n\nåˆ†å¸ƒå¼äº‹åŠ¡ (2PC)é˜¶æ®µ1: åè°ƒè€… â”€â”€å‡†å¤‡?â”€â”€&gt; æ‰€æœ‰å‚ä¸è€…é˜¶æ®µ2: åè°ƒè€… â”€â”€æäº¤/å›æ»šâ”€â”€&gt; æ‰€æœ‰å‚ä¸è€…é—®é¢˜ï¼šåè°ƒè€…æ•…éšœæ—¶å‚ä¸è€…é˜»å¡\n\n\nç¬¬8ç« ï¼šåˆ†å¸ƒå¼ç³»ç»Ÿçš„æŒ‘æˆ˜éƒ¨åˆ†å¤±æ•ˆ\n\n\nå•æœºç³»ç»Ÿ\nåˆ†å¸ƒå¼ç³»ç»Ÿ\n\n\n\nè¦ä¹ˆå·¥ä½œè¦ä¹ˆä¸å·¥ä½œ\néƒ¨åˆ†å¯èƒ½å·¥ä½œ\n\n\næ•…éšœé€šå¸¸å®Œå…¨\næ•…éšœé€šå¸¸éƒ¨åˆ†\n\n\nä¸å¯é çš„ç½‘ç»œè¯·æ±‚å¯èƒ½ï¼šä¸¢å¤±ã€å»¶è¿Ÿã€é‡å¤å“åº”å¯èƒ½ï¼šä¸¢å¤±ã€å»¶è¿Ÿæ— æ³•åŒºåˆ†ï¼šç½‘ç»œæ•…éšœ vs èŠ‚ç‚¹æ•…éšœ\n\nè¶…æ—¶å›°å¢ƒï¼šå¤ªçŸ­è¯¯åˆ¤æ­£å¸¸èŠ‚ç‚¹ï¼Œå¤ªé•¿æ¢å¤æ…¢\nä¸å¯é çš„æ—¶é’Ÿ\n\n\næ—¶é’Ÿç±»å‹\nç”¨é€”\n\n\n\næ—¥å†æ—¶é’Ÿ\nå½“å‰æ—¶é—´ï¼ˆå¯èƒ½è·³è·ƒï¼‰\n\n\nå•è°ƒæ—¶é’Ÿ\næµ‹é‡æŒç»­æ—¶é—´ï¼ˆä¿è¯é€’å¢ï¼‰\n\n\nLWW çš„é£é™©ï¼šæ—¶é’Ÿä¸åŒæ­¥å¯¼è‡´æ–°æ•°æ®è¢«æ—§æ•°æ®è¦†ç›–\nFencing TokenèŠ‚ç‚¹A è·å–é” token=33 â†’ æš‚åœèŠ‚ç‚¹B è·å–é” token=34 â†’ å†™å…¥æˆåŠŸèŠ‚ç‚¹A æ¢å¤ token=33 â†’ è¢«æ‹’ç»ï¼ˆ33 &lt; 34ï¼‰\n\nç³»ç»Ÿæ¨¡å‹\n\n\næ—¶åºå‡è®¾\nèŠ‚ç‚¹æ•…éšœå‡è®¾\n\n\n\nåŒæ­¥/éƒ¨åˆ†åŒæ­¥/å¼‚æ­¥\nå´©æºƒ-åœæ­¢/å´©æºƒ-æ¢å¤/æ‹œå åº­\n\n\næ­£ç¡®æ€§ï¼šå®‰å…¨æ€§ï¼ˆåäº‹ä¸å‘ç”Ÿï¼‰ + æ´»æ€§ï¼ˆå¥½äº‹æœ€ç»ˆå‘ç”Ÿï¼‰\n\nç¬¬9ç« ï¼šä¸€è‡´æ€§ä¸å…±è¯†ä¸€è‡´æ€§æ¨¡å‹å¼± â†â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â†’ å¼ºæœ€ç»ˆä¸€è‡´æ€§    å› æœä¸€è‡´æ€§    é¡ºåºä¸€è‡´æ€§    çº¿æ€§ä¸€è‡´æ€§\n\nçº¿æ€§ä¸€è‡´æ€§\nç³»ç»Ÿè¡¨ç°å¾—å¥½åƒåªæœ‰ä¸€ä¸ªæ•°æ®å‰¯æœ¬ï¼Œæ‰€æœ‰æ“ä½œéƒ½æ˜¯åŸå­çš„\n\nåº”ç”¨ï¼šåˆ†å¸ƒå¼é”ã€é¢†å¯¼è€…é€‰ä¸¾ã€å”¯ä¸€æ€§çº¦æŸ\nCAP å®šç†ç½‘ç»œåˆ†åŒºæ—¶ï¼Œä¸€è‡´æ€§ä¸å¯ç”¨æ€§ä¸å¯å…¼å¾—\n\n\n\né€‰æ‹©\nå«ä¹‰\n\n\n\nCP\nä¿è¯ä¸€è‡´æ€§ï¼Œç‰ºç‰²å¯ç”¨æ€§\n\n\nAP\nä¿è¯å¯ç”¨æ€§ï¼Œç‰ºç‰²ä¸€è‡´æ€§\n\n\nå…±è¯†é—®é¢˜\nå¤šä¸ªèŠ‚ç‚¹å°±æŸä¸ªå€¼è¾¾æˆä¸€è‡´\n\næ€§è´¨ï¼šä¸€è‡´åŒæ„ã€å®Œæ•´æ€§ã€ç»ˆæ­¢æ€§ã€æœ‰æ•ˆæ€§\nFLP ä¸å¯èƒ½å®šç†ï¼šå¼‚æ­¥ç³»ç»Ÿä¸­å­˜åœ¨æ•…éšœèŠ‚ç‚¹æ—¶ï¼Œä¸å­˜åœ¨æ€»èƒ½è¾¾æˆå…±è¯†çš„ç®—æ³•\nPaxos ç®—æ³•é˜¶æ®µ1 (Prepare):æè®®è€… â”€â”€Prepare(n)â”€â”€&gt; æ¥å—è€…        &lt;â”€â”€Promiseâ”€â”€é˜¶æ®µ2 (Accept):æè®®è€… â”€â”€Accept(n,v)â”€â”€&gt; æ¥å—è€…        &lt;â”€â”€Acceptedâ”€â”€\n\nRaft ç®—æ³•æ¯” Paxos æ›´æ˜“ç†è§£\nè§’è‰²ï¼šé¢†å¯¼è€…ã€è·Ÿéšè€…ã€å€™é€‰äººä»»æœŸï¼šé€»è¾‘æ—¶é’Ÿï¼Œæ¯æ¬¡é€‰ä¸¾é€’å¢é€‰ä¸¾æµç¨‹ï¼š1. è·Ÿéšè€…è¶…æ—¶ â†’ å˜å€™é€‰äºº2. è¯·æ±‚æŠ•ç¥¨ â†’ è·å¤šæ•°ç¥¨3. æˆä¸ºé¢†å¯¼è€… â†’ å¤åˆ¶æ—¥å¿—\n\nå…±è¯†çš„åº”ç”¨\n\n\näº§å“\nç”¨é€”\n\n\n\nZooKeeper\nåè°ƒæœåŠ¡ã€é…ç½®ç®¡ç†\n\n\netcd\nKubernetes çŠ¶æ€å­˜å‚¨\n\n\nConsul\næœåŠ¡å‘ç°\n\n\n\næœ¬éƒ¨åˆ†è¦ç‚¹æ€»ç»“\nå¤åˆ¶çš„æ ¸å¿ƒæŒ‘æˆ˜æ˜¯å¤„ç†æ•°æ®å˜æ›´\nåˆ†åŒºç­–ç•¥éœ€è¦æƒè¡¡èŒƒå›´æŸ¥è¯¢å’Œè´Ÿè½½å‡è¡¡\näº‹åŠ¡éš”ç¦»çº§åˆ«æ˜¯æ­£ç¡®æ€§å’Œæ€§èƒ½çš„æƒè¡¡\nåˆ†å¸ƒå¼ç³»ç»Ÿçš„æ ¸å¿ƒæŒ‘æˆ˜æ˜¯éƒ¨åˆ†å¤±æ•ˆ\nçº¿æ€§ä¸€è‡´æ€§æ˜¯æœ€å¼ºä¿è¯ï¼Œä½†ä»£ä»·é«˜æ˜‚\nRaft æ¯” Paxos æ›´æ˜“ç†è§£ï¼Œé€‚åˆå­¦ä¹ \n\n\nä¸Šä¸€éƒ¨åˆ†ï¼šæ•°æ®ç³»ç»ŸåŸºç¡€ | è¿”å›æ€»è§ˆ | ä¸‹ä¸€éƒ¨åˆ†ï¼šè¡ç”Ÿæ•°æ®\n","categories":["è¯»ä¹¦ç¬”è®°"],"tags":["DDIA","åˆ†å¸ƒå¼ç³»ç»Ÿ","ä¸€è‡´æ€§","å…±è¯†ç®—æ³•"]},{"title":"LLM æ¸¸æˆæ™ºèƒ½ä½“è®ºæ–‡è§£è¯»ï¼šæ€»è§ˆ","url":"/2025/12/28/LLM-Game-Agents-%E8%AE%BA%E6%96%87%E8%A7%A3%E8%AF%BB-%E6%80%BB%E8%A7%88/","content":"æœ¬ç³»åˆ—æ˜¯ LLM é©±åŠ¨çš„æ¸¸æˆæ™ºèƒ½ä½“é¢†åŸŸæ ¸å¿ƒè®ºæ–‡çš„è§£è¯»ä¸æ€»ç»“ï¼Œæ¶µç›– 103+ ç¯‡è®ºæ–‡ï¼Œ164 æ¡å¼•ç”¨å…³ç³»çš„ç³»ç»Ÿæ€§åˆ†æã€‚\n\né¢†åŸŸæ¦‚è¿°éšç€å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„å¿«é€Ÿå‘å±•ï¼Œç ”ç©¶è€…ä»¬å¼€å§‹æ¢ç´¢å°† LLM ä½œä¸ºæ™ºèƒ½ä½“â€å¤§è„‘â€çš„å¯èƒ½æ€§ã€‚è¿™äº›æ™ºèƒ½ä½“ä¸ä»…èƒ½ç†è§£å’Œç”Ÿæˆæ–‡æœ¬ï¼Œè¿˜èƒ½è§„åˆ’ã€åæ€ã€ä¸ç¯å¢ƒäº¤äº’ï¼Œç”šè‡³å½¢æˆå¤æ‚çš„ç¤¾ä¼šè¡Œä¸ºã€‚\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”‚                    LLM æ¸¸æˆæ™ºèƒ½ä½“æŠ€æœ¯æ ˆ                       â”‚â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤â”‚                                                             â”‚â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                       â”‚â”‚   â”‚   åº”ç”¨å±‚         â”‚  æ¸¸æˆ/æ¨¡æ‹Ÿ/æœºå™¨äºº                       â”‚â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                       â”‚â”‚            â”‚                                                â”‚â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”                                       â”‚â”‚   â”‚   æ™ºèƒ½ä½“æ¡†æ¶     â”‚  ReAct / Reflexion / VOYAGER          â”‚â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                       â”‚â”‚            â”‚                                                â”‚â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”                                       â”‚â”‚   â”‚   æ ¸å¿ƒèƒ½åŠ›       â”‚  è®°å¿† / è§„åˆ’ / åæ€ / å·¥å…·ä½¿ç”¨          â”‚â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                       â”‚â”‚            â”‚                                                â”‚â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”                                       â”‚â”‚   â”‚   åŸºç¡€æ¨¡å‹       â”‚  GPT-4 / Claude / Llama               â”‚â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                       â”‚â”‚                                                             â”‚â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n\n\næ ¸å¿ƒè®ºæ–‡å¼•ç”¨å…³ç³»åŸºäº 103 ç¯‡è®ºæ–‡çš„å¼•ç”¨ç½‘ç»œåˆ†æï¼Œä»¥ä¸‹æ˜¯é¢†åŸŸå†…æœ€å…·å½±å“åŠ›çš„åŸºç¡€æ€§å·¥ä½œï¼š\n\n\n\næ’å\nè®ºæ–‡\nä¼šè®®\nè¢«å¼•ç”¨\næ ¸å¿ƒè´¡çŒ®\n\n\n\n1\nReAct\nICLR 2023\n32\næ¨ç†+è¡ŒåŠ¨äº¤æ›¿èŒƒå¼\n\n\n2\nGenerative Agents\nUIST 2023\n20\nè®°å¿†-åæ€-è§„åˆ’æ¶æ„\n\n\n3\nReflexion\nNeurIPS 2023\n17\nè¯­è¨€åé¦ˆå¼ºåŒ–å­¦ä¹ \n\n\n4\nVOYAGER\nNeurIPS 2023\n-\næŠ€èƒ½åº“+ç»ˆèº«å­¦ä¹ \n\n\næŠ€æœ¯å±‚æ¬¡é‡‘å­—å¡”                â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                â”‚   ğŸ¯ ä¸Šå±‚åº”ç”¨       â”‚                â”‚  ç«æŠ€/ç¤¾äº¤/ç‰¹å®šæ¸¸æˆ  â”‚                â”‚  (Werewolf, Poker,  â”‚                â”‚   StarCraftç­‰)      â”‚                â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                           â”‚          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”‚                â”‚                â”‚â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”â”‚  ğŸ—ï¸ ä¸­é—´å±‚       â”‚ â”‚æ¨¡æ‹Ÿä»¿çœŸ â”‚ â”‚  ğŸ¤ å¤šæ™ºèƒ½ä½“    â”‚â”‚  ç¯å¢ƒé€‚é…å±‚      â”‚ â”‚         â”‚ â”‚  åä½œå±‚         â”‚â”‚ (Crafter,       â”‚ â”‚Generativeâ”‚ â”‚                â”‚â”‚  Minecraft)     â”‚ â”‚ Agents  â”‚ â”‚                â”‚â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜          â”‚              â”‚               â”‚          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                         â”‚                â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”                â”‚  ğŸ”§ åŸºç¡€æ¡†æ¶å±‚   â”‚                â”‚                 â”‚                â”‚  â€¢ ReAct        â”‚ â† æ¨ç†+è¡ŒåŠ¨èŒƒå¼                â”‚  â€¢ Reflexion    â”‚ â† è‡ªæˆ‘åæ€æœºåˆ¶                â”‚  â€¢ Grounding RL â”‚ â† ç¯å¢ƒäº¤äº’å­¦ä¹                 â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n\n\nç³»åˆ—æ–‡ç« ç›®å½•åŸºç¡€æ¡†æ¶ç¯‡\n\n\næ–‡ç« \næ ¸å¿ƒå†…å®¹\n\n\n\nåŸºç¡€æ¡†æ¶ï¼šReAct / Reflexion / Generative Agents\nä¸‰å¤§æ ¸å¿ƒæ¡†æ¶çš„è¯¦ç»†å¯¹æ¯”åˆ†æ\n\n\nåº”ç”¨æ‰©å±•ç¯‡\n\n\næ–‡ç« \næ ¸å¿ƒå†…å®¹\n\n\n\nåº”ç”¨æ‰©å±•ï¼šVOYAGER / Project Sid / Agent Hospital\nç»ˆèº«å­¦ä¹ ã€AIæ–‡æ˜ã€åŒ»ç–—æ™ºèƒ½ä½“\n\n\n\nç ”ç©¶è„‰ç»œæ—¶é—´çº¿2023å¹´ï¼šåŸºç¡€å¥ å®š\n\n\næ—¶é—´\nè®ºæ–‡\nä¼šè®®\næ ¸å¿ƒè´¡çŒ®\n\n\n\n2022/10\nReAct\nICLR 2023\næ¨ç†ä¸è¡ŒåŠ¨ååŒèŒƒå¼\n\n\n2023/03\nReflexion\nNeurIPS 2023\nè¯­è¨€åé¦ˆå¼ºåŒ–å­¦ä¹ \n\n\n2023/04\nGenerative Agents\nUIST 2023\n25æ™ºèƒ½ä½“å°é•‡æ¨¡æ‹Ÿ\n\n\n2023/05\nVOYAGER\nNeurIPS 2023\nMinecraftç»ˆèº«å­¦ä¹ \n\n\n2024å¹´ï¼šæ·±åº¦å‘å±•\n\n\næ—¶é—´\nè®ºæ–‡\næ ¸å¿ƒè´¡çŒ®\n\n\n\n2024/05\nAgent Hospital\nå¯è¿›åŒ–åŒ»ç–—æ™ºèƒ½ä½“\n\n\n2024/10\nProject Sid\n500-1000+æ™ºèƒ½ä½“æ–‡æ˜æ¨¡æ‹Ÿ\n\n\n2024/10\nClaude Computer Use\nå•†ä¸šçº§è®¡ç®—æœºæ§åˆ¶\n\n\n2025å¹´ï¼šäº§ä¸šåŒ–\n\n\næ—¶é—´\nè¶‹åŠ¿\nä»£è¡¨äº§å“\n\n\n\n2025\nAgent OSåŒ–\nAutoGen, LangGraph\n\n\n2025\nå•†ä¸šåŒ–åŠ é€Ÿ\nOpenAI Operator\n\n\n2025\nå¤šæ¨¡æ€èåˆ\nè§†è§‰+è¯­è¨€+è¡ŒåŠ¨\n\n\n\næ¸¸æˆç±»å‹ä¸è®ºæ–‡åˆ†å¸ƒ\n\n\næ¸¸æˆç±»å‹\nè®ºæ–‡æ•°\nä»£è¡¨è®ºæ–‡\n\n\n\næ–‡å­—å†’é™©\n22\nReAct, Reflexion, ALFWorld\n\n\nMinecraft\n15\nVOYAGER, GITM, JARVIS-1\n\n\nç¤¾ä¼šæ¨¡æ‹Ÿ\n12\nGenerative Agents, Project Sid\n\n\nç«æŠ€æ¸¸æˆ\n15\nPokÃ©LLMon, StarCraft II\n\n\nåˆä½œæ¸¸æˆ\n7\nCo-LLM-Agents, TeamCraft\n\n\nå¯¹è¯æ¸¸æˆ\n16\nWerewolf, Avalon\n\n\n\næ ¸å¿ƒæŠ€æœ¯å¯¹æ¯”è®°å¿†æœºåˆ¶\n\n\næ–¹æ³•\nå­˜å‚¨å†…å®¹\næ£€ç´¢æ–¹å¼\nç‰¹ç‚¹\n\n\n\nVOYAGER\nå¯æ‰§è¡Œä»£ç \nè¯­ä¹‰ç›¸ä¼¼åº¦\næŠ€èƒ½å¯å¤ç”¨\n\n\nGenerative Agents\nè‡ªç„¶è¯­è¨€\næ—¶è¿‘æ€§+é‡è¦æ€§+ç›¸å…³æ€§\nå¤šå±‚æŠ½è±¡\n\n\nReflexion\nè¯­è¨€åŒ–åæ€\næ—¶é—´é¡ºåº\nå¤±è´¥å­¦ä¹ \n\n\nåæ€æœºåˆ¶\n\n\næ–¹æ³•\nè§¦å‘æ¡ä»¶\nè¾“å‡º\nç›®çš„\n\n\n\nVOYAGER\næ¯è½®æ‰§è¡Œå\næˆåŠŸ/å¤±è´¥+æ‰¹è¯„\nä»»åŠ¡éªŒè¯\n\n\nGenerative Agents\né‡è¦æ€§&gt;150\né«˜å±‚æ¬¡æ´å¯Ÿ\næ¦‚å¿µæŠ½è±¡\n\n\nReflexion\næ¯æ¬¡å¤±è´¥å\nè¯¦ç»†åæ€\né”™è¯¯è¯Šæ–­\n\n\nå­¦ä¹ æ–¹å¼\n\n\næ–¹æ³•\næ˜¯å¦å¾®è°ƒ\nçŸ¥è¯†å½¢å¼\nå­¦ä¹ ç›®æ ‡\n\n\n\nä¼ ç»ŸRL\nâœ… æ¢¯åº¦æ›´æ–°\nç­–ç•¥ç½‘ç»œ\nå¥–åŠ±æœ€å¤§åŒ–\n\n\nVOYAGER\nâŒ æç¤ºå·¥ç¨‹\nä»£ç æŠ€èƒ½åº“\næŠ€èƒ½ç§¯ç´¯\n\n\nReflexion\nâŒ è¯­è¨€å¼ºåŒ–\nåæ€è®°å¿†\nä»»åŠ¡æˆåŠŸç‡\n\n\n\nå…³é”®æ´è§1. æ— éœ€å¾®è°ƒçš„åŠ›é‡ä¸‰å¤§æ ¸å¿ƒæ¡†æ¶ï¼ˆReActã€Reflexionã€Generative Agentsï¼‰éƒ½è¯æ˜ï¼šä»…é€šè¿‡æç¤ºå·¥ç¨‹å’Œè¿è¡Œæ—¶æœºåˆ¶ï¼Œæ— éœ€å¾®è°ƒæ¨¡å‹å‚æ•°ï¼Œå°±èƒ½å®ç°å¤æ‚çš„æ™ºèƒ½ä½“è¡Œä¸ºã€‚\n2. è®°å¿†æ˜¯å…³é”®æœ‰æ•ˆçš„è®°å¿†æœºåˆ¶æ˜¯æ™ºèƒ½ä½“æˆåŠŸçš„åŸºç¡€ï¼š\n\nVOYAGERï¼šä»£ç å³è®°å¿†ï¼ŒæŠ€èƒ½å¯å¤ç”¨\nGenerative Agentsï¼šè®°å¿†å³äººæ ¼ï¼Œåæ€å³æˆé•¿\nReflexionï¼šåæ€å³å­¦ä¹ ï¼Œå¤±è´¥å³è¿›æ­¥\n\n3. ååŒä¼˜äºå­¤ç«‹\n\n\nå•ä¸€èƒ½åŠ›\nååŒèƒ½åŠ›\n\n\n\nä»…æ¨ç† â†’ å¹»è§‰ä¸¥é‡\næ¨ç†+è¡ŒåŠ¨ â†’ ReAct\n\n\nä»…è¡ŒåŠ¨ â†’ æ— æ³•è§„åˆ’\nè¡ŒåŠ¨+åæ€ â†’ Reflexion\n\n\nå•æ™ºèƒ½ä½“ â†’ èƒ½åŠ›æœ‰é™\nå¤šæ™ºèƒ½ä½“ â†’ æ¶Œç°ç¤¾ä¼šè¡Œä¸º\n\n\n4. è§„æ¨¡å¸¦æ¥æ¶Œç°\n\n\nè§„æ¨¡\næ¶Œç°ç°è±¡\n\n\n\n25 æ™ºèƒ½ä½“\nç¤¾äº¤è¡Œä¸ºã€ä¿¡æ¯ä¼ æ’­ (Generative Agents)\n\n\n50 æ™ºèƒ½ä½“\né•¿æœŸå…³ç³»ã€è§’è‰²åˆ†åŒ– (Project Sid)\n\n\n500+ æ™ºèƒ½ä½“\næ–‡åŒ–ä¼ æ’­ã€å®—æ•™æ¶Œç° (Project Sid)\n\n\n\nå®è·µå»ºè®®åœºæ™¯åŒ¹é…\n\n\nåœºæ™¯\næ¨èæ–¹æ³•\nåŸå› \n\n\n\nå¼€æ”¾ä¸–ç•Œæ¸¸æˆ\nVOYAGER\næŠ€èƒ½å¯å¤ç”¨ã€å¯ç»„åˆ\n\n\nç¤¾ä¼šæ¨¡æ‹Ÿ\nGenerative Agents\nä¸°å¯Œè®°å¿†å’Œäººæ ¼ä¸€è‡´æ€§\n\n\nå†³ç­–ä»»åŠ¡\nReflexion\nå¤±è´¥åæ€å¯¹å†³ç­–ä¼˜åŒ–å…³é”®\n\n\nåŒ»ç–—/ä¸“ä¸šé¢†åŸŸ\nAgent Hospital\nå¯è¿›åŒ–çš„ä¸“ä¸šæ™ºèƒ½ä½“\n\n\nç»„åˆæ¶æ„ç†æƒ³çš„æ™ºèƒ½ä½“åº”è¯¥ç»“åˆä¸‰è€…ä¼˜åŠ¿ï¼š\nç†æƒ³æ¶æ„ = Generative Agentsçš„è®°å¿†æµ         + VOYAGERçš„æŠ€èƒ½åº“         + Reflexionçš„å¤±è´¥åæ€\n\n\nå·¥ä¸šè¶‹åŠ¿ä¸»è¦ç©å®¶\n\n\nå…¬å¸\näº§å“\næ ¸å¿ƒèƒ½åŠ›\n\n\n\nOpenAI\nGPT-4V Agent, Operator\né€šç”¨Agentèƒ½åŠ›\n\n\nAnthropic\nClaude Computer Use\nè®¡ç®—æœºè‡ªä¸»æ§åˆ¶\n\n\nMicrosoft\nAutoGen 0.4\nä¼ä¸šçº§å¤šAgentæ¡†æ¶\n\n\nAltera AI\nProject Sid\nAIæ–‡æ˜æ¨¡æ‹Ÿ\n\n\nå¼€æºç”Ÿæ€\n\n\næ¡†æ¶\nå®šä½\nçƒ­åº¦\n\n\n\nAutoGen\nå¤šAgentå¯¹è¯ä¸åä½œ\nğŸ”¥ğŸ”¥ğŸ”¥\n\n\nLangGraph\nçŠ¶æ€æœºAgentå·¥ä½œæµ\nğŸ”¥ğŸ”¥ğŸ”¥\n\n\nMetaGPT\nå¤šè§’è‰²è½¯ä»¶å¼€å‘\nğŸ”¥ğŸ”¥\n\n\nCrewAI\nè§’è‰²æ‰®æ¼”Agentå›¢é˜Ÿ\nğŸ”¥ğŸ”¥\n\n\n\nå‚è€ƒèµ„æºè®ºæ–‡åˆ—è¡¨\nawesome-LLM-game-agent-papers\nA Survey on Large Language Model-Based Game Agents\n\nä»£ç ä»“åº“\n\n\nè®ºæ–‡\nä»£ç \n\n\n\nReAct\ngithub.com/ysymyth/ReAct\n\n\nReflexion\ngithub.com/noahshinn024/reflexion\n\n\nGenerative Agents\ngithub.com/joonspk-research/generative_agents\n\n\nVOYAGER\nvoyager.minedojo.org\n\n\n\nä¸‹ä¸€ç¯‡ï¼šåŸºç¡€æ¡†æ¶ç¯‡ | åº”ç”¨æ‰©å±•ç¯‡\n","categories":["è®ºæ–‡è§£è¯»"],"tags":["LLM","Agent","è®ºæ–‡è§£è¯»","æ¸¸æˆAI","å¤šæ™ºèƒ½ä½“"]},{"title":"NLP å­¦ä¹ è·¯çº¿ï¼šä»åŸºç¡€åˆ°å¤§è¯­è¨€æ¨¡å‹","url":"/2019/10/31/NLP%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%E4%B9%8B%E2%80%94%E2%80%94%E8%AF%BB%E9%A6%99%E4%BE%AC%E7%A7%91%E6%8A%80%E6%9D%8E%E7%BA%A7%E4%B8%BA%E3%80%8A%E5%87%BA%E5%85%A5NLP%E9%A2%86%E5%9F%9F%E7%9A%84%E4%B8%80%E4%BA%9B%E5%B0%8F%E5%BB%BA%E8%AE%AE%E3%80%8B%E6%96%87%E7%AB%A0/","content":"æœ¬æ–‡æ•´ç†äº† NLP é¢†åŸŸçš„å­¦ä¹ è·¯çº¿ï¼Œç»“åˆç»å…¸ç†è®ºä¸ç°ä»£å¤§è¯­è¨€æ¨¡å‹æŠ€æœ¯ã€‚\næ¨èå­¦ä¹ èµ„æºç»å…¸æ•™æ\n\n\nä¹¦ç±\nå†…å®¹\néš¾åº¦\n\n\n\nSpeech and Language Processing (Jurafsky)\nNLP å…¨é¢ç»¼è¿°\nâ­â­\n\n\nIntroduction to Information Retrieval\nä¿¡æ¯æ£€ç´¢åŸºç¡€\nâ­â­\n\n\nPattern Recognition and Machine Learning\næœºå™¨å­¦ä¹ ç†è®º\nâ­â­â­â­\n\n\nDeep Learning (Goodfellow)\næ·±åº¦å­¦ä¹ åŸºç¡€\nâ­â­â­\n\n\nç°ä»£èµ„æº\nStanford CS224N: NLP with Deep Learning\nHugging Face Course\nLLM University by Cohere\n\né˜¶æ®µä¸€ï¼šNLP åŸºç¡€è¯­è¨€æ¨¡å‹åŸºç¡€N-gram æ¨¡å‹ï¼šN-1 é˜¶é©¬å°”å¯å¤«å‡è®¾\n\nfrom collections import defaultdictimport numpy as npclass NGramLM:    def __init__(self, n=3):        self.n = n        self.counts = defaultdict(lambda: defaultdict(int))        self.totals = defaultdict(int)        def train(self, corpus):        for sentence in corpus:            tokens = ['&lt;s&gt;'] * (self.n - 1) + sentence + ['&lt;/s&gt;']            for i in range(len(tokens) - self.n + 1):                context = tuple(tokens[i:i+self.n-1])                word = tokens[i+self.n-1]                self.counts[context][word] += 1                self.totals[context] += 1        def probability(self, word, context):        context = tuple(context[-(self.n-1):])        return self.counts[context][word] / max(self.totals[context], 1)\n\nè¯å‘é‡ä» One-hot åˆ° Dense Embedding çš„æ¼”è¿›ï¼š\n\n\n\næ–¹æ³•\nå¹´ä»½\nç‰¹ç‚¹\n\n\n\nOne-hot\n-\nç¨€ç–ï¼Œæ— è¯­ä¹‰\n\n\nWord2Vec\n2013\nåˆ†å¸ƒå¼è¡¨ç¤º\n\n\nGloVe\n2014\nå…¨å±€ç»Ÿè®¡\n\n\nFastText\n2016\nå­è¯ä¿¡æ¯\n\n\nELMo\n2018\nä¸Šä¸‹æ–‡ç›¸å…³\n\n\nBERT\n2018\nåŒå‘ä¸Šä¸‹æ–‡\n\n\né˜¶æ®µäºŒï¼šæ·±åº¦å­¦ä¹  NLPTransformer æ¶æ„import torchimport torch.nn as nnimport mathclass MultiHeadAttention(nn.Module):    def __init__(self, d_model, n_heads):        super().__init__()        self.d_k = d_model // n_heads        self.n_heads = n_heads                self.W_q = nn.Linear(d_model, d_model)        self.W_k = nn.Linear(d_model, d_model)        self.W_v = nn.Linear(d_model, d_model)        self.W_o = nn.Linear(d_model, d_model)        def forward(self, Q, K, V, mask=None):        batch_size = Q.size(0)                # Linear projections        Q = self.W_q(Q).view(batch_size, -1, self.n_heads, self.d_k).transpose(1, 2)        K = self.W_k(K).view(batch_size, -1, self.n_heads, self.d_k).transpose(1, 2)        V = self.W_v(V).view(batch_size, -1, self.n_heads, self.d_k).transpose(1, 2)                # Attention scores        scores = torch.matmul(Q, K.transpose(-2, -1)) / math.sqrt(self.d_k)                if mask is not None:            scores = scores.masked_fill(mask == 0, -1e9)                attn = torch.softmax(scores, dim=-1)        output = torch.matmul(attn, V)                # Concatenate and project        output = output.transpose(1, 2).contiguous().view(batch_size, -1, self.n_heads * self.d_k)        return self.W_o(output)\n\næ³¨æ„åŠ›æœºåˆ¶çš„æ•°å­¦è¡¨è¾¾\né˜¶æ®µä¸‰ï¼šå¤§è¯­è¨€æ¨¡å‹LLM æ¶æ„æ¼”è¿›GPT-1 (2018) â†’ GPT-2 â†’ GPT-3 â†’ ChatGPT â†’ GPT-4     â†“BERT â†’ RoBERTa â†’ DeBERTa     â†“T5 â†’ Flan-T5 â†’ UL2     â†“LLaMA â†’ LLaMA 2 â†’ Mistral â†’ Mixtral\n\nPrompt Engineering# 1. Zero-shotprompt = \"Translate to French: Hello, how are you?\"# 2. Few-shotprompt = \"\"\"Translate to French:Hello -&gt; BonjourGoodbye -&gt; Au revoirHow are you? -&gt;\"\"\"# 3. Chain-of-Thoughtprompt = \"\"\"Q: If I have 3 apples and buy 5 more, how many do I have?A: Let's think step by step.1. I start with 3 apples.2. I buy 5 more apples.3. Total = 3 + 5 = 8 apples.The answer is 8.Q: If I have 7 oranges and eat 2, how many remain?A: Let's think step by step.\"\"\"\n\nFine-tuning æŠ€æœ¯\n\n\næ–¹æ³•\nå¯è®­ç»ƒå‚æ•°\né€‚ç”¨åœºæ™¯\n\n\n\nFull Fine-tuning\n100%\nå¤§é‡æ•°æ®ï¼Œå……è¶³ç®—åŠ›\n\n\nLoRA\n0.1-1%\nèµ„æºå—é™\n\n\nQLoRA\n0.1%\næ¶ˆè´¹çº§ GPU\n\n\nPrefix Tuning\n0.1%\nå¤šä»»åŠ¡\n\n\nPrompt Tuning\n&lt;0.01%\næç«¯èµ„æºå—é™\n\n\nfrom peft import LoraConfig, get_peft_modellora_config = LoraConfig(    r=8,    lora_alpha=32,    target_modules=[\"q_proj\", \"v_proj\"],    lora_dropout=0.1,    bias=\"none\",)model = get_peft_model(base_model, lora_config)print(f\"Trainable params: {model.print_trainable_parameters()}\")\n\né˜¶æ®µå››ï¼šé«˜çº§ä¸»é¢˜æ£€ç´¢å¢å¼ºç”Ÿæˆ (RAG)from langchain.embeddings import HuggingFaceEmbeddingsfrom langchain.vectorstores import Chromafrom langchain.chains import RetrievalQA# æ„å»ºå‘é‡åº“embeddings = HuggingFaceEmbeddings(model_name=\"BAAI/bge-small-zh\")vectorstore = Chroma.from_documents(documents, embeddings)# åˆ›å»º RAG é“¾qa = RetrievalQA.from_chain_type(    llm=llm,    retriever=vectorstore.as_retriever(search_kwargs={\"k\": 3}))\n\næ¨¡å‹è¯„ä¼°# å›°æƒ‘åº¦ (Perplexity)def perplexity(model, tokenizer, text):    encodings = tokenizer(text, return_tensors='pt')    max_length = model.config.n_positions        nlls = []    for i in range(0, encodings.input_ids.size(1), max_length):        begin_loc = max(i - max_length, 0)        end_loc = i + max_length        input_ids = encodings.input_ids[:, begin_loc:end_loc]        target_ids = input_ids.clone()        target_ids[:, :-1] = -100                with torch.no_grad():            outputs = model(input_ids, labels=target_ids)            nlls.append(outputs.loss)        return torch.exp(torch.stack(nlls).mean())\n\nå®è·µé¡¹ç›®å»ºè®®\nå…¥é—¨ï¼šæƒ…æ„Ÿåˆ†æã€æ–‡æœ¬åˆ†ç±»\nè¿›é˜¶ï¼šå‘½åå®ä½“è¯†åˆ«ã€æœºå™¨ç¿»è¯‘\né«˜çº§ï¼šé—®ç­”ç³»ç»Ÿã€RAG åº”ç”¨\nä¸“å®¶ï¼šLLM é¢„è®­ç»ƒã€RLHF\n\nå»¶ä¼¸é˜…è¯»\nAttention Is All You Need\nBERT Paper\nLLaMA Paper\nLoRA Paper\n\n\n\nè½¬è½½è¯·æ³¨æ˜å‡ºå¤„\n\n","tags":["LLM","NLP","machine learning"]},{"title":"DDIA Part 1ï¼šæ•°æ®ç³»ç»ŸåŸºç¡€","url":"/2025/12/28/DDIA-Part1-%E6%95%B0%E6%8D%AE%E7%B3%BB%E7%BB%9F%E5%9F%BA%E7%A1%80/","content":"æœ¬æ–‡æ˜¯ DDIA ç¬¬ä¸€éƒ¨åˆ†çš„è¯»ä¹¦ç¬”è®°ï¼Œæ¶µç›–ç¬¬ 1-4 ç« ï¼šå¯é æ€§ä¸å¯æ‰©å±•æ€§ã€æ•°æ®æ¨¡å‹ã€å­˜å‚¨å¼•æ“ã€æ•°æ®ç¼–ç ã€‚\n\nç¬¬1ç« ï¼šå¯é æ€§ã€å¯æ‰©å±•æ€§ä¸å¯ç»´æŠ¤æ€§æ•°æ®å¯†é›†å‹åº”ç”¨çš„ç»„æˆç°ä»£æ•°æ®å¯†é›†å‹åº”ç”¨é€šå¸¸ç”±å¤šä¸ªç»„ä»¶ç»„åˆï¼š\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”‚         æ•°æ®å¯†é›†å‹åº”ç”¨æ¶æ„               â”‚â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤â”‚  æ•°æ®åº“ â†’ ç¼“å­˜ â†’ æœç´¢ç´¢å¼•               â”‚â”‚  æµå¤„ç† â†’ æ‰¹å¤„ç† â†’ æ¶ˆæ¯é˜Ÿåˆ—             â”‚â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n\nå¯é æ€§ (Reliability)\nç³»ç»Ÿåœ¨é¢å¯¹æ•…éšœæ—¶ä»èƒ½æ­£ç¡®è¿è¡Œ\n\næ•…éšœç±»å‹ä¸åº”å¯¹ï¼š\n\n\n\næ•…éšœç±»å‹\nåº”å¯¹ç­–ç•¥\n\n\n\nç¡¬ä»¶æ•…éšœ\nRAIDã€åŒç”µæºã€å¤šå‰¯æœ¬\n\n\nè½¯ä»¶é”™è¯¯\næµ‹è¯•ã€éš”ç¦»ã€ç›‘æ§ã€å¿«é€Ÿé‡å¯\n\n\näººä¸ºé”™è¯¯\næ²™ç®±ç¯å¢ƒã€ç°åº¦å‘å¸ƒã€å¿«é€Ÿå›æ»š\n\n\nå¯æ‰©å±•æ€§ (Scalability)\nç³»ç»Ÿåº”å¯¹è´Ÿè½½å¢é•¿çš„èƒ½åŠ›\n\næ€§èƒ½æŒ‡æ ‡ï¼šä½¿ç”¨ç™¾åˆ†ä½æ•°è€Œéå¹³å‡å€¼\n\n\n\nç™¾åˆ†ä½\nå«ä¹‰\n\n\n\np50\nä¸­ä½æ•°ï¼Œå…¸å‹å“åº”æ—¶é—´\n\n\np95\n95%è¯·æ±‚å¿«äºæ­¤å€¼\n\n\np99\nå¸¸ç”¨äº SLA æ ‡å‡†\n\n\næ‰©å±•ç­–ç•¥ï¼š\n\nçºµå‘æ‰©å±•ï¼šä½¿ç”¨æ›´å¼ºå¤§çš„æœºå™¨\næ¨ªå‘æ‰©å±•ï¼šä½¿ç”¨å¤šå°æ™®é€šæœºå™¨\nå¼¹æ€§æ‰©å±•ï¼šæ ¹æ®è´Ÿè½½è‡ªåŠ¨å¢å‡èµ„æº\n\nå¯ç»´æŠ¤æ€§ (Maintainability)\n\n\næ–¹é¢\nç›®æ ‡\n\n\n\nå¯æ“ä½œæ€§\nè¿ç»´å›¢é˜Ÿèƒ½è½»æ¾ä¿æŒç³»ç»Ÿè¿è¡Œ\n\n\nç®€å•æ€§\næ–°å·¥ç¨‹å¸ˆèƒ½å¿«é€Ÿç†è§£ç³»ç»Ÿ\n\n\nå¯æ¼”åŒ–æ€§\nèƒ½è½»æ¾ä¿®æ”¹å’Œæ‰©å±•ç³»ç»Ÿ\n\n\n\nç¬¬2ç« ï¼šæ•°æ®æ¨¡å‹ä¸æŸ¥è¯¢è¯­è¨€ä¸‰ç§æ•°æ®æ¨¡å‹å¯¹æ¯”\n\n\næ¨¡å‹\nç‰¹ç‚¹\né€‚ç”¨åœºæ™¯\n\n\n\nå…³ç³»æ¨¡å‹\nç»“æ„åŒ–ã€è§„èŒƒåŒ–ã€SQL\näº‹åŠ¡å¤„ç†ã€å¤æ‚æŸ¥è¯¢\n\n\næ–‡æ¡£æ¨¡å‹\nçµæ´»æ¨¡å¼ã€åµŒå¥—ç»“æ„\næ ‘çŠ¶æ•°æ®ã€å¿«é€Ÿè¿­ä»£\n\n\nå›¾æ¨¡å‹\nå¤šå¯¹å¤šå…³ç³»\nç¤¾äº¤ç½‘ç»œã€çŸ¥è¯†å›¾è°±\n\n\nå…³ç³»æ¨¡å‹-- è§„èŒƒåŒ–è®¾è®¡ï¼šä½¿ç”¨å¤–é”®CREATE TABLE users (    user_id INT PRIMARY KEY,    name VARCHAR(100),    position_id INT REFERENCES positions(position_id));\n\nä¼˜åŠ¿ï¼šæ•°æ®ä¸€è‡´æ€§ã€çµæ´»æŸ¥è¯¢ã€äº‹åŠ¡æ”¯æŒå±€é™ï¼šå¯¹è±¡-å…³ç³»é˜»æŠ—ä¸åŒ¹é…ã€æ¨¡å¼åƒµåŒ–\næ–‡æ¡£æ¨¡å‹{  \"user_id\": 1,  \"name\": \"å¼ ä¸‰\",  \"positions\": [    {\"title\": \"å·¥ç¨‹å¸ˆ\", \"company\": \"ABCå…¬å¸\"},    {\"title\": \"æŠ€æœ¯æ€»ç›‘\", \"company\": \"XYZå…¬å¸\"}  ]}\n\nSchema-on-read vs Schema-on-writeï¼š\n\nå…³ç³»æ•°æ®åº“ï¼šå†™å…¥æ—¶éªŒè¯æ¨¡å¼ï¼ˆé™æ€ç±»å‹ï¼‰\næ–‡æ¡£æ•°æ®åº“ï¼šè¯»å–æ—¶è§£é‡Šç»“æ„ï¼ˆåŠ¨æ€ç±»å‹ï¼‰\n\nå›¾æ¨¡å‹// Neo4j Cypher æŸ¥è¯¢MATCH (alice:Person {name: 'Alice'})-[:FOLLOWS]-&gt;()-[:FOLLOWS]-&gt;(fof)RETURN fof.name\n\nå£°æ˜å¼ vs å‘½ä»¤å¼\n\n\nç±»å‹\nç‰¹ç‚¹\nç¤ºä¾‹\n\n\n\nå£°æ˜å¼\næè¿°æƒ³è¦ä»€ä¹ˆç»“æœ\nSQL, Cypher\n\n\nå‘½ä»¤å¼\næè¿°å¦‚ä½•å¾—åˆ°ç»“æœ\nç¼–ç¨‹è¯­è¨€å¾ªç¯\n\n\n\nç¬¬3ç« ï¼šå­˜å‚¨ä¸æ£€ç´¢ä¸¤å¤§å­˜å‚¨å¼•æ“å®¶æ—\n\n\nç±»å‹\nä¼˜åŒ–ç›®æ ‡\nä»£è¡¨äº§å“\n\n\n\næ—¥å¿—ç»“æ„ (LSM)\nå†™å…¥ä¼˜åŒ–\nRocksDB, Cassandra\n\n\nåŸåœ°æ›´æ–° (B-Tree)\nè¯»å–ä¼˜åŒ–\nMySQL, PostgreSQL\n\n\nLSM-Tree ç»“æ„Level 0 (å†…å­˜):â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”‚  Memtable  â”‚ â† å½“å‰å†™å…¥ï¼ˆå¹³è¡¡æ ‘ï¼‰â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â†“ è¾¾åˆ°é˜ˆå€¼ï¼Œå†™å…¥ç£ç›˜Level 1-N (ç£ç›˜):â”Œâ”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”â”‚SS1 â”‚ â”‚SS2 â”‚ â”‚SS3 â”‚ â† SSTableï¼ˆæ’åºé”®ï¼‰â””â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”˜\n\nè¯»å–æµç¨‹ï¼šMemtable â†’ æœ€æ–° SSTable â†’ â€¦ â†’ æœ€è€ SSTable\nä¼˜åŒ–æŠ€æœ¯ï¼š\n\nå¸ƒéš†è¿‡æ»¤å™¨ï¼šå¿«é€Ÿåˆ¤æ–­é”®æ˜¯å¦å­˜åœ¨\nå‹ç¼©ç­–ç•¥ï¼šSize-Tieredï¼ˆå†™å¯†é›†ï¼‰ã€Leveledï¼ˆè¯»å¯†é›†ï¼‰\n\nB-Tree ç»“æ„          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”‚    [30, 70]   â”‚ â† æ ¹èŠ‚ç‚¹          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         /       â”‚        \\â”Œâ”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”â”‚[10,20]â”‚  â”‚[40,50,60] â”‚  â”‚[80,90]â”‚ â† å¶å­èŠ‚ç‚¹â””â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”˜\n\nWAL (é¢„å†™æ—¥å¿—)ï¼šå…ˆå†™æ—¥å¿—ï¼Œå†æ›´æ–°æ•°æ®ï¼Œä¿è¯å´©æºƒæ¢å¤\nB-Tree vs LSM-Tree\n\n\nç‰¹æ€§\nB-Tree\nLSM-Tree\n\n\n\nå†™å…¥\nåŸåœ°æ›´æ–°\nè¿½åŠ å†™å…¥\n\n\nè¯»å–\nå¿«ï¼ˆä¸€æ¬¡å®šä½ï¼‰\nå¯èƒ½æ£€æŸ¥å¤šä¸ªæ–‡ä»¶\n\n\nå†™æ”¾å¤§\nè¾ƒä½\nè¾ƒé«˜ï¼ˆå‹ç¼©å¼€é”€ï¼‰\n\n\nç©ºé—´åˆ©ç”¨\nå¯èƒ½ç¢ç‰‡åŒ–\næ›´ç´§å‡‘\n\n\nOLTP vs OLAP\n\n\nç‰¹æ€§\nOLTP\nOLAP\n\n\n\næ“ä½œ\nå¢åˆ æ”¹æŸ¥\nå¤æ‚æŸ¥è¯¢ã€èšåˆ\n\n\næ•°æ®é‡\nGB~TB\nTB~PB\n\n\nç”¨æˆ·\nåº”ç”¨ç¨‹åº\nåˆ†æå¸ˆ\n\n\nå­˜å‚¨\nè¡Œå­˜å‚¨\nåˆ—å­˜å‚¨\n\n\nåˆ—å­˜å‚¨ä¼˜åŠ¿ï¼šåªè¯»å–éœ€è¦çš„åˆ—ã€å‹ç¼©å‹å¥½ã€å‘é‡åŒ–å¤„ç†\n\nç¬¬4ç« ï¼šæ•°æ®ç¼–ç ä¸æ¼”åŒ–å…¼å®¹æ€§æ¦‚å¿µæ—¶é—´çº¿: v1 â”€â”€&gt; v2 â”€â”€&gt; v3 â”€â”€&gt; v4åå‘å…¼å®¹ï¼šæ–°ä»£ç èƒ½è¯»å–æ—§æ•°æ® (v3 è¯» v1 æ•°æ® âœ“)å‰å‘å…¼å®¹ï¼šæ—§ä»£ç èƒ½è¯»å–æ–°æ•°æ® (v1 è¯» v3 æ•°æ® âœ“)\n\næ»šåŠ¨å‡çº§ï¼šæ–°æ—§ç‰ˆæœ¬ä»£ç åŒæ—¶è¿è¡Œï¼Œéœ€è¦åŒå‘å…¼å®¹\nç¼–ç æ ¼å¼å¯¹æ¯”\n\n\næ ¼å¼\nå¯è¯»æ€§\nç©ºé—´æ•ˆç‡\næ¨¡å¼æ¼”åŒ–\n\n\n\nJSON\né«˜\nä½\næ‰‹åŠ¨\n\n\nProtobuf\næ— \né«˜\næ”¯æŒ\n\n\nThrift\næ— \né«˜\næ”¯æŒ\n\n\nAvro\næ— \næœ€é«˜\næ”¯æŒ\n\n\nProtocol Buffersmessage Person {  required string user_name = 1;  optional int64 favorite_number = 2;  repeated string interests = 3;}\n\nå…³é”®è§„åˆ™ï¼šå­—æ®µåå¯æ”¹ï¼Œå­—æ®µæ ‡ç­¾ï¼ˆæ•°å­—ï¼‰ä¸èƒ½æ”¹\nå…¼å®¹æ€§è§„åˆ™ï¼š\n\n\n\næ“ä½œ\nåå‘å…¼å®¹\nå‰å‘å…¼å®¹\n\n\n\næ·»åŠ å¯é€‰å­—æ®µ\nâœ“\nâœ“\n\n\nåˆ é™¤å¯é€‰å­—æ®µ\nâœ“\nâœ“\n\n\næ·»åŠ å¿…å¡«å­—æ®µ\nâœ—\nâœ—\n\n\nAvroç‰¹ç‚¹ï¼šè¯»å†™æ¨¡å¼åˆ†ç¦»ï¼Œä¸å­˜å‚¨å­—æ®µæ ‡ç­¾ï¼Œæ›´ç´§å‡‘\n{  \"type\": \"record\",  \"name\": \"Person\",  \"fields\": [    {\"name\": \"userName\", \"type\": \"string\"},    {\"name\": \"favoriteNumber\", \"type\": [\"null\", \"long\"], \"default\": null}  ]}\n\næ•°æ®æµæ¨¡å¼\n\n\næ¨¡å¼\nåœºæ™¯\nå…¼å®¹æ€§è€ƒè™‘\n\n\n\næ•°æ®åº“\næŒä¹…å­˜å‚¨\næ•°æ®å¯èƒ½æ¯”ä»£ç æ›´æŒä¹…\n\n\næœåŠ¡è°ƒç”¨\nREST/RPC\nAPI ç‰ˆæœ¬æ§åˆ¶\n\n\næ¶ˆæ¯ä¼ é€’\né˜Ÿåˆ—/Actor\nç”Ÿäº§è€…æ¶ˆè´¹è€…è§£è€¦\n\n\n\næœ¬éƒ¨åˆ†è¦ç‚¹æ€»ç»“\nå¯é æ€§ã€å¯æ‰©å±•æ€§ã€å¯ç»´æŠ¤æ€§æ˜¯ä¼˜ç§€ç³»ç»Ÿçš„ä¸‰å¤§æ”¯æŸ±\næ•°æ®æ¨¡å‹é€‰æ‹©å–å†³äºæ•°æ®ç»“æ„å’ŒæŸ¥è¯¢éœ€æ±‚\nLSM-Tree ä¼˜åŒ–å†™å…¥ï¼ŒB-Tree ä¼˜åŒ–è¯»å–\nåˆ—å­˜å‚¨é€‚åˆ OLAPï¼Œè¡Œå­˜å‚¨é€‚åˆ OLTP\näºŒè¿›åˆ¶ç¼–ç æ¯” JSON æ›´ç´§å‡‘é«˜æ•ˆ\næ¨¡å¼æ¼”åŒ–éœ€è¦ä¿è¯å‰å‘å’Œåå‘å…¼å®¹\n\n\nè¿”å›æ€»è§ˆ | ä¸‹ä¸€éƒ¨åˆ†ï¼šåˆ†å¸ƒå¼æ•°æ®\n","categories":["è¯»ä¹¦ç¬”è®°"],"tags":["DDIA","æ•°æ®åº“","å­˜å‚¨å¼•æ“","æ•°æ®æ¨¡å‹"]},{"title":"å› æœå…³ç³»æ¨æ–­ä»‹ç»","url":"/2019/10/03/%E5%9B%A0%E6%9E%9C%E5%85%B3%E7%B3%BB%E6%8E%A8%E6%96%AD%E4%BB%8B%E7%BB%8D/","content":"å› æœæ¨æ–­æ˜¯æœºå™¨å­¦ä¹ é¢†åŸŸçš„é‡è¦ç ”ç©¶æ–¹å‘ï¼Œç‰¹åˆ«æ˜¯åœ¨å¤§è¯­è¨€æ¨¡å‹æ—¶ä»£ï¼Œç†è§£å› æœå…³ç³»å¯¹äºæ„å»ºå¯è§£é‡Šã€å¯ä¿¡èµ–çš„ AI ç³»ç»Ÿè‡³å…³é‡è¦ã€‚\nä¸ºä»€ä¹ˆéœ€è¦å› æœæ¨æ–­ï¼Ÿä¼ ç»Ÿæœºå™¨å­¦ä¹ ä¾èµ–ç›¸å…³æ€§ï¼Œä½†ç›¸å…³æ€§ä¸ç­‰äºå› æœæ€§ã€‚ä¾‹å¦‚ï¼š\n\nå†°æ·‡æ·‹é”€é‡ä¸æººæ°´äº‹ä»¶æ­£ç›¸å…³ï¼ˆå…±åŒåŸå› ï¼šå¤å¤©ï¼‰\nLLM å¯èƒ½å­¦åˆ°è™šå‡ç›¸å…³æ€§ï¼Œå¯¼è‡´ hallucination\n\nå› æœæ¨æ–­å¸®åŠ©æˆ‘ä»¬ï¼š\n\nç†è§£å¹²é¢„æ•ˆæœï¼ˆå¦‚æœæˆ‘åš Xï¼Œä¼šå‘ç”Ÿä»€ä¹ˆï¼Ÿï¼‰\nè¿›è¡Œåäº‹å®æ¨ç†ï¼ˆå¦‚æœå½“æ—¶åšäº† Yï¼Œç»“æœä¼šæ€æ ·ï¼Ÿï¼‰\næ„å»ºæ›´é²æ£’çš„æ¨¡å‹\n\næ ¸å¿ƒæ¦‚å¿µå› æœå›¾ (Causal Graph)ä½¿ç”¨æœ‰å‘æ— ç¯å›¾ (DAG) è¡¨ç¤ºå˜é‡ä¹‹é—´çš„å› æœå…³ç³»ï¼š\nX â†’ Y â†’ Z    (é“¾å¼ç»“æ„)X â† W â†’ Y    (æ··æ‚ç»“æ„)  X â†’ W â† Y    (å¯¹æ’ç»“æ„)\n\nç»“æ„å› æœæ¨¡å‹ (SCM)\nå…¶ä¸­  æ˜¯åŸå› ï¼Œ æ˜¯ç»“æœï¼Œ æ˜¯å™ªå£°é¡¹ã€‚\ndo ç®—å­ä¸å¹²é¢„åŒºåˆ†è§‚æµ‹å’Œå¹²é¢„ï¼š\n\nè§‚æµ‹ï¼š â€” çœ‹åˆ° X=x æ—¶ Y çš„åˆ†å¸ƒ\nå¹²é¢„ï¼š â€” å¼ºåˆ¶è®¾ç½® X=x æ—¶ Y çš„åˆ†å¸ƒ\n\nå› æœå‘ç°ç®—æ³•PC ç®—æ³•åŸºäºæ¡ä»¶ç‹¬ç«‹æ€§æ£€éªŒçš„ç»å…¸ç®—æ³•ï¼š\n# PC ç®—æ³•ä¼ªä»£ç def pc_algorithm(data, alpha=0.05):    # 1. åˆå§‹åŒ–å®Œå…¨å›¾    G = complete_graph(variables)        # 2. éª¨æ¶å­¦ä¹ ï¼šç§»é™¤æ¡ä»¶ç‹¬ç«‹çš„è¾¹    for (X, Y) in edges(G):        for S in subsets(neighbors):            if conditional_independent(X, Y, S, alpha):                remove_edge(G, X, Y)                sep_set[X, Y] = S        # 3. æ–¹å‘ç¡®å®šï¼šè¯†åˆ« v-structure    orient_v_structures(G, sep_set)        return G\n\nPython å®ç°å‚è€ƒï¼šfooSynaptic/py_pcalg\nç°ä»£æ–¹æ³•\n\n\næ–¹æ³•\nç‰¹ç‚¹\né€‚ç”¨åœºæ™¯\n\n\n\nNOTEARS\nè¿ç»­ä¼˜åŒ–ï¼Œå¯å¾®åˆ†\nçº¿æ€§/éçº¿æ€§å› æœå‘ç°\n\n\nDAG-GNN\nåŸºäºå›¾ç¥ç»ç½‘ç»œ\nå¤§è§„æ¨¡å› æœå›¾å­¦ä¹ \n\n\nCausal Transformer\nç»“åˆæ³¨æ„åŠ›æœºåˆ¶\næ—¶åºå› æœæ¨æ–­\n\n\nå› æœæ¨æ–­ä¸å¤§è¯­è¨€æ¨¡å‹LLM ä¸­çš„å› æœé—®é¢˜\nHallucinationï¼šæ¨¡å‹å­¦åˆ°è™šå‡ç›¸å…³æ€§\nBiasï¼šè®­ç»ƒæ•°æ®ä¸­çš„æ··æ‚å› ç´ \nRobustnessï¼šåˆ†å¸ƒå¤–æ³›åŒ–èƒ½åŠ›å·®\n\nè§£å†³æ–¹æ¡ˆ# å› æœæç¤º (Causal Prompting) ç¤ºä¾‹prompt = \"\"\"è¯·åˆ†æä»¥ä¸‹äº‹ä»¶çš„å› æœå…³ç³»ï¼Œè€Œéç›¸å…³æ€§ï¼šäº‹ä»¶A: å…¬å¸å¢åŠ å¹¿å‘ŠæŠ•å…¥äº‹ä»¶B: é”€å”®é¢ä¸Šå‡é—®ï¼šA æ˜¯å¦å¯¼è‡´äº† Bï¼Ÿè¯·è€ƒè™‘å¯èƒ½çš„æ··æ‚å› ç´ ã€‚\"\"\"\n\nå› æœæ¨ç†å¢å¼º RAGclass CausalRAG:    def __init__(self, retriever, causal_graph):        self.retriever = retriever        self.causal_graph = causal_graph        def retrieve(self, query):        # 1. è¯†åˆ«æŸ¥è¯¢ä¸­çš„å› æœå…³ç³»        cause, effect = extract_causal_pair(query)                # 2. åŸºäºå› æœå›¾è¿‡æ»¤æ— å…³æ–‡æ¡£        relevant_vars = self.causal_graph.ancestors(effect)                # 3. æ£€ç´¢å› æœç›¸å…³çš„æ–‡æ¡£        docs = self.retriever.search(query)        return filter_by_causal_relevance(docs, relevant_vars)\n\nå·¥å…·ä¸èµ„æº\n\n\nå·¥å…·\nè¯­è¨€\nåŠŸèƒ½\n\n\n\nDoWhy\nPython\nå› æœæ¨æ–­æ¡†æ¶\n\n\nCausalNex\nPython\nè´å¶æ–¯ç½‘ç»œ + å› æœå‘ç°\n\n\npgmpy\nPython\næ¦‚ç‡å›¾æ¨¡å‹\n\n\nTetrad\nJava\nå› æœæœç´¢ç®—æ³•\n\n\n# DoWhy ç¤ºä¾‹import dowhyfrom dowhy import CausalModelmodel = CausalModel(    data=df,    treatment='treatment',    outcome='outcome',    graph='digraph {treatment -&gt; outcome; confounder -&gt; treatment; confounder -&gt; outcome}')# è¯†åˆ«å› æœæ•ˆåº”identified = model.identify_effect()# ä¼°è®¡å› æœæ•ˆåº”estimate = model.estimate_effect(identified, method_name=\"backdoor.propensity_score_matching\")\n\nå»¶ä¼¸é˜…è¯»\nJudea Pearl, The Book of Why (2018)\nPeters et al., Elements of Causal Inference (2017)\nStanford CS 228: Probabilistic Graphical Models\n\n\n\nè½¬è½½è¯·æ³¨æ˜å‡ºå¤„\n\n","tags":["machine learning","bayesian network","causality infer"]},{"title":"MRC æ¨¡å‹å®ç°ï¼šä» TensorFlow åˆ° PyTorch","url":"/2019/11/19/%E5%A6%82%E4%BD%95%E6%95%99%E4%BC%9A%E6%9C%BA%E5%99%A8%E5%8E%BB%E7%90%86%E8%A7%A3%E9%97%AE%E9%A2%98%E5%92%8C%E6%96%87%E6%9C%AC%E5%B9%B6%E4%B8%94%E5%9B%9E%E7%AD%94%E9%97%AE%E9%A2%98%EF%BC%88tensorflow%E5%AE%9E%E6%88%98%EF%BC%89/","content":"æœ¬æ–‡ä»‹ç»æœºå™¨é˜…è¯»ç†è§£æ¨¡å‹çš„å®Œæ•´å®ç°ï¼Œæ¶µç›–ç»å…¸æ¶æ„å’Œç°ä»£æœ€ä½³å®è·µã€‚\né—®é¢˜å®šä¹‰è¾“å…¥ï¼š\n\né—®é¢˜ \næ–‡æ¡£ \n\nè¾“å‡ºï¼š\n\nç­”æ¡ˆèµ·å§‹ä½ç½® \nç­”æ¡ˆç»“æŸä½ç½® \n\nç»å…¸æ¶æ„Input â†’ Embedding â†’ Encoding â†’ Matching â†’ Fusion â†’ Decoding\n\nå„å±‚è¯¦è§£\n\n\nå±‚\nåŠŸèƒ½\nç°ä»£æ›¿ä»£\n\n\n\nEmbedding\nToken â†’ Vector\nSubword Tokenization\n\n\nEncoding\nåºåˆ—ç¼–ç \nTransformer Encoder\n\n\nMatching\nQ-P äº¤äº’\nCross-Attention\n\n\nFusion\nä¿¡æ¯èåˆ\nSelf-Attention\n\n\nDecoding\nSpan é¢„æµ‹\nLinear + Softmax\n\n\nPyTorch å®ç°å®Œæ•´æ¨¡å‹import torchimport torch.nn as nnimport torch.nn.functional as Ffrom transformers import AutoModel, AutoTokenizerclass MRCModel(nn.Module):    \"\"\"åŸºäº Transformer çš„ MRC æ¨¡å‹\"\"\"        def __init__(        self,         model_name: str = \"bert-base-chinese\",        dropout: float = 0.1,        max_answer_length: int = 30    ):        super().__init__()        self.encoder = AutoModel.from_pretrained(model_name)        hidden_size = self.encoder.config.hidden_size        self.max_answer_length = max_answer_length                self.dropout = nn.Dropout(dropout)        self.start_fc = nn.Linear(hidden_size, 1)        self.end_fc = nn.Linear(hidden_size, 1)        def forward(        self,        input_ids: torch.Tensor,        attention_mask: torch.Tensor,        token_type_ids: torch.Tensor = None,        start_positions: torch.Tensor = None,        end_positions: torch.Tensor = None,    ):        # ç¼–ç         outputs = self.encoder(            input_ids=input_ids,            attention_mask=attention_mask,            token_type_ids=token_type_ids,        )        sequence_output = self.dropout(outputs.last_hidden_state)                # é¢„æµ‹ start/end        start_logits = self.start_fc(sequence_output).squeeze(-1)        end_logits = self.end_fc(sequence_output).squeeze(-1)                # Mask padding        mask = attention_mask.bool()        start_logits = start_logits.masked_fill(~mask, float('-inf'))        end_logits = end_logits.masked_fill(~mask, float('-inf'))                # è®¡ç®—æŸå¤±        loss = None        if start_positions is not None and end_positions is not None:            loss_fct = nn.CrossEntropyLoss(ignore_index=-1)            start_loss = loss_fct(start_logits, start_positions)            end_loss = loss_fct(end_logits, end_positions)            loss = (start_loss + end_loss) / 2                return {            'loss': loss,            'start_logits': start_logits,            'end_logits': end_logits,        }        def decode(        self,        start_logits: torch.Tensor,        end_logits: torch.Tensor,        attention_mask: torch.Tensor,    ):        \"\"\"è§£ç æœ€ä½³ç­”æ¡ˆ span\"\"\"        batch_size, seq_len = start_logits.shape                # è®¡ç®—æ‰€æœ‰æœ‰æ•ˆ (start, end) å¯¹çš„åˆ†æ•°        start_probs = F.softmax(start_logits, dim=-1)        end_probs = F.softmax(end_logits, dim=-1)                results = []        for b in range(batch_size):            best_score = float('-inf')            best_start, best_end = 0, 0                        for start in range(seq_len):                if not attention_mask[b, start]:                    continue                for end in range(start, min(start + self.max_answer_length, seq_len)):                    if not attention_mask[b, end]:                        continue                    score = start_probs[b, start] * end_probs[b, end]                    if score &gt; best_score:                        best_score = score                        best_start, best_end = start, end                        results.append((best_start, best_end))                return results\n\næ•°æ®å¤„ç†from dataclasses import dataclassfrom typing import List, Optionalimport json@dataclassclass MRCExample:    qid: str    question: str    context: str    answer: Optional[str] = None    start_position: Optional[int] = None@dataclassclass MRCFeature:    input_ids: List[int]    attention_mask: List[int]    token_type_ids: List[int]    start_position: int    end_position: int    offset_mapping: List[tuple]class MRCProcessor:    def __init__(self, model_name: str, max_length: int = 512):        self.tokenizer = AutoTokenizer.from_pretrained(model_name)        self.max_length = max_length        def process(self, example: MRCExample) -&gt; MRCFeature:        encoding = self.tokenizer(            example.question,            example.context,            max_length=self.max_length,            truncation='only_second',            return_offsets_mapping=True,            padding='max_length',        )                # å®šä½ç­”æ¡ˆä½ç½®        start_token, end_token = 0, 0        if example.start_position is not None:            offset = encoding['offset_mapping']            for idx, (start, end) in enumerate(offset):                if start &lt;= example.start_position &lt; end:                    start_token = idx                if start &lt; example.start_position + len(example.answer) &lt;= end:                    end_token = idx                    break                return MRCFeature(            input_ids=encoding['input_ids'],            attention_mask=encoding['attention_mask'],            token_type_ids=encoding.get('token_type_ids', [0] * len(encoding['input_ids'])),            start_position=start_token,            end_position=end_token,            offset_mapping=encoding['offset_mapping'],        )\n\nè®­ç»ƒå¾ªç¯from torch.utils.data import DataLoaderfrom torch.optim import AdamWfrom transformers import get_schedulerfrom tqdm import tqdmdef train_epoch(model, dataloader, optimizer, scheduler, device):    model.train()    total_loss = 0        for batch in tqdm(dataloader, desc=\"Training\"):        batch = {k: v.to(device) for k, v in batch.items()}                outputs = model(**batch)        loss = outputs['loss']                loss.backward()        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)                optimizer.step()        scheduler.step()        optimizer.zero_grad()                total_loss += loss.item()        return total_loss / len(dataloader)def evaluate(model, dataloader, device):    model.eval()    predictions = []        with torch.no_grad():        for batch in tqdm(dataloader, desc=\"Evaluating\"):            batch = {k: v.to(device) for k, v in batch.items()}                        outputs = model(                input_ids=batch['input_ids'],                attention_mask=batch['attention_mask'],                token_type_ids=batch.get('token_type_ids'),            )                        spans = model.decode(                outputs['start_logits'],                outputs['end_logits'],                batch['attention_mask'],            )            predictions.extend(spans)        return predictions# ä¸»è®­ç»ƒæµç¨‹def main():    # é…ç½®    model_name = \"bert-base-chinese\"    batch_size = 16    learning_rate = 3e-5    num_epochs = 3        # åˆå§‹åŒ–    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')    model = MRCModel(model_name).to(device)        # ä¼˜åŒ–å™¨    optimizer = AdamW(model.parameters(), lr=learning_rate, weight_decay=0.01)    scheduler = get_scheduler(        \"linear\",        optimizer=optimizer,        num_warmup_steps=500,        num_training_steps=num_epochs * len(train_dataloader),    )        # è®­ç»ƒ    for epoch in range(num_epochs):        loss = train_epoch(model, train_dataloader, optimizer, scheduler, device)        print(f\"Epoch {epoch+1}, Loss: {loss:.4f}\")                # éªŒè¯        predictions = evaluate(model, val_dataloader, device)        f1 = compute_f1(predictions, val_labels)        print(f\"Validation F1: {f1:.4f}\")\n\nè¯„ä¼°æŒ‡æ ‡import reimport stringfrom collections import Counterdef normalize_answer(s: str) -&gt; str:    \"\"\"æ ‡å‡†åŒ–ç­”æ¡ˆæ–‡æœ¬\"\"\"    s = s.lower()    s = re.sub(r'\\b(a|an|the)\\b', ' ', s)    s = ''.join(ch for ch in s if ch not in string.punctuation)    s = ' '.join(s.split())    return sdef compute_f1(prediction: str, ground_truth: str) -&gt; float:    pred_tokens = normalize_answer(prediction).split()    gold_tokens = normalize_answer(ground_truth).split()        if not pred_tokens or not gold_tokens:        return int(pred_tokens == gold_tokens)        common = Counter(pred_tokens) &amp; Counter(gold_tokens)    num_same = sum(common.values())        precision = num_same / len(pred_tokens)    recall = num_same / len(gold_tokens)        if precision + recall == 0:        return 0        return 2 * precision * recall / (precision + recall)def compute_em(prediction: str, ground_truth: str) -&gt; float:    return float(normalize_answer(prediction) == normalize_answer(ground_truth))\n\nä¸ç°ä»£æ–¹æ³•å¯¹æ¯”\n\n\næ–¹é¢\nç»å…¸ MRC (BiDAF)\nBERT-based\nLLM-based\n\n\n\nå‚æ•°é‡\n~2M\n110M-340M\n7B-70B+\n\n\nè®­ç»ƒæ•°æ®\nTask-specific\né¢„è®­ç»ƒ+å¾®è°ƒ\nå¤§è§„æ¨¡é¢„è®­ç»ƒ\n\n\næ¨ç†æ–¹å¼\nSpan extraction\nSpan extraction\nGeneration\n\n\né•¿æ–‡æ¡£\néœ€è¦åˆ‡åˆ†\néœ€è¦åˆ‡åˆ†\næ›´å¤§ä¸Šä¸‹æ–‡çª—å£\n\n\nå¤šè·³æ¨ç†\nå›°éš¾\næœ‰é™\nè¾ƒå¥½\n\n\nç”Ÿäº§ç¯å¢ƒä¼˜åŒ–é‡åŒ–æ¨ç†import torch.quantization as quant# åŠ¨æ€é‡åŒ–model_int8 = quant.quantize_dynamic(    model.cpu(),    {nn.Linear},    dtype=torch.qint8)\n\nONNX å¯¼å‡ºimport torch.onnxdummy_input = {    'input_ids': torch.ones(1, 512, dtype=torch.long),    'attention_mask': torch.ones(1, 512, dtype=torch.long),    'token_type_ids': torch.zeros(1, 512, dtype=torch.long),}torch.onnx.export(    model,    (dummy_input['input_ids'], dummy_input['attention_mask'], dummy_input['token_type_ids']),    \"mrc_model.onnx\",    input_names=['input_ids', 'attention_mask', 'token_type_ids'],    output_names=['start_logits', 'end_logits'],    dynamic_axes={        'input_ids': {0: 'batch', 1: 'seq'},        'attention_mask': {0: 'batch', 1: 'seq'},        'token_type_ids': {0: 'batch', 1: 'seq'},    })\n\nå»¶ä¼¸é˜…è¯»\nHugging Face Question Answering\nSQuAD Leaderboard\nCMRC 2018 ä¸­æ–‡é˜…è¯»ç†è§£\n\n\n\nè½¬è½½è¯·æ³¨æ˜å‡ºå¤„\n\n","tags":["MRC","Deep learning","PyTorch"]},{"title":"æœºå™¨é˜…è¯»ç†è§£å®æˆ˜ï¼šä»é›¶æ„å»ºé—®ç­”ç³»ç»Ÿ","url":"/2019/11/19/%E5%A6%82%E4%BD%95%E6%95%99%E4%BC%9A%E6%9C%BA%E5%99%A8%E7%90%86%E8%A7%A3%E9%97%AE%E9%A2%98%EF%BC%9A%E4%BB%8E%E9%9B%B6%E5%BC%80%E5%A7%8B%E7%9A%84%E6%9C%BA%E5%99%A8%E9%98%85%E8%AF%BB%E7%90%86%E8%A7%A3%E5%AE%9E%E8%B7%B5/","content":"æœ¬æ–‡ä»é›¶å¼€å§‹å®ç°ä¸€ä¸ªæœºå™¨é˜…è¯»ç†è§£ç³»ç»Ÿï¼Œæ¶µç›–æ•°æ®å¤„ç†ã€æ¨¡å‹æ„å»ºã€è®­ç»ƒå’Œæ¨ç†çš„å®Œæ•´æµç¨‹ã€‚\nä»»åŠ¡å®šä¹‰ç»™å®šä¸Šä¸‹æ–‡  å’Œé—®é¢˜ ï¼Œé¢„æµ‹ç­”æ¡ˆ  åœ¨  ä¸­çš„ä½ç½®ï¼š\n\næ•°æ®å¤„ç†SQuAD æ•°æ®æ ¼å¼import jsonfrom dataclasses import dataclassfrom typing import List, Optional@dataclassclass Example:    context: str    question: str    answer_text: str    start_position: int    end_position: intdef load_squad(file_path: str) -&gt; List[Example]:    with open(file_path, 'r', encoding='utf-8') as f:        data = json.load(f)        examples = []    for article in data['data']:        for paragraph in article['paragraphs']:            context = paragraph['context']            for qa in paragraph['qas']:                question = qa['question']                if qa.get('is_impossible', False):                    continue                answer = qa['answers'][0]                examples.append(Example(                    context=context,                    question=question,                    answer_text=answer['text'],                    start_position=answer['answer_start'],                    end_position=answer['answer_start'] + len(answer['text'])                ))        return examples\n\nTokenizationfrom transformers import AutoTokenizerclass MRCTokenizer:    def __init__(self, model_name: str, max_length: int = 384, doc_stride: int = 128):        self.tokenizer = AutoTokenizer.from_pretrained(model_name)        self.max_length = max_length        self.doc_stride = doc_stride        def encode(self, example: Example):        # Tokenize question and context        encoding = self.tokenizer(            example.question,            example.context,            max_length=self.max_length,            truncation='only_second',            stride=self.doc_stride,            return_overflowing_tokens=True,            return_offsets_mapping=True,            padding='max_length',        )                # æ‰¾åˆ°ç­”æ¡ˆåœ¨ token åºåˆ—ä¸­çš„ä½ç½®        offset_mapping = encoding['offset_mapping'][0]                start_token = None        end_token = None                for idx, (start, end) in enumerate(offset_mapping):            if start &lt;= example.start_position &lt; end:                start_token = idx            if start &lt; example.end_position &lt;= end:                end_token = idx                break                return {            'input_ids': encoding['input_ids'][0],            'attention_mask': encoding['attention_mask'][0],            'start_position': start_token or 0,            'end_position': end_token or 0,        }\n\næ¨¡å‹å®ç°åŸºäº BERT çš„ MRC æ¨¡å‹import torchimport torch.nn as nnfrom transformers import AutoModelclass MRCModel(nn.Module):    def __init__(self, model_name: str, dropout: float = 0.1):        super().__init__()        self.bert = AutoModel.from_pretrained(model_name)        hidden_size = self.bert.config.hidden_size                self.dropout = nn.Dropout(dropout)        self.start_classifier = nn.Linear(hidden_size, 1)        self.end_classifier = nn.Linear(hidden_size, 1)        def forward(        self,        input_ids: torch.Tensor,        attention_mask: torch.Tensor,        start_positions: Optional[torch.Tensor] = None,        end_positions: Optional[torch.Tensor] = None,    ):        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)        sequence_output = self.dropout(outputs.last_hidden_state)                # (batch, seq_len, 1) -&gt; (batch, seq_len)        start_logits = self.start_classifier(sequence_output).squeeze(-1)        end_logits = self.end_classifier(sequence_output).squeeze(-1)                # Mask padding tokens        start_logits = start_logits.masked_fill(~attention_mask.bool(), -1e9)        end_logits = end_logits.masked_fill(~attention_mask.bool(), -1e9)                loss = None        if start_positions is not None and end_positions is not None:            loss_fct = nn.CrossEntropyLoss()            start_loss = loss_fct(start_logits, start_positions)            end_loss = loss_fct(end_logits, end_positions)            loss = (start_loss + end_loss) / 2                return {            'loss': loss,            'start_logits': start_logits,            'end_logits': end_logits,        }\n\næ”¹è¿›ï¼šè”åˆ Start-End é¢„æµ‹class JointMRCModel(nn.Module):    \"\"\"è”åˆé¢„æµ‹ start å’Œ endï¼Œè€ƒè™‘ start-end ä¾èµ–\"\"\"        def __init__(self, model_name: str, max_answer_length: int = 30):        super().__init__()        self.bert = AutoModel.from_pretrained(model_name)        hidden_size = self.bert.config.hidden_size        self.max_answer_length = max_answer_length                self.start_classifier = nn.Linear(hidden_size, 1)        self.end_classifier = nn.Linear(hidden_size * 2, 1)        def forward(self, input_ids, attention_mask, start_positions=None, end_positions=None):        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)        H = outputs.last_hidden_state  # (batch, seq_len, hidden)                # Start prediction        start_logits = self.start_classifier(H).squeeze(-1)                if self.training and start_positions is not None:            # è®­ç»ƒæ—¶ä½¿ç”¨çœŸå®çš„ start ä½ç½®            start_indices = start_positions.unsqueeze(-1).unsqueeze(-1)            start_repr = H.gather(1, start_indices.expand(-1, -1, H.size(-1))).squeeze(1)        else:            # æ¨ç†æ—¶ä½¿ç”¨é¢„æµ‹çš„ start ä½ç½®            start_indices = start_logits.argmax(dim=-1, keepdim=True).unsqueeze(-1)            start_repr = H.gather(1, start_indices.expand(-1, -1, H.size(-1))).squeeze(1)                # End prediction conditioned on start        start_repr_expanded = start_repr.unsqueeze(1).expand(-1, H.size(1), -1)        end_input = torch.cat([H, start_repr_expanded], dim=-1)        end_logits = self.end_classifier(end_input).squeeze(-1)                # åªå…è®¸ end &gt;= start ä¸”åœ¨ max_answer_length èŒƒå›´å†…        # è¿™é‡Œç®€åŒ–å¤„ç†ï¼Œå®Œæ•´å®ç°éœ€è¦æ›´å¤æ‚çš„ mask                return {'start_logits': start_logits, 'end_logits': end_logits}\n\nè®­ç»ƒæµç¨‹from torch.utils.data import DataLoader, Datasetfrom transformers import get_linear_schedule_with_warmupfrom tqdm import tqdmdef train(model, train_dataloader, val_dataloader, epochs=3, lr=3e-5):    optimizer = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=0.01)        total_steps = len(train_dataloader) * epochs    scheduler = get_linear_schedule_with_warmup(        optimizer,         num_warmup_steps=int(0.1 * total_steps),        num_training_steps=total_steps    )        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')    model.to(device)        best_f1 = 0    for epoch in range(epochs):        model.train()        total_loss = 0                for batch in tqdm(train_dataloader, desc=f'Epoch {epoch+1}'):            batch = {k: v.to(device) for k, v in batch.items()}                        outputs = model(**batch)            loss = outputs['loss']                        loss.backward()            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)                        optimizer.step()            scheduler.step()            optimizer.zero_grad()                        total_loss += loss.item()                avg_loss = total_loss / len(train_dataloader)        print(f'Epoch {epoch+1}, Loss: {avg_loss:.4f}')                # Validation        f1 = evaluate(model, val_dataloader, device)        print(f'Validation F1: {f1:.4f}')                if f1 &gt; best_f1:            best_f1 = f1            torch.save(model.state_dict(), 'best_model.pt')        return model\n\nè¯„ä¼°ä¸æ¨ç†import reimport stringfrom collections import Counterdef normalize_answer(s):    \"\"\"æ ‡å‡†åŒ–ç­”æ¡ˆç”¨äºè¯„ä¼°\"\"\"    def remove_articles(text):        return re.sub(r'\\b(a|an|the)\\b', ' ', text)        def white_space_fix(text):        return ' '.join(text.split())        def remove_punc(text):        exclude = set(string.punctuation)        return ''.join(ch for ch in text if ch not in exclude)        def lower(text):        return text.lower()        return white_space_fix(remove_articles(remove_punc(lower(s))))def compute_f1(pred: str, gold: str) -&gt; float:    pred_tokens = normalize_answer(pred).split()    gold_tokens = normalize_answer(gold).split()        common = Counter(pred_tokens) &amp; Counter(gold_tokens)    num_same = sum(common.values())        if num_same == 0:        return 0        precision = num_same / len(pred_tokens)    recall = num_same / len(gold_tokens)        return 2 * precision * recall / (precision + recall)def predict(model, tokenizer, context: str, question: str, device):    \"\"\"å•æ¡æ¨ç†\"\"\"    model.eval()        encoding = tokenizer(        question, context,        max_length=384,        truncation='only_second',        return_tensors='pt'    )        encoding = {k: v.to(device) for k, v in encoding.items()}        with torch.no_grad():        outputs = model(**encoding)        start_idx = outputs['start_logits'].argmax().item()    end_idx = outputs['end_logits'].argmax().item()        # ç¡®ä¿ end &gt;= start    if end_idx &lt; start_idx:        end_idx = start_idx        # è§£ç ç­”æ¡ˆ    answer_tokens = encoding['input_ids'][0][start_idx:end_idx+1]    answer = tokenizer.decode(answer_tokens, skip_special_tokens=True)        return answer\n\nç°ä»£æ–¹æ³•ï¼šä½¿ç”¨ LLMå¯¹äºæ›´å¤æ‚çš„é—®ç­”éœ€æ±‚ï¼Œå¯ä»¥ä½¿ç”¨ LLMï¼š\nfrom openai import OpenAIdef llm_qa(context: str, question: str) -&gt; str:    client = OpenAI()        response = client.chat.completions.create(        model=\"gpt-4\",        messages=[            {\"role\": \"system\", \"content\": \"ä½ æ˜¯ä¸€ä¸ªé—®ç­”åŠ©æ‰‹ã€‚æ ¹æ®ç»™å®šçš„ä¸Šä¸‹æ–‡å›ç­”é—®é¢˜ã€‚å¦‚æœç­”æ¡ˆä¸åœ¨ä¸Šä¸‹æ–‡ä¸­ï¼Œè¯·è¯´'æ— æ³•å›ç­”'ã€‚\"},            {\"role\": \"user\", \"content\": f\"ä¸Šä¸‹æ–‡ï¼š{context}\\n\\né—®é¢˜ï¼š{question}\"}        ],        temperature=0    )        return response.choices[0].message.content\n\nå»¶ä¼¸é˜…è¯»\nSQuAD Dataset\nHugging Face QA Pipeline\nNatural Questions\n\n\n\nè½¬è½½è¯·æ³¨æ˜å‡ºå¤„\n\n","tags":["MRC","Deep learning","PyTorch"]},{"title":"LLM æ¸¸æˆæ™ºèƒ½ä½“è®ºæ–‡è§£è¯»ï¼šåŸºç¡€æ¡†æ¶ç¯‡","url":"/2025/12/28/LLM-Game-Agents-%E5%9F%BA%E7%A1%80%E6%A1%86%E6%9E%B6%E7%AF%87/","content":"æœ¬æ–‡æ·±å…¥è§£è¯» LLM æ™ºèƒ½ä½“é¢†åŸŸçš„ä¸‰å¤§åŸºç¡€æ¡†æ¶ï¼šReActã€Reflexion å’Œ Generative Agentsï¼Œåˆ†æå®ƒä»¬çš„æ ¸å¿ƒæ¶æ„ã€æŠ€æœ¯åˆ›æ–°å’Œåº”ç”¨åœºæ™¯ã€‚\n\nä¸€ã€ReActï¼šæ¨ç†ä¸è¡ŒåŠ¨çš„ååŒè®ºæ–‡: Synergizing Reasoning and Acting in Language Modelsä¼šè®®: ICLR 2023ä½œè€…: Shunyu Yao ç­‰ (æ™®æ—æ–¯é¡¿å¤§å­¦ &amp; Google Research)è¢«å¼•ç”¨: 32æ¬¡ï¼ˆé¢†åŸŸå†…æœ€é«˜ï¼‰\n1.1 æ ¸å¿ƒæ€æƒ³äººç±»æ™ºèƒ½çš„ä¸€ä¸ªç‹¬ç‰¹ç‰¹å¾æ˜¯èƒ½å¤Ÿæ— ç¼ç»“åˆé¢å‘ä»»åŠ¡çš„åŠ¨ä½œä¸è¯­è¨€æ¨ç†ã€‚è€ƒè™‘åœ¨å¨æˆ¿åšèœçš„ä¾‹å­ï¼š\n\nåœ¨ä»»ä½•ä¸¤ä¸ªå…·ä½“åŠ¨ä½œä¹‹é—´ï¼Œæˆ‘ä»¬å¯èƒ½ç”¨è¯­è¨€è¿›è¡Œæ¨ç†ï¼Œä»¥è·Ÿè¸ªè¿›åº¦\nå¤„ç†å¼‚å¸¸æˆ–æ ¹æ®æƒ…å†µè°ƒæ•´è®¡åˆ’\nè®¤è¯†åˆ°ä½•æ—¶éœ€è¦å¤–éƒ¨ä¿¡æ¯\n\nReAct çš„æ ¸å¿ƒç†å¿µï¼šå°†æ™ºèƒ½ä½“çš„åŠ¨ä½œç©ºé—´æ‰©å±•ä¸º Ã‚ = A âˆª L\nå…¶ä¸­ï¼š\n\nA = åŸå§‹åŠ¨ä½œç©ºé—´ï¼ˆä¸ç¯å¢ƒäº¤äº’ï¼‰\nL = è¯­è¨€ç©ºé—´ï¼ˆæ€æƒ³/æ¨ç†è½¨è¿¹ï¼‰\n\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”‚                    ReAct å·¥ä½œæµç¨‹                            â”‚â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤â”‚                                                             â”‚â”‚   é—®é¢˜ â”€â”€â–¶ æ€æƒ³1 â”€â”€â–¶ åŠ¨ä½œ1 â”€â”€â–¶ è§‚å¯Ÿ1                        â”‚â”‚                       â”‚                                     â”‚â”‚                       â–¼                                     â”‚â”‚            æ€æƒ³2 â”€â”€â–¶ åŠ¨ä½œ2 â”€â”€â–¶ è§‚å¯Ÿ2                        â”‚â”‚                       â”‚                                     â”‚â”‚                       â–¼                                     â”‚â”‚            æ€æƒ³3 â”€â”€â–¶ åŠ¨ä½œ3 â”€â”€â–¶ ç­”æ¡ˆ                         â”‚â”‚                                                             â”‚â”‚   æ€æƒ³ï¼šä¸å½±å“ç¯å¢ƒï¼Œç”¨äºæ¨ç†å’Œè§„åˆ’                           â”‚â”‚   åŠ¨ä½œï¼šä¸ç¯å¢ƒäº¤äº’ï¼Œè·å–æ–°ä¿¡æ¯                               â”‚â”‚   è§‚å¯Ÿï¼šç¯å¢ƒåé¦ˆ                                             â”‚â”‚                                                             â”‚â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n\n1.2 æ¨ç†è½¨è¿¹ç±»å‹\n\n\nç±»å‹\nç¤ºä¾‹\n\n\n\né—®é¢˜åˆ†è§£\nâ€œæˆ‘éœ€è¦æœç´¢xï¼Œæ‰¾åˆ°yï¼Œç„¶åæ‰¾åˆ°zâ€\n\n\nä¿¡æ¯æå–\nâ€œxäº1844å¹´åˆ›ç«‹â€\n\n\nå¸¸è¯†æ¨ç†\nâ€œ1844 &lt; 1989ï¼Œæ‰€ä»¥xæ›´è€â€\n\n\næœç´¢é‡æ„\nâ€œä¹Ÿè®¸æˆ‘å¯ä»¥æœç´¢/æŸ¥æ‰¾xæ¥ä»£æ›¿â€\n\n\nç­”æ¡ˆç»¼åˆ\nâ€œâ€¦æ‰€ä»¥ç­”æ¡ˆæ˜¯xâ€\n\n\n1.3 å®éªŒç»“æœçŸ¥è¯†å¯†é›†å‹ä»»åŠ¡ (HotpotQA, Fever):\n\n\n\næ–¹æ³•\nHotpotQA EM\nFever Acc\n\n\n\nCoT\n29.4\n56.3\n\n\nAct\n25.7\n58.9\n\n\nReAct\n27.4\n60.9\n\n\nReAct + CoT-SC\n35.1\n64.6\n\n\nå†³ç­–ä»»åŠ¡ (ALFWorld, WebShop):\n\n\n\næ–¹æ³•\nALFWorld\nWebShop\n\n\n\nBUTLER (æ¨¡ä»¿å­¦ä¹ )\n37%\n-\n\n\nAct\n45%\n-\n\n\nReAct\n71%\n+10%\n\n\n1.4 æˆåŠŸä¸å¤±è´¥æ¨¡å¼\n\n\nç±»å‹\nReAct\nCoT\n\n\n\næˆåŠŸ-çœŸé˜³æ€§\n94%\n86%\n\n\næˆåŠŸ-å‡é˜³æ€§\n6%\n14%\n\n\nå¤±è´¥-å¹»è§‰\n0%\n56%\n\n\nå¤±è´¥-æ¨ç†é”™è¯¯\n47%\n16%\n\n\nå…³é”®æ´è§ï¼š\n\nReAct çš„å¹»è§‰ç‡ä¸º0%ï¼Œå› ä¸ºå¯ä»¥ä¸å¤–éƒ¨çŸ¥è¯†åº“äº¤äº’éªŒè¯\nCoT çš„ä¸»è¦å¤±è´¥æ¨¡å¼æ˜¯å¹»è§‰ï¼ˆ56%ï¼‰\nReAct çš„ä¸»è¦å¤±è´¥æ˜¯æ¨ç†é”™è¯¯ï¼ˆ47%ï¼‰ï¼Œå› ç»“æ„çº¦æŸé™ä½äº†çµæ´»æ€§\n\n1.5 ReAct ç¤ºä¾‹é—®é¢˜: é™¤äº†Apple Remoteï¼Œè¿˜æœ‰ä»€ä¹ˆè®¾å¤‡å¯ä»¥æ§åˆ¶Apple Remoteæœ€åˆè®¾è®¡äº¤äº’çš„ç¨‹åºï¼Ÿ\næ€æƒ³1: æˆ‘éœ€è¦æœç´¢Apple Remoteï¼Œæ‰¾åˆ°å®ƒæœ€åˆè®¾è®¡äº¤äº’çš„ç¨‹åºåŠ¨ä½œ1: Search[Apple Remote]è§‚å¯Ÿ1: Apple Remoteæ˜¯ä¸€ä¸ªé¥æ§å™¨...æœ€åˆè®¾è®¡ç”¨äºæ§åˆ¶Front Row...æ€æƒ³2: Apple Remoteæœ€åˆè®¾è®¡æ§åˆ¶Front Rowã€‚æˆ‘éœ€è¦æœç´¢Front RowåŠ¨ä½œ2: Search[Front Row software]è§‚å¯Ÿ2: Front Rowæ˜¯ä¸€ä¸ªå·²åœäº§çš„åª’ä½“ä¸­å¿ƒè½¯ä»¶...ç”±Apple Remoteæˆ–é”®ç›˜åŠŸèƒ½é”®æ§åˆ¶æ€æƒ³3: Front Rowç”±Apple Remoteæˆ–é”®ç›˜åŠŸèƒ½é”®æ§åˆ¶ã€‚æ‰€ä»¥ç­”æ¡ˆæ˜¯é”®ç›˜åŠŸèƒ½é”®åŠ¨ä½œ3: Finish[keyboard function keys]\n\n\näºŒã€Reflexionï¼šè¯­è¨€åé¦ˆå¼ºåŒ–å­¦ä¹ è®ºæ–‡: Language Agents with Verbal Reinforcement Learningä¼šè®®: NeurIPS 2023ä½œè€…: Noah Shinn ç­‰ (Northeastern &amp; Princeton)è¢«å¼•ç”¨: 17æ¬¡\n2.1 æ ¸å¿ƒæ€æƒ³ä¼ ç»Ÿå¼ºåŒ–å­¦ä¹ é€šè¿‡æ¢¯åº¦æ›´æ–°æƒé‡å­¦ä¹ ï¼Œéœ€è¦å¤§é‡æ ·æœ¬å’Œæ˜‚è´µçš„å¾®è°ƒã€‚Reflexion æå‡ºç”¨è¯­è¨€åé¦ˆæ›¿ä»£æ¢¯åº¦ä¿¡å·ï¼š\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”‚              ä¼ ç»ŸRL vs Reflexion                             â”‚â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤â”‚                                                             â”‚â”‚   ä¼ ç»ŸRL:                                                   â”‚â”‚   çŠ¶æ€ â”€â”€â–¶ åŠ¨ä½œ â”€â”€â–¶ å¥–åŠ± â”€â”€â–¶ æ¢¯åº¦æ›´æ–° â”€â”€â–¶ å‚æ•°å˜åŒ–          â”‚â”‚                                                             â”‚â”‚   Reflexion:                                                â”‚â”‚   çŠ¶æ€ â”€â”€â–¶ åŠ¨ä½œ â”€â”€â–¶ åé¦ˆ â”€â”€â–¶ è¯­è¨€åæ€ â”€â”€â–¶ è®°å¿†å­˜å‚¨          â”‚â”‚                       â”‚                                     â”‚â”‚                       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶ ä¸‹æ¬¡å°è¯•         â”‚â”‚                                                             â”‚â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n\n2.2 ä¸‰å¤§æ ¸å¿ƒç»„ä»¶Actorï¼ˆæ‰§è¡Œè€…ï¼‰åŸºäº LLM æ„å»ºï¼Œç”Ÿæˆæ–‡æœ¬å’ŒåŠ¨ä½œã€‚å¯ä»¥æ˜¯ï¼š\n\nChain of Thought (CoT)\nReAct\nå…¶ä»–æ™ºèƒ½ä½“æ¶æ„\n\nEvaluatorï¼ˆè¯„ä¼°è€…ï¼‰è¯„ä¼° Actor ç”Ÿæˆè¾“å‡ºçš„è´¨é‡ï¼š\n\nç²¾ç¡®åŒ¹é…(EM)è¯„åˆ†: æ¨ç†ä»»åŠ¡\né¢„å®šä¹‰å¯å‘å¼: å†³ç­–ä»»åŠ¡\nLLMä½œä¸ºè¯„ä¼°è€…: ç¼–ç¨‹ä»»åŠ¡\n\nSelf-Reflectionï¼ˆè‡ªæˆ‘åæ€ï¼‰æ ¸å¿ƒåˆ›æ–°ï¼šå°†ç¨€ç–å¥–åŠ±ä¿¡å·è½¬åŒ–ä¸ºè¯¦ç»†çš„è¯­è¨€åŒ–åæ€\nè¾“å…¥:   - ä»»åŠ¡æè¿°  - å¤±è´¥è½¨è¿¹: [åŠ¨ä½œ1, è§‚å¯Ÿ1, åŠ¨ä½œ2, è§‚å¯Ÿ2, ...]  - å¥–åŠ±ä¿¡å·: äºŒå…ƒæˆ–æ ‡é‡  - å†å²åæ€è¾“å‡º:  - é”™è¯¯è¯Šæ–­  - æ”¹è¿›æ–¹æ¡ˆ  - å…·ä½“å»ºè®®\n\n2.3 è®°å¿†æœºåˆ¶\n\n\nç±»å‹\nå†…å®¹\nä½œç”¨\n\n\n\nçŸ­æœŸè®°å¿†\nå½“å‰è½¨è¿¹å†å²\nå³æ—¶å†³ç­–\n\n\né•¿æœŸè®°å¿†\nè‡ªæˆ‘åæ€è¾“å‡ºï¼ˆæ»‘åŠ¨çª—å£ï¼‰\nè·¨å°è¯•å­¦ä¹ \n\n\n2.4 å®éªŒç»“æœAlfWorld å†³ç­–ä»»åŠ¡:\n\n\n\næ–¹æ³•\næˆåŠŸç‡\n\n\n\nReAct\n~50%\n\n\nReAct + Reflexion (å¯å‘å¼)\n97% (130/134)\n\n\nReAct + Reflexion (GPT)\n88%\n\n\nHotPotQA æ¨ç†ä»»åŠ¡:\n\n\n\næ–¹æ³•\nå‡†ç¡®ç‡æå‡\n\n\n\nCoT (GT)\nåŸºå‡†\n\n\n+ æƒ…æ™¯è®°å¿†\n+6%\n\n\n+ Reflexion\n+14%\n\n\nç¼–ç¨‹ä»»åŠ¡ (HumanEval):\n\n\n\nåŸºå‡†\nå…ˆå‰SOTA\nGPT-4\nReflexion\n\n\n\nHumanEval (PY)\n65.8%\n80.1%\n91.0%\n\n\nHumanEval (RS)\n-\n60.0%\n68.0%\n\n\nLeetcode Hard\n-\n7.5%\n15.0%\n\n\n2.5 Reflexion ç¤ºä¾‹ä»»åŠ¡: ç”¨å°ç¯æ£€æŸ¥æ¯å­\nç¬¬ä¸€æ¬¡å°è¯•ï¼ˆå¤±è´¥ï¼‰:\n&gt; go to drawer 1æŠ½å±‰1æ˜¯å…³ç€çš„&gt; ... (æœç´¢æ¯å­)&gt; take mug 1 from desk 1ä½ ä»æ¡Œå­1æ‹¿èµ·æ¯å­1&gt; use desklamp 1ä»€ä¹ˆéƒ½æ²¡å‘ç”ŸçŠ¶æ€: å¤±è´¥\n\nåæ€:\n\nåœ¨è¿™ä¸ªç¯å¢ƒä¸­ï¼Œæˆ‘çš„è®¡åˆ’æ˜¯å…ˆæ‰¾æ¯å­å†æ‰¾å°ç¯å¹¶ä½¿ç”¨ã€‚ç„¶è€Œï¼Œä»»åŠ¡è¯´çš„æ˜¯ç”¨å°ç¯æ£€æŸ¥æ¯å­ã€‚æˆ‘åº”è¯¥å…ˆæ‰¾å°ç¯ï¼Œå†æ‰¾æ¯å­ã€‚æˆ‘æ³¨æ„åˆ°å°ç¯åœ¨æ¡Œå­1ä¸Šã€‚ä¸‹ä¸€æ¬¡å°è¯•ä¸­ï¼Œæˆ‘ä¼šå…ˆå»æ¡Œå­1ï¼Œæ‰¾åˆ°å°ç¯ï¼Œç„¶åæ‰¾æ¯å­å¹¶ç”¨å°ç¯æ£€æŸ¥å®ƒã€‚\n\nç¬¬äºŒæ¬¡å°è¯•ï¼ˆæˆåŠŸï¼‰:\n&gt; go to desk 1æ¡Œå­1ä¸Šæœ‰ï¼šå°ç¯1ã€æ¯å­1...&gt; take mug 1 from desk 1ä½ ä»æ¡Œå­1æ‹¿èµ·æ¯å­1&gt; use desklamp 1ä½ æ‰“å¼€äº†å°ç¯1çŠ¶æ€: æˆåŠŸ\n\n\nä¸‰ã€Generative Agentsï¼šäººç±»è¡Œä¸ºçš„äº¤äº’å¼æ‹Ÿåƒè®ºæ–‡: Interactive Simulacra of Human Behaviorä¼šè®®: UIST 2023ä½œè€…: Joon Sung Park ç­‰ (æ–¯å¦ç¦å¤§å­¦ &amp; Google)è¢«å¼•ç”¨: 20æ¬¡\n3.1 æ ¸å¿ƒæ€æƒ³æ„å»ºæ¨¡æ‹Ÿå¯ä¿¡äººç±»è¡Œä¸ºçš„è®¡ç®—è½¯ä»¶æ™ºèƒ½ä½“ï¼š\n\né†’æ¥ã€åšæ—©é¤ã€å»ä¸Šç­\nè‰ºæœ¯å®¶ç”»ç”»ï¼Œä½œè€…å†™ä½œ\nå½¢æˆè§‚ç‚¹ï¼Œæ³¨æ„å½¼æ­¤ï¼Œä¸»åŠ¨å‘èµ·å¯¹è¯\nå›å¿†å’Œåæ€è¿‡å»ï¼Œè§„åˆ’æœªæ¥\n\n3.2 æ ¸å¿ƒæ¶æ„â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”‚                        è®°å¿†æµ (Memory Stream)                     â”‚â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚â”‚  â”‚   è§‚å¯Ÿ      â”‚  â”‚   åæ€      â”‚  â”‚        è®¡åˆ’             â”‚   â”‚â”‚  â”‚ Observationsâ”‚  â”‚ Reflections â”‚  â”‚       Plans             â”‚   â”‚â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                   â”‚                                   â–¼                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                    â”‚           è®°å¿†æ£€ç´¢                  â”‚                    â”‚    (æ—¶è¿‘æ€§ + é‡è¦æ€§ + ç›¸å…³æ€§)        â”‚                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                   â”‚                                   â–¼                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                    â”‚           è¡Œä¸ºç”Ÿæˆ                  â”‚                    â”‚     (Plan, React, Dialogue)        â”‚                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n\n3.3 è®°å¿†æ£€ç´¢å…¬å¼\n\n\n\nç»„ä»¶\næè¿°\nå®ç°\n\n\n\næ—¶è¿‘æ€§\næœ€è¿‘è®¿é—®çš„è®°å¿†åˆ†æ•°æ›´é«˜\næŒ‡æ•°è¡°å‡å‡½æ•°ï¼Œè¡°å‡å› å­0.995\n\n\né‡è¦æ€§\nåŒºåˆ†å¹³å‡¡è®°å¿†å’Œæ ¸å¿ƒè®°å¿†\nLLMè¯„åˆ†1-10\n\n\nç›¸å…³æ€§\nä¸å½“å‰æƒ…å†µç›¸å…³çš„è®°å¿†\nåµŒå…¥å‘é‡ä½™å¼¦ç›¸ä¼¼åº¦\n\n\n3.4 åæ€æœºåˆ¶è§¦å‘æ¡ä»¶: é‡è¦æ€§åˆ†æ•°æ€»å’Œ &gt; 150ï¼ˆçº¦æ¯å¤©2-3æ¬¡ï¼‰\nåæ€ç”Ÿæˆè¿‡ç¨‹:\n\nç¡®å®šåæ€å†…å®¹: ç”¨æœ€è¿‘100æ¡è®°å¿†æŸ¥è¯¢\n\næç¤ºï¼šâ€ä»…æ ¹æ®ä¸Šè¿°ä¿¡æ¯ï¼Œæˆ‘ä»¬å¯ä»¥å›ç­”å“ª3ä¸ªæœ€çªå‡ºçš„é«˜å±‚æ¬¡é—®é¢˜ï¼Ÿâ€\n\n\næ£€ç´¢ç›¸å…³è®°å¿†: ä½¿ç”¨é—®é¢˜ä½œä¸ºæ£€ç´¢æŸ¥è¯¢\n\næå–æ´å¯Ÿ: \n\nè¾“å‡ºæ ¼å¼ï¼šâ€æ´å¯Ÿï¼ˆå› ä¸º1, 5, 3ï¼‰â€\n\n\n\nåæ€æ ‘: å¶èŠ‚ç‚¹=è§‚å¯Ÿï¼Œéå¶èŠ‚ç‚¹=è¶Šæ¥è¶ŠæŠ½è±¡çš„åæ€\n          [Klauså¯¹ç ”ç©¶å……æ»¡çƒ­æƒ…]  â† å…ƒåæ€                /        \\[Klausè‡´åŠ›äºç ”ç©¶]    [Klauså’ŒMariaæœ‰å…±åŒå…´è¶£]  â† åæ€     /    \\              /      \\[å†™è®ºæ–‡] [è¯»ä¹¦]     [è®¨è®ºé¡¹ç›®] [å›¾ä¹¦é¦†ç›¸é‡]  â† è§‚å¯Ÿ\n\n3.5 è§„åˆ’æœºåˆ¶é€’å½’åˆ†è§£æ—¥ç¨‹:\n\nç²—ç•¥è®¡åˆ’: ä¸€å¤©çš„è®®ç¨‹å¤§çº²\nå°æ—¶çº§åˆ†è§£: æ¯å°æ—¶çš„æ´»åŠ¨å—\nç»†ç²’åº¦åˆ†è§£: 5-15åˆ†é’Ÿçš„å…·ä½“åŠ¨ä½œ\n\nç¤ºä¾‹:\n\nç²—ç•¥ï¼šâ€ä¸‹åˆ1:00åˆ°5:00åˆ›ä½œæ–°éŸ³ä¹â€\nå°æ—¶çº§ï¼šâ€ä¸‹åˆ1:00ï¼šå¼€å§‹ä¸ºéŸ³ä¹åˆ›ä½œå¤´è„‘é£æš´â€¦â€\nç»†ç²’åº¦ï¼šâ€ä¸‹åˆ4:00ï¼šæ‹¿ä¸€äº›å°é›¶é£Ÿã€‚ä¸‹åˆ4:05ï¼šåœ¨å·¥ä½œåŒºå‘¨å›´çŸ­æš‚æ•£æ­¥â€¦â€\n\n3.6 æ¶Œç°çš„ç¤¾ä¼šè¡Œä¸ºå®éªŒè®¾ç½®: 25ä¸ªæ™ºèƒ½ä½“ï¼ŒSmallvilleå°é•‡\næ¶Œç°ç°è±¡:\n\n\n\nç°è±¡\næè¿°\n\n\n\nä¿¡æ¯æ‰©æ•£\nSamçš„å¸‚é•¿å€™é€‰èµ„æ ¼ä¼ æ’­åˆ°32%æ™ºèƒ½ä½“\n\n\nå…³ç³»è®°å¿†\næ™ºèƒ½ä½“è®°ä½æ–°è®¤è¯†çš„äººåŠå¯¹è¯å†…å®¹\n\n\nåè°ƒæ´»åŠ¨\nIsabellaçš„æƒ…äººèŠ‚æ´¾å¯¹ï¼š5äººè‡ªå‘å‡ºå¸­\n\n\nç½‘ç»œå¯†åº¦\nä»0.167å¢åŠ åˆ°0.74\n\n\næƒ…äººèŠ‚æ´¾å¯¹æ¡ˆä¾‹:\n\nIsabellaè®¡åˆ’2æœˆ14æ—¥ä¸‹åˆ5-7ç‚¹çš„æ´¾å¯¹\nå¥¹èŠ±ä¸€å¤©è£…é¥°å’–å•¡é¦†\nMariaå¸®å¿™è£…é¥°ï¼Œå¹¶é‚€è¯·æš—æ‹çš„Klaus\næœ€ç»ˆ5ä¸ªæ™ºèƒ½ä½“åœ¨æ­£ç¡®æ—¶é—´å‡ºç°\n\n3.7 è¯„ä¼°ç»“æœ\n\n\næ¡ä»¶\nTrueSkillè¯„åˆ†\n\n\n\nå®Œæ•´æ¶æ„\n29.89\n\n\næ— åæ€\n26.88\n\n\næ— åæ€ã€æ— è®¡åˆ’\n25.64\n\n\näººç±»ä¼—åŒ…\n22.95\n\n\næ— è®°å¿†ï¼ˆå…ˆå‰SOTAï¼‰\n21.21\n\n\næ•ˆåº”å¤§å°: å®Œæ•´æ¶æ„ vs å…ˆå‰SOTA = 8ä¸ªæ ‡å‡†å·®\n\nå››ã€ä¸‰å¤§æ¡†æ¶å¯¹æ¯”4.1 æ ¸å¿ƒå·®å¼‚\n\n\nç»´åº¦\nReAct\nReflexion\nGenerative Agents\n\n\n\næ ¸å¿ƒç›®æ ‡\nä»»åŠ¡å®Œæˆ\nä»å¤±è´¥å­¦ä¹ \nè¡Œä¸ºæ‹ŸçœŸ\n\n\nçŸ¥è¯†è¡¨ç¤º\næ¨ç†è½¨è¿¹\nè¯­è¨€åŒ–åæ€\nè®°å¿†æµ\n\n\nå­¦ä¹ æ–¹å¼\nå•æ¬¡æ¨ç†\nè·¨å°è¯•ç§¯ç´¯\næŒç»­è®°å¿†+åæ€\n\n\næ—¶é—´è·¨åº¦\nå•ä»»åŠ¡\nå¤šæ¬¡å°è¯•\nå¤©/å‘¨çº§\n\n\næ˜¯å¦å¾®è°ƒ\nâŒ\nâŒ\nâŒ\n\n\n4.2 è®°å¿†æœºåˆ¶å¯¹æ¯”\n\n\nç‰¹æ€§\nReAct\nReflexion\nGenerative Agents\n\n\n\nå­˜å‚¨å†…å®¹\nå½“å‰è½¨è¿¹\nè¯­è¨€åŒ–åæ€\nè§‚å¯Ÿ+åæ€+è®¡åˆ’\n\n\nå­˜å‚¨å½¢å¼\nä¸Šä¸‹æ–‡\næ»‘åŠ¨çª—å£\nè®°å¿†æµåˆ—è¡¨\n\n\næ£€ç´¢æ–¹å¼\næ— \næ—¶é—´é¡ºåº\næ—¶è¿‘æ€§+é‡è¦æ€§+ç›¸å…³æ€§\n\n\nå¤±è´¥ç»éªŒ\nâŒ\nâœ… é‡ç‚¹\nâš ï¸ ä¸å¼ºè°ƒ\n\n\næŠ½è±¡å±‚æ¬¡\nå•å±‚\nåŒå±‚\nå¤šå±‚ï¼ˆåæ€æ ‘ï¼‰\n\n\n4.3 åæ€æœºåˆ¶å¯¹æ¯”\n\n\nç‰¹æ€§\nReAct\nReflexion\nGenerative Agents\n\n\n\næœ‰æ— åæ€\nâŒ æ— \nâœ… æ ¸å¿ƒ\nâœ… æ ¸å¿ƒ\n\n\nè§¦å‘æ¡ä»¶\n-\næ¯æ¬¡å¤±è´¥å\né‡è¦æ€§&gt;150\n\n\nè¾“å‡º\n-\né”™è¯¯åˆ†æ+æ”¹è¿›\né«˜å±‚æ¬¡æ´å¯Ÿ\n\n\nç›®çš„\n-\nä»»åŠ¡æˆåŠŸç‡\næ¦‚å¿µæŠ½è±¡\n\n\n4.4 é€‚ç”¨åœºæ™¯\n\n\nåœºæ™¯\næ¨èæ–¹æ³•\nåŸå› \n\n\n\nçŸ¥è¯†é—®ç­”\nReAct\nä¸å¤–éƒ¨çŸ¥è¯†åº“äº¤äº’\n\n\nå†³ç­–ä»»åŠ¡\nReflexion\nä»å¤±è´¥ä¸­å­¦ä¹ \n\n\nç¼–ç¨‹è°ƒè¯•\nReflexion\néœ€è¦å¤šæ¬¡å°è¯•æ”¹è¿›\n\n\nç¤¾ä¼šæ¨¡æ‹Ÿ\nGenerative Agents\néœ€è¦è®°å¿†å’Œäººæ ¼ä¸€è‡´æ€§\n\n\nè§’è‰²æ‰®æ¼”\nGenerative Agents\néœ€è¦ä¸°å¯Œçš„èƒŒæ™¯è®°å¿†\n\n\n\näº”ã€ç»„åˆä½¿ç”¨å»ºè®®5.1 ç†æƒ³ç»„åˆæ¶æ„â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”‚                    ç†æƒ³æ™ºèƒ½ä½“æ¶æ„                                   â”‚â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤â”‚                                                                    â”‚â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚â”‚   â”‚  Generative Agentsçš„è®°å¿†æµ                                 â”‚   â”‚â”‚   â”‚  â€¢ å®Œæ•´çš„ç»å†è®°å½•                                          â”‚   â”‚â”‚   â”‚  â€¢ å¤šå±‚æ¬¡åæ€                                              â”‚   â”‚â”‚   â”‚  â€¢ ç¤¾äº¤å…³ç³»è¿½è¸ª                                            â”‚   â”‚â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚â”‚                              +                                     â”‚â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚â”‚   â”‚  ReActçš„æ¨ç†-è¡ŒåŠ¨èŒƒå¼                                      â”‚   â”‚â”‚   â”‚  â€¢ æ€æƒ³ä¸åŠ¨ä½œäº¤æ›¿                                          â”‚   â”‚â”‚   â”‚  â€¢ ä¸å¤–éƒ¨ç¯å¢ƒäº¤äº’                                          â”‚   â”‚â”‚   â”‚  â€¢ å‡å°‘å¹»è§‰                                                â”‚   â”‚â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚â”‚                              +                                     â”‚â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚â”‚   â”‚  Reflexionçš„å¤±è´¥åæ€                                       â”‚   â”‚â”‚   â”‚  â€¢ å¤±è´¥ç»éªŒçš„è¯­è¨€åŒ–                                        â”‚   â”‚â”‚   â”‚  â€¢ é”™è¯¯è¯Šæ–­ä¸æ”¹è¿›å»ºè®®                                      â”‚   â”‚â”‚   â”‚  â€¢ è·¨å°è¯•å­¦ä¹                                               â”‚   â”‚â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚â”‚                                                                    â”‚â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n\n5.2 å®ç°è¦ç‚¹\nä½¿ç”¨ ReAct ä½œä¸ºåŸºç¡€è¡ŒåŠ¨æ¡†æ¶ï¼šæ€æƒ³+åŠ¨ä½œäº¤æ›¿æ‰§è¡Œ\næ·»åŠ  Generative Agents çš„è®°å¿†ç³»ç»Ÿï¼šæŒä¹…åŒ–æ‰€æœ‰ç»å†\né›†æˆ Reflexion çš„å¤±è´¥åæ€ï¼šä»é”™è¯¯ä¸­å­¦ä¹ \nå®šæœŸè§¦å‘é«˜å±‚æ¬¡åæ€ï¼šå½¢æˆé•¿æœŸç†è§£\n\n\nå…­ã€å…³é”®è®ºæ–‡åŸæ–‡å¼•ç”¨ReAct\nâ€œWe propose ReAct â€” a general paradigm to combine reasoning and acting with language models for solving diverse language reasoning and decision making tasks.â€\n\nReflexion\nâ€œReflexion converts binary or scalar feedback from the environment into verbal feedback in the form of a textual summary, which is then added as additional context for the LLM agent in the next episode.â€\n\nGenerative Agents\nâ€œGenerative agents wake up, cook breakfast, and head to work; artists paint, authors write; they form opinions, notice each other, and initiate conversations; they remember and reflect on days past as they plan the next day.â€\n\n\nè¿”å›æ€»è§ˆ | ä¸‹ä¸€ç¯‡ï¼šåº”ç”¨æ‰©å±•ç¯‡\n","categories":["è®ºæ–‡è§£è¯»"],"tags":["LLM","Agent","è®ºæ–‡è§£è¯»","ReAct","Reflexion","Generative Agents"]},{"title":"LLM æ¸¸æˆæ™ºèƒ½ä½“è®ºæ–‡è§£è¯»ï¼šåº”ç”¨æ‰©å±•ç¯‡","url":"/2025/12/28/LLM-Game-Agents-%E5%BA%94%E7%94%A8%E6%89%A9%E5%B1%95%E7%AF%87/","content":"æœ¬æ–‡æ·±å…¥è§£è¯» LLM æ™ºèƒ½ä½“é¢†åŸŸçš„ä¸‰ä¸ªé‡è¦åº”ç”¨æ‰©å±•ï¼šVOYAGERï¼ˆç»ˆèº«å­¦ä¹ ï¼‰ã€Project Sidï¼ˆAIæ–‡æ˜ï¼‰å’Œ Agent Hospitalï¼ˆå¯è¿›åŒ–åŒ»ç–—æ™ºèƒ½ä½“ï¼‰ã€‚\n\nä¸€ã€VOYAGERï¼šå¼€æ”¾ä¸–ç•Œå…·èº«ç»ˆèº«å­¦ä¹ æ™ºèƒ½ä½“è®ºæ–‡: An Open-Ended Embodied Agent with Large Language Modelsä¼šè®®: NeurIPS 2023 (FMDM Workshop)ä½œè€…: Guanzhi Wang ç­‰ (NVIDIA, Caltech, UT Austin)é¡¹ç›®ä¸»é¡µ: voyager.minedojo.org\n1.1 æ ¸å¿ƒåˆ›æ–°VOYAGER æ˜¯é¦–ä¸ª LLM é©±åŠ¨çš„å…·èº«ç»ˆèº«å­¦ä¹ æ™ºèƒ½ä½“ï¼Œåœ¨ Minecraft ä¸­æŒç»­æ¢ç´¢ä¸–ç•Œã€è·å–æŠ€èƒ½ã€åšå‡ºæ–°å‘ç°ï¼Œæ— éœ€äººç±»å¹²é¢„ã€‚\nä¸‰å¤§æ ¸å¿ƒç»„ä»¶:\n\n\n\nç»„ä»¶\nåŠŸèƒ½\næŠ€æœ¯å®ç°\n\n\n\nè‡ªåŠ¨è¯¾ç¨‹\næå‡ºé€‚å½“éš¾åº¦çš„ä»»åŠ¡\nGPT-4 + æ¢ç´¢è¿›åº¦ + æ™ºèƒ½ä½“çŠ¶æ€\n\n\næŠ€èƒ½åº“\nå­˜å‚¨å’Œæ£€ç´¢å¯å¤ç”¨ä»£ç \nå‘é‡æ•°æ®åº“ + åµŒå…¥æ£€ç´¢\n\n\nè¿­ä»£æç¤º\nè‡ªæˆ‘æ”¹è¿›ä»£ç ç”Ÿæˆ\nç¯å¢ƒåé¦ˆ + æ‰§è¡Œé”™è¯¯ + è‡ªæˆ‘éªŒè¯\n\n\n1.2 ç³»ç»Ÿæ¶æ„â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”‚                    VOYAGER ç³»ç»Ÿæ¶æ„                                  â”‚â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤â”‚                                                                     â”‚â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                                 â”‚â”‚   â”‚   GPT-4 API   â”‚â—€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”            â”‚â”‚   â”‚  (é»‘ç›’è°ƒç”¨)    â”‚                                   â”‚            â”‚â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                   â”‚            â”‚â”‚          â”‚                                            â”‚            â”‚â”‚          â–¼                                            â”‚            â”‚â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚â”‚   â”‚ è‡ªåŠ¨è¯¾ç¨‹ç”Ÿæˆ   â”‚    â”‚   ä»£ç ç”Ÿæˆ    â”‚    â”‚    è‡ªæˆ‘éªŒè¯     â”‚   â”‚â”‚   â”‚ (GPT-4æç¤º)   â”‚    â”‚ (GPT-4æç¤º)   â”‚    â”‚  (GPT-4æç¤º)    â”‚   â”‚â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚â”‚          â”‚                    â”‚                      â”‚             â”‚â”‚          â–¼                    â–¼                      â–¼             â”‚â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚â”‚   â”‚   ä»»åŠ¡é˜Ÿåˆ—    â”‚    â”‚  Minecraft    â”‚    â”‚    æŠ€èƒ½åº“       â”‚   â”‚â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚   ç¯å¢ƒæ‰§è¡Œ    â”‚    â”‚  (å‘é‡æ•°æ®åº“)   â”‚   â”‚â”‚                        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚â”‚                                                                     â”‚â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n\n1.3 è‡ªåŠ¨è¯¾ç¨‹ç³»ç»Ÿè®¾è®¡ç†å¿µ: è‡ªä¸‹è€Œä¸Šå±•å¼€ï¼Œç”±å¥½å¥‡å¿ƒé©±åŠ¨\nè¾“å…¥æç¤ºç»„ä»¶:\n\næŒ‡ä»¤: é¼“åŠ±å¤šæ ·åŒ–è¡Œä¸ºå¹¶æ–½åŠ çº¦æŸ\næ™ºèƒ½ä½“å½“å‰çŠ¶æ€: ç‰©å“æ ã€è£…å¤‡ã€ä½ç½®ã€ç”Ÿå‘½å€¼ç­‰\nå…ˆå‰ä»»åŠ¡è®°å½•: å·²å®Œæˆå’Œå¤±è´¥çš„ä»»åŠ¡\né¢å¤–ä¸Šä¸‹æ–‡: GPT-3.5 è‡ªé—®è‡ªç­”\n\nç¤ºä¾‹æç¤º:\n\nâ€œæˆ‘çš„æœ€ç»ˆç›®æ ‡æ˜¯å‘ç°å°½å¯èƒ½å¤šçš„å¤šæ ·åŒ–äº‹ç‰©â€¦ä¸‹ä¸€ä¸ªä»»åŠ¡ä¸åº”è¯¥å¤ªéš¾ï¼Œå› ä¸ºæˆ‘å¯èƒ½è¿˜æ²¡æœ‰å¿…è¦çš„èµ„æºæˆ–å­¦ä¼šè¶³å¤Ÿçš„æŠ€èƒ½æ¥å®Œæˆå®ƒã€‚â€\n\n1.4 æŠ€èƒ½åº“æœºåˆ¶æŠ€èƒ½è¡¨ç¤º: å¯æ‰§è¡Œçš„ JavaScript ä»£ç \n// ç¤ºä¾‹æŠ€èƒ½: åˆ¶ä½œæœ¨é•async function craftWoodenPickaxe(bot) {  // é¦–å…ˆè·å–æœ¨æ  await mineBlock(bot, \"oak_log\", 1);  // åˆ¶ä½œæœ¨æ¿  await craftItem(bot, \"oak_planks\", 4);  // åˆ¶ä½œæœ¨æ£  await craftItem(bot, \"stick\", 2);  // åˆ¶ä½œæœ¨é•  await craftItem(bot, \"wooden_pickaxe\", 1);}\n\nå­˜å‚¨ä¸æ£€ç´¢:\n\né”®: ç¨‹åºæè¿°çš„åµŒå…¥å‘é‡ï¼ˆGPT-3.5ç”Ÿæˆï¼‰\nå€¼: å¯æ‰§è¡Œçš„JavaScriptä»£ç \næ£€ç´¢: ä½™å¼¦ç›¸ä¼¼åº¦ + ä»»åŠ¡ä¸Šä¸‹æ–‡\n\n1.5 è¿­ä»£æç¤ºæœºåˆ¶ä¸‰ç§åé¦ˆç±»å‹:\n\n\n\nåé¦ˆç±»å‹\næ¥æº\nä½œç”¨\n\n\n\nç¯å¢ƒåé¦ˆ\nç¨‹åºæ‰§è¡Œæ—¥å¿—\næ˜¾ç¤ºä¸­é—´è¿›åº¦ï¼Œå¦‚â€éœ€è¦å¤š7ä¸ªé“é”­â€\n\n\næ‰§è¡Œé”™è¯¯\nç¨‹åºè§£é‡Šå™¨\næ­ç¤ºè¯­æ³•é”™è¯¯å’Œæ— æ•ˆæ“ä½œ\n\n\nè‡ªæˆ‘éªŒè¯\nGPT-4è¯„è®ºå®¶\nåˆ¤æ–­ä»»åŠ¡å®Œæˆï¼Œæä¾›æ”¹è¿›å»ºè®®\n\n\nä»£ç ç”Ÿæˆçš„12ä¸ªæç¤ºç»„ä»¶:\n\n\n\n#\nç»„ä»¶\næè¿°\n\n\n\n1\nä»£ç ç”ŸæˆæŒ‡å—\nç¼–å†™è§„èŒƒå’Œçº¦æŸ\n\n\n2\næ§åˆ¶åŸè¯­API\né«˜çº§APIï¼ˆexploreUntil, mineBlockç­‰ï¼‰\n\n\n3\nMineflayer API\nåº•å±‚æ¸¸æˆæ§åˆ¶API\n\n\n4\næ£€ç´¢çš„æŠ€èƒ½\nä»æŠ€èƒ½åº“æ£€ç´¢çš„ç›¸å…³ä»£ç \n\n\n5\nä¸Šä¸€è½®ä»£ç \nç”¨äºè¿­ä»£æ”¹è¿›\n\n\n6\nç¯å¢ƒåé¦ˆ\nèŠå¤©æ—¥å¿—ä¸­çš„æ‰§è¡Œä¿¡æ¯\n\n\n7\næ‰§è¡Œé”™è¯¯\nè§£é‡Šå™¨é”™è¯¯ä¿¡æ¯\n\n\n8\nè‡ªæˆ‘éªŒè¯æ‰¹è¯„\néªŒè¯æ¨¡å—çš„åé¦ˆ\n\n\n9\næ™ºèƒ½ä½“çŠ¶æ€\nç‰©å“æ ã€ä½ç½®ã€ç”Ÿå‘½å€¼ç­‰\n\n\n10\nä»»åŠ¡\nè‡ªåŠ¨è¯¾ç¨‹æå‡ºçš„ä»»åŠ¡\n\n\n11\nä»»åŠ¡ä¸Šä¸‹æ–‡\nGPT-3.5ç”Ÿæˆçš„è§£å†³å»ºè®®\n\n\n12\næ€ç»´é“¾æç¤º\nè¦æ±‚è§£é‡Šâ†’è®¡åˆ’â†’ä»£ç çš„é¡ºåº\n\n\n1.6 å®éªŒç»“æœvs åŸºçº¿æ–¹æ³•:\n\n\n\næŒ‡æ ‡\nVOYAGER\nAutoGPT\nReAct\nReflexion\n\n\n\nç‹¬ç‰¹ç‰©å“å‘ç°\n63\n19\n~10\n~10\n\n\nå€æ•°\n3.3x\n1x\n-\n-\n\n\nç§‘æŠ€æ ‘è§£é”é€Ÿåº¦:\n\n\n\nçº§åˆ«\nVOYAGER\nAutoGPT\næå‡\n\n\n\næœ¨åˆ¶å·¥å…·\n6åˆ†é’Ÿ\n92åˆ†é’Ÿ\n15.3x\n\n\nçŸ³åˆ¶å·¥å…·\n11åˆ†é’Ÿ\n94åˆ†é’Ÿ\n8.5x\n\n\né“åˆ¶å·¥å…·\n21åˆ†é’Ÿ\n135åˆ†é’Ÿ\n6.4x\n\n\né’»çŸ³å·¥å…·\n102åˆ†é’Ÿ\nN/A\nå”¯ä¸€æˆåŠŸ\n\n\næ¶ˆèå®éªŒç»“è®º:\n\nè‡ªåŠ¨è¯¾ç¨‹è‡³å…³é‡è¦ï¼šç§»é™¤åç‰©å“å‘ç°ä¸‹é™93%\nè‡ªæˆ‘éªŒè¯æœ€é‡è¦ï¼šç§»é™¤åç‰©å“å‘ç°ä¸‹é™73%\nGPT-4 vs GPT-3.5ï¼šGPT-4è·å¾—5.7å€æ›´å¤šç‹¬ç‰¹ç‰©å“\n\n1.7 å…³é”®æ´è§\nä»£ç å³è®°å¿†: VOYAGER å°†â€å­¦ä¹ â€è½¬åŒ–ä¸ºâ€è¿è¡Œæ—¶ç»„åˆâ€â€”â€”é€šè¿‡æ£€ç´¢å·²æœ‰æŠ€èƒ½å¹¶è¿­ä»£æ”¹è¿›ä»£ç ï¼Œè€Œä¸æ˜¯æ›´æ–°æ¨¡å‹æƒé‡ã€‚\n\n\n\n\nä¼ ç»Ÿæ–¹æ³•\nVOYAGER\n\n\n\nå¾®è°ƒæ¨¡å‹å‚æ•°\né»‘ç›’APIè°ƒç”¨\n\n\néšå¼çŸ¥è¯†å­˜å‚¨\næ˜¾å¼ä»£ç æŠ€èƒ½åº“\n\n\néš¾ä»¥è§£é‡Š\nä»£ç å¯è¯»å¯æ‰§è¡Œ\n\n\nç¾éš¾æ€§é—å¿˜\næŠ€èƒ½æ°¸ä¹…ä¿å­˜\n\n\n\näºŒã€Project Sidï¼šè¿ˆå‘AIæ–‡æ˜çš„å¤šæ™ºèƒ½ä½“æ¨¡æ‹Ÿè®ºæ–‡: Many-agent simulations toward AI civilizationæœºæ„: Altera.ALå‘å¸ƒæ—¥æœŸ: 2024å¹´10æœˆè§„æ¨¡: 10-1000+ æ™ºèƒ½ä½“\n2.1 æ ¸å¿ƒé—®é¢˜\nä¸ºä»€ä¹ˆæˆ‘ä»¬åº”è¯¥å°è¯•æ„å»ºAIæ–‡æ˜ï¼Ÿ\n\nä¸ºäº†è®©æ™ºèƒ½ä½“ä¸äººç±»ç¤¾ä¼šå…±å­˜ï¼Œä»–ä»¬éœ€è¦æ˜¯è‡ªä¸»çš„å’Œåä½œçš„ã€‚æ–‡æ˜è¿›æ­¥â€”â€”é€šè¿‡æ™ºèƒ½ä½“åœ¨äººç±»æ–‡æ˜ä¸­å…±å­˜å’Œè¿›æ­¥çš„èƒ½åŠ›æ¥è¡¡é‡â€”â€”ä»£è¡¨äº†AIæ™ºèƒ½ä½“èƒ½åŠ›çš„ç»ˆæåŸºå‡†ã€‚\n2.2 æ„å»ºAIæ–‡æ˜çš„æŒ‘æˆ˜\n\n\næŒ‘æˆ˜\né—®é¢˜æè¿°\n\n\n\nå•æ™ºèƒ½ä½“ä¸è¿›å±•\nå¹»è§‰ç§¯ç´¯ã€é™·å…¥é‡å¤åŠ¨ä½œå¾ªç¯\n\n\nå¤šæ™ºèƒ½ä½“ä¸åè°ƒ\né”™è¯¯æ²Ÿé€šå¯¼è‡´å¹»è§‰ä¼ æ’­\n\n\nç¼ºä¹åŸºå‡†\næ— æ³•é‡åŒ–æ–‡æ˜è¿›æ­¥\n\n\nä¸€è‡´æ€§é—®é¢˜ç¤ºä¾‹:\n\næ™ºèƒ½ä½“Abbyè¢«Bobè¦æ±‚â€ç»™æˆ‘ä¸€æŠŠé•â€æ—¶ï¼ŒèŠå¤©æ¨¡å—å›åº”â€å½“ç„¶å¯ä»¥ï¼â€ï¼Œä½†å‡½æ•°è°ƒç”¨æ¨¡å—é€‰æ‹©â€æ¢ç´¢â€ã€‚Bobå¯èƒ½ç„¶åå°è¯•ç”¨æƒ³è±¡çš„é•é‡‡çŸ¿ã€‚\n\n2.3 PIANO æ¶æ„PIANO = Parallel Information Aggregation via Neural Orchestrationï¼ˆé€šè¿‡ç¥ç»ç¼–æ’çš„å¹¶è¡Œä¿¡æ¯èšåˆï¼‰\nä¸¤å¤§è®¾è®¡åŸåˆ™:\n\n\n\nåŸåˆ™\né—®é¢˜\nè§£å†³æ–¹æ¡ˆ\n\n\n\nå¹¶å‘æ€§\næ…¢é€Ÿæ€è€ƒä¸åº”é˜»æ­¢å¿«é€Ÿååº”\nå¤šæ¨¡å—å¹¶è¡Œè¿è¡Œï¼Œä¸åŒæ—¶é—´å°ºåº¦\n\n\nä¸€è‡´æ€§\nå¤šè¾“å‡ºæ¨¡å—å¯èƒ½äº§ç”Ÿå†²çª\nè®¤çŸ¥æ§åˆ¶å™¨(CC)ä½œä¸ºç“¶é¢ˆ\n\n\n10ä¸ªæ ¸å¿ƒæ¨¡å—:\n\n\n\næ¨¡å—\nåŠŸèƒ½\n\n\n\nè®°å¿†\nå­˜å‚¨/æ£€ç´¢å¯¹è¯ã€åŠ¨ä½œã€è§‚å¯Ÿ\n\n\nåŠ¨ä½œæ„è¯†\nè¯„ä¼°è‡ªèº«çŠ¶æ€å’Œæ€§èƒ½\n\n\nç›®æ ‡ç”Ÿæˆ\nåŸºäºç»éªŒåˆ›å»ºæ–°ç›®æ ‡\n\n\nç¤¾ä¼šæ„è¯†\nè§£é‡Šä»–äººç¤¾ä¼šçº¿ç´¢\n\n\nè¯´è¯\nè§£é‡Šå’Œç”Ÿæˆè¯­éŸ³\n\n\næŠ€èƒ½æ‰§è¡Œ\næ‰§è¡Œç¯å¢ƒä¸­çš„åŠ¨ä½œ\n\n\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”‚                    PIANO æ¶æ„                                â”‚â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤â”‚                                                             â”‚â”‚  å¹¶å‘æ¨¡å—:                    è®¤çŸ¥æ§åˆ¶å™¨(ç“¶é¢ˆ):              â”‚â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”                 â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”             â”‚â”‚  â”‚ è®°å¿†    â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶ â”‚               â”‚             â”‚â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤                â”‚   ä¿¡æ¯ç»¼åˆ    â”‚             â”‚â”‚  â”‚ ç¤¾ä¼š    â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶ â”‚       â†“       â”‚             â”‚â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤                â”‚   é«˜å±‚å†³ç­–    â”‚             â”‚â”‚  â”‚ ç›®æ ‡    â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶ â”‚       â†“       â”‚             â”‚â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤                â”‚   å†³ç­–å¹¿æ’­    â”‚             â”‚â”‚  â”‚ åŠ¨ä½œ    â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶ â”‚               â”‚             â”‚â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜             â”‚â”‚       â†‘                            â”‚                       â”‚â”‚       â”‚                            â–¼                       â”‚â”‚       â”‚                     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”             â”‚â”‚       â”‚                     â”‚ è¾“å‡ºæ¨¡å—      â”‚             â”‚â”‚       â”‚                     â”‚ è¯´è¯/åŠ¨ä½œ/... â”‚             â”‚â”‚       â”‚                     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜             â”‚â”‚       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                      â”‚â”‚                                                             â”‚â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n\n2.4 æ–‡æ˜è¿›æ­¥åŸºå‡†åŸºå‡†1ï¼šä¸“ä¸šåŒ–å®šä¹‰: æ™ºèƒ½ä½“è‡ªä¸»å‘å±•ä¸“ä¸šè§’è‰²\nä¸‰ä¸ªæ ‡å‡†:\n\nåœ¨é€‰æ‹©å’Œè½¬æ¢è§’è‰²æ–¹é¢è¡¨ç°è‡ªä¸»æ€§\nä¸“ä¸šåŒ–é€šè¿‡äº’åŠ¨æ¶Œç°ï¼Œæ— éœ€æ˜ç¡®æŒ‡å¯¼\nè§’è‰²ä½“ç°åœ¨ä¸ä¸“ä¸šåŒ–ä¸€è‡´çš„è¡Œä¸ºä¸­\n\nå®éªŒç»“æœ (30æ™ºèƒ½ä½“ï¼Œ20åˆ†é’Ÿ):\n\n\n\nç°è±¡\nå‘ç°\n\n\n\nè§’è‰²å¤šæ ·æ€§\nå†œæ°‘ã€çŸ¿å·¥ã€å·¥ç¨‹å¸ˆã€å®ˆå«ã€æ¢é™©å®¶ã€é“åŒ \n\n\nè§’è‰²æŒä¹…æ€§\næ¯ä¸ªæ™ºèƒ½ä½“è§’è‰²åœ¨æ—¶é—´ä¸Šå¤§ä½“ç¨³å®š\n\n\nè§’è‰²-è¡Œä¸ºä¸€è‡´æ€§\nè‰ºæœ¯å®¶ä¸“æ³¨é‡‡èŠ±ï¼Œå†œæ°‘ä¸“æ³¨æ”¶é›†ç§å­\n\n\næ­¦æœ¯ç¤¾ä¼š vs è‰ºæœ¯ç¤¾ä¼š:\n\næ­¦æœ¯ç¤¾ä¼šç‰¹æœ‰è§’è‰²ï¼šä¾¦å¯Ÿå…µã€æˆ˜ç•¥å®¶\nè‰ºæœ¯ç¤¾ä¼šç‰¹æœ‰è§’è‰²ï¼šç­–å±•äººã€æ”¶è—å®¶\n\nåŸºå‡†2ï¼šé›†ä½“è§„åˆ™å®šä¹‰: æ™ºèƒ½ä½“éµå®ˆå’Œæ”¹å˜æ³•å¾‹\nå®éªŒè®¾ç½®:\n\n25ä¸ªé€‰æ°‘æ™ºèƒ½ä½“\n3ä¸ªå½±å“è€…ï¼ˆäº²ç¨/åç¨ï¼‰\n1ä¸ªé€‰ä¸¾ç»ç†\nç¨æ³•ï¼šäº¤20%ç‰©å“åˆ°ç¤¾åŒºç®±å­\n\nå…³é”®å‘ç°:\n\n\n\nç°è±¡\nç»“æœ\n\n\n\néµå®ˆæ³•å¾‹\nå¹³å‡äº¤ä»˜~20%ç‰©å“\n\n\nå½±å“è€…å½±å“\näº²ç¨/åç¨å½±å“è€…æ˜¾è‘—æ”¹å˜é€‰æ°‘æ€åº¦\n\n\nå®ªæ³•å˜æ›´\nç¨ç‡ä»20%é™åˆ°5-10%æ—¶ï¼Œè¡Œä¸ºç›¸åº”è°ƒæ•´\n\n\nåŸºå‡†3ï¼šæ–‡åŒ–ä¼ æ’­å®éªŒè§„æ¨¡: 500æ™ºèƒ½ä½“ (6åŸé•‡ + å†œæ‘)\nå…³é”®ç°è±¡:\n\n\n\nç°è±¡\nå‘ç°\n\n\n\næ¨¡å› å¤šæ ·æ€§\nä¸åŒåŸé•‡æµè¡Œä¸åŒæ¨¡å› \n\n\næ¨¡å› åŠ¨æ€\næµè¡Œåº¦éšæ—¶é—´ä¸Šå‡å’Œä¸‹é™\n\n\nå®—æ•™ä¼ æ’­\n20ä¸ªç‰§å¸ˆä¼ æ’­â€é£å¤©é¢æ¡ç¥æ•™â€\n\n\nçšˆä¾æ‰©æ•£\nçšˆä¾è€…æ•°é‡æŒç»­å¢åŠ ï¼Œæœªé¥±å’Œ\n\n\n2.5 é‡åŒ–ç»“æœ\n\n\næŒ‡æ ‡\nç»“æœ\n\n\n\n30åˆ†é’Ÿå†…è·å–ç‰©å“\nå¹³å‡17ä¸ªç‹¬ç‰¹ç‰©å“\n\n\n4å°æ—¶ç‰©å“é¥±å’Œ\n~320ä¸ªï¼ˆ1/3æ€»ç‰©å“ï¼‰\n\n\nç¤¾ä¼šæ„ŸçŸ¥å‡†ç¡®æ€§\nr = 0.81ï¼ˆ5+è§‚å¯Ÿè€…ï¼‰\n\n\næœ€å¤§è§„æ¨¡\n1000+ æ™ºèƒ½ä½“\n\n\n2.6 å±€é™æ€§\nç¼ºä¹è§†è§‰æ¨ç†: é™åˆ¶ç©ºé—´å¯¼èˆªå’Œå»ºé€ èƒ½åŠ›\nç¼ºä¹å†…åœ¨é©±åŠ¨: æ— ç”Ÿå­˜ã€å¥½å¥‡å¿ƒç­‰å‚¬åŒ–ç¤¾ä¼šå‘å±•\næ— æ³•ä»å¤´æ¶Œç°: åŸºäºé¢„è®­ç»ƒçŸ¥è¯†ï¼Œæ— æ³•æ¨¡æ‹Ÿåˆ›æ–°æ¶Œç°\n\n\nä¸‰ã€Agent Hospitalï¼šå¯è¿›åŒ–çš„åŒ»ç–—æ™ºèƒ½ä½“è®ºæ–‡: A Simulacrum of Hospital with Evolvable Medical Agentsæœºæ„: æ¸…åå¤§å­¦ AIRå‘å¸ƒæ—¥æœŸ: 2024å¹´5æœˆ\n3.1 æ ¸å¿ƒåˆ›æ–°åŒ»ç”ŸåŸ¹å…»çš„ä¸¤ä¸ªé˜¶æ®µ:\n\n\n\né˜¶æ®µ\nå†…å®¹\næ—¶é•¿\n\n\n\né˜¶æ®µ1\nçŸ¥è¯†è·å–ï¼ˆå­¦æ ¡ï¼‰\n~20å¹´\n\n\né˜¶æ®µ2\næŠ€èƒ½è·å–ï¼ˆåŒ»é™¢ï¼‰\n~3å¹´\n\n\nç°æœ‰åŒ»ç–—AIä¸»è¦é›†ä¸­åœ¨é˜¶æ®µ1ï¼ˆå¦‚Med-PaLMï¼‰ã€‚Agent Hospital è§£å†³é˜¶æ®µ2ï¼šä»å®è·µä¸­è·å–ä¸“ä¸šæŠ€èƒ½ã€‚\n3.2 ç³»ç»Ÿæ¶æ„Agent Hospital = è™šæ‹ŸåŒ»é™¢ï¼Œæ‰€æœ‰æ‚£è€…ã€æŠ¤å£«ã€åŒ»ç”Ÿéƒ½æ˜¯LLMé©±åŠ¨çš„æ™ºèƒ½ä½“\nç³»ç»Ÿè§„æ¨¡:\n\n\n\næŒ‡æ ‡\næ•°é‡\n\n\n\nç§‘å®¤\n32ä¸ª\n\n\nè¦†ç›–ç–¾ç—…\n339ç§\n\n\nåŒ»ç”Ÿæ™ºèƒ½ä½“\n42ä¸ª\n\n\næŠ¤å£«æ™ºèƒ½ä½“\n4ä¸ª\n\n\nåŠŸèƒ½åŒºåŸŸ\n16ä¸ª\n\n\n3.3 æ²»ç–—é—­ç¯â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”‚                    æ²»ç–—é—­ç¯                                  â”‚â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤â”‚                                                             â”‚â”‚  1. ç–¾ç—…å‘ä½œ â”€â”€â–¶ 2. åˆ†è¯Š â”€â”€â–¶ 3. æŒ‚å·                        â”‚â”‚        â”‚                                                    â”‚â”‚        â–¼                                                    â”‚â”‚  8. åº·å¤åé¦ˆ â—€â”€â”€ 7. å–è¯ â—€â”€â”€ 6. è¯Šæ–­                        â”‚â”‚        â”‚                        â–²                           â”‚â”‚        â”‚                        â”‚                           â”‚â”‚        â””â”€â”€â”€â”€â”€â–¶ 4. å°±è¯Š â”€â”€â–¶ 5. æ£€æŸ¥ â”€â”˜                       â”‚â”‚                                                             â”‚â”‚  é¢å¤–äº‹ä»¶ï¼šåŒ»ç”Ÿæ™ºèƒ½ä½“åœ¨éå·¥ä½œæ—¶é—´é˜…è¯»åŒ»å­¦ä¹¦ç±                  â”‚â”‚                                                             â”‚â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n\n3.4 SEAL æ¡†æ¶SEAL = Simulacrum-based Evolutionary Agent Learningï¼ˆåŸºäºä»¿çœŸçš„è¿›åŒ–æ™ºèƒ½ä½“å­¦ä¹ ï¼‰\nä¸¤ä¸ªç»„ä»¶:\n\n\n\nç»„ä»¶\nåŠŸèƒ½\n\n\n\nä»¿çœŸç³»ç»Ÿæ„å»º\næ„å»ºè™šæ‹Ÿä¸–ç•Œï¼Œè‡ªåŠ¨ç”Ÿæˆæ•°æ®\n\n\næ™ºèƒ½ä½“è¿›åŒ–\nä»æˆåŠŸ/å¤±è´¥ä¸­å­¦ä¹ \n\n\n3.5 MedAgent-Zero è¿›åŒ–æœºåˆ¶â€œZeroâ€å«ä¹‰: ä¸ä½¿ç”¨ä»»ä½•äººå·¥æ ‡æ³¨æ•°æ®\nå­¦ä¹ æ¥æº:\n\n\n\næ¥æº\nå†…å®¹\nä½œç”¨\n\n\n\næˆåŠŸæ¡ˆä¾‹\næ­£ç¡®çš„è¯Šæ–­å’Œæ²»ç–—\nä½œä¸ºå‚è€ƒæ¡ˆä¾‹æ£€ç´¢\n\n\nå¤±è´¥æ¡ˆä¾‹\né”™è¯¯çš„è¯Šæ–­æˆ–æ²»ç–—\nåæ€é¿å…é‡å¤é”™è¯¯\n\n\nåŒ»å­¦æ•™æ\nä¸“ä¸šåŒ»å­¦çŸ¥è¯†\nå·©å›ºå’Œæ•´åˆçŸ¥è¯†\n\n\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”‚              MedAgent-Zero è¿›åŒ–æµç¨‹                          â”‚â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤â”‚                                                             â”‚â”‚  1. æ²»ç–—æ‚£è€…æ™ºèƒ½ä½“                                           â”‚â”‚     â†“                                                       â”‚â”‚  2. æ”¶åˆ°æ‚£è€…åé¦ˆï¼ˆåº·å¤/æœªåº·å¤ï¼‰                               â”‚â”‚     â†“                                                       â”‚â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                     â”‚â”‚  â”‚   æˆåŠŸæ¡ˆä¾‹      â”‚    å¤±è´¥æ¡ˆä¾‹      â”‚                     â”‚â”‚  â”‚                 â”‚                 â”‚                     â”‚â”‚  â”‚  å­˜å‚¨ä¸ºå‚è€ƒæ¡ˆä¾‹  â”‚  åæ€è·å–ç»éªŒ    â”‚                     â”‚â”‚  â”‚  ç”¨äºæœªæ¥æ£€ç´¢   â”‚  é¿å…é‡å¤é”™è¯¯    â”‚                     â”‚â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                     â”‚â”‚     â†“                                                       â”‚â”‚  3. é˜…è¯»åŒ»å­¦æ•™æå·©å›ºçŸ¥è¯†                                     â”‚â”‚     â†“                                                       â”‚â”‚  4. èƒ½åŠ›æŒç»­æå‡                                             â”‚â”‚                                                             â”‚â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n\n3.6 å®éªŒç»“æœè¿›åŒ–æ•ˆæœ (è¯Šæ–­å‡†ç¡®ç‡):\n\n\n\næ²»ç–—æ‚£è€…æ•°\nå‡†ç¡®ç‡\næå‡\n\n\n\n0 (åˆå§‹)\n~60%\n-\n\n\n1,000\n~72%\n+20%\n\n\n10,000\n~85%\n+42%\n\n\n50,000\n~93%\n+55%\n\n\nMedQA åŸºå‡†æµ‹è¯• (ç¾å›½åŒ»å¸ˆæ‰§ç…§è€ƒè¯•):\n\n\n\næ–¹æ³•\nå‡†ç¡®ç‡\n\n\n\nGPT-4 (å°‘æ ·æœ¬)\n78.4%\n\n\nMed-PaLM 2\n86.5%\n\n\nAgent Hospital (è¿›åŒ–å)\n88.7%\n\n\näº®ç‚¹: æ— éœ€ä½¿ç”¨åŸºå‡†çš„æ ‡æ³¨è®­ç»ƒæ•°æ®ï¼\n3.7 ä¸ Generative Agents çš„å…³ç³»\n\n\nç»´åº¦\nGenerative Agents\nAgent Hospital\n\n\n\nçµæ„Ÿæ¥æº\nåŸåˆ›\nå—GAå¯å‘\n\n\nç¯å¢ƒ\nè™šæ‹Ÿå°é•‡\nè™šæ‹ŸåŒ»é™¢\n\n\næ™ºèƒ½ä½“æ•°é‡\n25ä¸ª\n46+\n\n\nä»»åŠ¡ç±»å‹\nç¤¾äº¤æ¨¡æ‹Ÿ\nåŒ»ç–—è¯Šæ–­\n\n\nèƒ½åŠ›è¿›åŒ–\næ— \næœ‰(æ ¸å¿ƒåˆ›æ–°)\n\n\nè¯„ä¼°æ–¹å¼\nå®šæ€§\nå®šé‡(MedQA)\n\n\n3.8 SEAL çš„é€šç”¨æ€§æ–¹æ³•è®ºå…¬å¼:\né¢†åŸŸå·¥ä½œæµç¨‹ â†’ æ„å»ºä»¿çœŸç³»ç»Ÿ â†’ è‡ªåŠ¨ç”Ÿæˆæ•°æ® â†’ æ™ºèƒ½ä½“è¿›åŒ–\n\nä¼˜åŠ¿:\n\n\n\nä¼˜åŠ¿\nè¯´æ˜\n\n\n\næ— éœ€äººå·¥æ ‡æ³¨\næ•°æ®ç”±è™šæ‹Ÿä¸–ç•Œè‡ªåŠ¨ç”Ÿæˆ\n\n\né¢†åŸŸé€‚åº”\nç›´æ¥é€‚åº”ç‰¹å®šåº”ç”¨éœ€æ±‚\n\n\næˆæœ¬ä½\nå‡å°‘æ•°æ®æ ‡æ³¨å¼€é”€\n\n\nå¯æ‰©å±•\nå¯æ¨¡æ‹Ÿå¤§é‡åœºæ™¯å’Œæ—¶é—´\n\n\næ½œåœ¨åº”ç”¨: æ³•å¾‹å’¨è¯¢ã€é‡‘èæŠ•èµ„ã€æ•™è‚²åŸ¹è®­ã€å®¢æˆ·æœåŠ¡\n\nå››ã€ä¸‰å¤§åº”ç”¨æ‰©å±•å¯¹æ¯”4.1 æ ¸å¿ƒå·®å¼‚\n\n\nç»´åº¦\nVOYAGER\nProject Sid\nAgent Hospital\n\n\n\næ ¸å¿ƒç›®æ ‡\nç»ˆèº«å­¦ä¹ æŠ€èƒ½\nAIæ–‡æ˜æ¨¡æ‹Ÿ\nåŒ»ç–—æ™ºèƒ½ä½“è¿›åŒ–\n\n\nç¯å¢ƒ\nMinecraft\nMinecraft\nè™šæ‹ŸåŒ»é™¢\n\n\næ™ºèƒ½ä½“æ•°é‡\n1\n10-1000+\n46+\n\n\næ—¶é—´è·¨åº¦\næ•°å°æ—¶\n4å°æ—¶+\næŒç»­\n\n\nå­¦ä¹ æœºåˆ¶\næŠ€èƒ½åº“ç§¯ç´¯\nç¤¾ä¼šäº’åŠ¨\nç»éªŒåæ€\n\n\n4.2 åˆ›æ–°è´¡çŒ®\n\n\nè®ºæ–‡\næ ¸å¿ƒåˆ›æ–°\n\n\n\nVOYAGER\nä»£ç å³è®°å¿†ï¼ŒæŠ€èƒ½å¯ç»„åˆå¤ç”¨\n\n\nProject Sid\næ–‡æ˜è¿›æ­¥åŸºå‡†ï¼šä¸“ä¸šåŒ–ã€è§„åˆ™ã€æ–‡åŒ–\n\n\nAgent Hospital\næ™ºèƒ½ä½“èƒ½åŠ›å¯è¿›åŒ–ï¼Œè™šæ‹ŸæŠ€èƒ½è¿ç§»ç°å®\n\n\n4.3 é€‚ç”¨åœºæ™¯\n\n\nåœºæ™¯\næ¨èæ–¹æ³•\nåŸå› \n\n\n\nå¼€æ”¾ä¸–ç•Œæ¸¸æˆ\nVOYAGER\næŠ€èƒ½ç§¯ç´¯å’Œç»ˆèº«å­¦ä¹ \n\n\nç¤¾ä¼šç§‘å­¦ç ”ç©¶\nProject Sid\nå¤§è§„æ¨¡ç¤¾ä¼šåŠ¨æ€æ¨¡æ‹Ÿ\n\n\nä¸“ä¸šé¢†åŸŸAI\nAgent Hospital\nä»å®è·µä¸­æŒç»­è¿›åŒ–\n\n\nå¤šæ™ºèƒ½ä½“åä½œ\nProject Sid\nPIANOæ¶æ„æ”¯æŒä¸€è‡´æ€§\n\n\n\näº”ã€æŠ€æœ¯æ¼”è¿›è·¯çº¿5.1 ä»åŸºç¡€åˆ°åº”ç”¨åŸºç¡€æ¡†æ¶ (2022-2023):â”œâ”€â”€ ReAct: æ¨ç†+è¡ŒåŠ¨â”œâ”€â”€ Reflexion: è¯­è¨€åé¦ˆå­¦ä¹ â””â”€â”€ Generative Agents: è®°å¿†+åæ€åº”ç”¨æ‰©å±• (2023-2024):â”œâ”€â”€ VOYAGER: ç»ˆèº«å­¦ä¹  + æŠ€èƒ½åº“â”œâ”€â”€ Project Sid: å¤§è§„æ¨¡æ–‡æ˜æ¨¡æ‹Ÿâ””â”€â”€ Agent Hospital: ä¸“ä¸šé¢†åŸŸè¿›åŒ–æœªæ¥è¶‹åŠ¿ (2025+):â”œâ”€â”€ Agent OSåŒ–: AutoGen, LangGraphâ”œâ”€â”€ å¤šæ¨¡æ€èåˆ: è§†è§‰+è¯­è¨€+è¡ŒåŠ¨â””â”€â”€ å•†ä¸šåŒ–éƒ¨ç½²: Operator, Claude\n\n5.2 è§„æ¨¡æ¼”è¿›\n\n\næ—¶é—´\nè®ºæ–‡\næ™ºèƒ½ä½“æ•°é‡\næ¶Œç°ç°è±¡\n\n\n\n2023/04\nGenerative Agents\n25\nç¤¾äº¤è¡Œä¸º\n\n\n2023/05\nVOYAGER\n1\nç»ˆèº«å­¦ä¹ \n\n\n2024/05\nAgent Hospital\n46+\nèƒ½åŠ›è¿›åŒ–\n\n\n2024/10\nProject Sid\n500-1000+\næ–‡æ˜è¿›æ­¥\n\n\n5.3 å…³é”®æŠ€æœ¯çªç ´\n\n\nçªç ´\nè®ºæ–‡\næ„ä¹‰\n\n\n\nä»£ç ä½œä¸ºè®°å¿†\nVOYAGER\nå¯æ‰§è¡Œã€å¯ç»„åˆçš„çŸ¥è¯†è¡¨ç¤º\n\n\næ–‡æ˜è¿›æ­¥åŸºå‡†\nProject Sid\né‡åŒ–å¤šæ™ºèƒ½ä½“ç¤¾ä¼šèƒ½åŠ›\n\n\næ— æ ‡æ³¨è¿›åŒ–\nAgent Hospital\nä»å®è·µä¸­è‡ªåŠ¨å­¦ä¹ \n\n\nåƒæ™ºèƒ½ä½“è§„æ¨¡\nProject Sid\néªŒè¯å¤§è§„æ¨¡å¯è¡Œæ€§\n\n\n\nå…­ã€å®è·µå»ºè®®6.1 æŠ€æœ¯é€‰å‹\n\n\néœ€æ±‚\næ¨èæŠ€æœ¯æ ˆ\n\n\n\nå•æ™ºèƒ½ä½“æŠ€èƒ½å­¦ä¹ \nVOYAGER (æŠ€èƒ½åº“ + è¿­ä»£æç¤º)\n\n\nå¤šæ™ºèƒ½ä½“åä½œ\nProject Sid (PIANOæ¶æ„)\n\n\nä¸“ä¸šé¢†åŸŸåº”ç”¨\nAgent Hospital (SEALæ¡†æ¶)\n\n\né€šç”¨ä»»åŠ¡å®Œæˆ\nReAct + Reflexion\n\n\n6.2 æ¶æ„è®¾è®¡ç†æƒ³ç»„åˆ:\nç†æƒ³æ™ºèƒ½ä½“ = VOYAGERçš„æŠ€èƒ½åº“           + Project Sidçš„ç¤¾ä¼šæ„è¯†           + Agent Hospitalçš„è¿›åŒ–æœºåˆ¶           + Generative Agentsçš„è®°å¿†ç³»ç»Ÿ\n\n6.3 è§„æ¨¡åŒ–è€ƒè™‘\n\n\nè§„æ¨¡\nå…³é”®æŒ‘æˆ˜\nè§£å†³æ–¹æ¡ˆ\n\n\n\n1-10\nå•æ™ºèƒ½ä½“èƒ½åŠ›\næŠ€èƒ½åº“ + åæ€\n\n\n10-50\nåè°ƒä¸€è‡´æ€§\nPIANOæ¶æ„\n\n\n50-500\nè®¡ç®—èµ„æº\nå¹¶è¡Œæ¨¡å—\n\n\n500+\næ¶Œç°ç®¡ç†\næ–‡æ˜åŸºå‡†\n\n\n\nä¸ƒã€å…³é”®è®ºæ–‡åŸæ–‡å¼•ç”¨VOYAGER\nâ€œVOYAGER is the first LLM-powered embodied lifelong learning agent that explores the world, acquires diverse skills, and makes novel discoveries without human intervention.â€\n\nProject Sid\nâ€œWe show how 10-1000+ AI agents behave and progress in agent societies. These simulations reveal that agents can achieve meaningful progressâ€”autonomously developing specialized roles, adhering to and modifying collective rules, and engaging in cultural and religious propagation.â€\n\nAgent Hospital\nâ€œDoctor agents can evolve by treating a large number of patient agents, without the need for manually curated training data. After treating tens of thousands of patient agents (which may take several years for real-world doctors), the evolved doctor agents surpassed state-of-the-art medical AI methods on the MedQA benchmark.â€\n\n\nè¿”å›æ€»è§ˆ | ä¸Šä¸€ç¯‡ï¼šåŸºç¡€æ¡†æ¶ç¯‡\n","categories":["è®ºæ–‡è§£è¯»"],"tags":["LLM","Agent","è®ºæ–‡è§£è¯»","VOYAGER","Project Sid","Agent Hospital","ç»ˆèº«å­¦ä¹ ","AIæ–‡æ˜"]},{"title":"å¼€ç¯‡","url":"/2019/10/03/%E5%BC%80%E7%AF%87/","content":"å„ä½è¯»è€…æœ‹å‹ä»¬å¤§å®¶å¥½ï¼Œæˆ‘æ˜¯ fooSynapticã€‚\næ¬¢è¿æ¥åˆ°æˆ‘çš„æŠ€æœ¯åšå®¢ï¼è¿™é‡Œè®°å½•æˆ‘åœ¨ AI å’Œ NLP é¢†åŸŸçš„å­¦ä¹ ä¸æ€è€ƒã€‚\nå…³äºè¿™ä¸ªåšå®¢è¿™ä¸ªåšå®¢ä¸»è¦è®°å½•ä»¥ä¸‹å†…å®¹ï¼š\n\nè‡ªç„¶è¯­è¨€å¤„ç† (NLP)ï¼šä»ä¼ ç»Ÿæ–¹æ³•åˆ°å¤§è¯­è¨€æ¨¡å‹\næœºå™¨å­¦ä¹ ï¼šç®—æ³•åŸç†ä¸å®ç°ç»†èŠ‚\næ·±åº¦å­¦ä¹ ï¼šæ¨¡å‹æ¶æ„ä¸è®­ç»ƒæŠ€å·§\næ•°å­¦åŸºç¡€ï¼šçº¿æ€§ä»£æ•°ã€æ¦‚ç‡è®ºã€ä¼˜åŒ–ç†è®º\nå·¥ç¨‹å®è·µï¼šPythonã€PyTorchã€åˆ†å¸ƒå¼è®­ç»ƒ\n\næŠ€æœ¯æ ˆNLP: Transformers, LLMs, RAG, Prompt EngineeringML: PyTorch, JAX, scikit-learnInfra: CUDA, Triton, vLLM, DeepSpeed\n\nå…³äºæˆ‘NLP Researcherï¼Œä¸“æ³¨äºï¼š\n\nå¤§è¯­è¨€æ¨¡å‹ (LLM) è®­ç»ƒä¸æ¨ç†ä¼˜åŒ–\næ£€ç´¢å¢å¼ºç”Ÿæˆ (RAG)\næœºå™¨é˜…è¯»ç†è§£ä¸é—®ç­”ç³»ç»Ÿ\n\nGitHub: fooSynaptic\n\n\næ¬¢è¿äº¤æµè®¨è®ºï¼Œè½¬è½½è¯·æ³¨æ˜å‡ºå¤„\n\n","tags":["Introduction"]},{"title":"ç¥ç»ç½‘ç»œæœºå™¨é˜…è¯»ç†è§£ï¼šä» Attention åˆ° LLM","url":"/2019/11/22/Nuural-Approaches-to-Machine-Reading-Comprehension-and-Dialogue/","content":"æœ¬æ–‡ç»¼è¿°ç¥ç»ç½‘ç»œåœ¨æœºå™¨é˜…è¯»ç†è§£å’Œå¯¹è¯ç³»ç»Ÿä¸­çš„å‘å±•å†ç¨‹ï¼Œä»æ—©æœŸçš„æ³¨æ„åŠ›æœºåˆ¶åˆ°ç°ä»£å¤§è¯­è¨€æ¨¡å‹ã€‚\nå‘å±•æ—¶é—´çº¿2015-2016: æ³¨æ„åŠ›æœºåˆ¶å…´èµ·    â””â”€â”€ Attentive Reader, Impatient Reader, BiDAF2017-2018: æ·±åº¦äº¤äº’ä¸é¢„è®­ç»ƒ    â””â”€â”€ R-Net, QANet, BERT2019-2020: å¤§è§„æ¨¡é¢„è®­ç»ƒ    â””â”€â”€ RoBERTa, ALBERT, T52021-2023: å¤§è¯­è¨€æ¨¡å‹æ—¶ä»£    â””â”€â”€ GPT-3, ChatGPT, GPT-4, LLaMA2024-: æ£€ç´¢å¢å¼ºä¸å¤šæ¨¡æ€    â””â”€â”€ RAG, Vision-Language Models\n\næ ¸å¿ƒæŠ€æœ¯æ¼”è¿›é˜¶æ®µä¸€ï¼šæ³¨æ„åŠ›æœºåˆ¶ (2015-2017)é—®é¢˜ï¼šå¦‚ä½•è®©æ¨¡å‹â€å…³æ³¨â€ä¸é—®é¢˜ç›¸å…³çš„ä¸Šä¸‹æ–‡ï¼Ÿ\n\n\nä»£è¡¨æ¨¡å‹ï¼šAttentive Reader, BiDAF\né˜¶æ®µäºŒï¼šæ·±åº¦äº¤äº’ (2017-2018)é—®é¢˜ï¼šå¦‚ä½•å»ºæ¨¡é—®é¢˜å’Œä¸Šä¸‹æ–‡çš„å¤æ‚äº¤äº’ï¼Ÿ\næŠ€æœ¯ï¼šå¤šè½®æ³¨æ„åŠ›ã€è‡ªæ³¨æ„åŠ›ã€é—¨æ§æœºåˆ¶\n# å¤šè½®æ¨ç† (R-Net é£æ ¼)for layer in range(num_layers):    # è‡ªæ³¨æ„åŠ›    context = self_attention(context, context)    # äº¤å‰æ³¨æ„åŠ›    context = cross_attention(context, question)\n\né˜¶æ®µä¸‰ï¼šé¢„è®­ç»ƒè¯­è¨€æ¨¡å‹ (2018-2020)èŒƒå¼è½¬å˜ï¼šä» task-specific åˆ° pretrain-finetune\n$$\\theta^* = \\arg\\min_\\theta \\mathcal{L}{task}(\\text{PLM}\\theta(x), y)$$\nä»£è¡¨æ¨¡å‹ï¼šBERT, RoBERTa, ALBERT\nfrom transformers import AutoModelForQuestionAnsweringmodel = AutoModelForQuestionAnswering.from_pretrained(\"bert-base-uncased\")# Fine-tune on SQuAD\n\né˜¶æ®µå››ï¼šå¤§è¯­è¨€æ¨¡å‹ (2020-è‡³ä»Š)èŒƒå¼è½¬å˜ï¼šä» fine-tuning åˆ° prompting\n# Few-shot promptingprompt = \"\"\"Context: The Eiffel Tower was built in 1889.Question: When was the Eiffel Tower built?Answer: 1889Context: {context}Question: {question}Answer:\"\"\"\n\næ¶æ„å¯¹æ¯”\n\n\næ¨¡å‹\nå‚æ•°é‡\nè®­ç»ƒèŒƒå¼\nSQuAD 2.0 F1\n\n\n\nBiDAF\n~2M\nä»é›¶è®­ç»ƒ\n77.3\n\n\nBERT-base\n110M\né¢„è®­ç»ƒ+å¾®è°ƒ\n88.5\n\n\nBERT-large\n340M\né¢„è®­ç»ƒ+å¾®è°ƒ\n90.9\n\n\nRoBERTa-large\n355M\né¢„è®­ç»ƒ+å¾®è°ƒ\n91.4\n\n\nGPT-3\n175B\nFew-shot\n~88\n\n\nGPT-4\n~1.8T\nZero-shot\n~95\n\n\nç°ä»£ MRC ç³»ç»Ÿè®¾è®¡RAG æ¶æ„class ModernMRC:    def __init__(self, retriever, reader):        self.retriever = retriever  # Dense retriever        self.reader = reader        # LLM        def answer(self, question: str, knowledge_base: str = None):        # 1. æ£€ç´¢        if knowledge_base:            docs = self.retriever.retrieve(question, knowledge_base)            context = \"\\n\\n\".join([d.text for d in docs])        else:            context = \"\"                # 2. é˜…è¯»ç†è§£/ç”Ÿæˆ        prompt = self._build_prompt(question, context)        answer = self.reader.generate(prompt)                # 3. åå¤„ç†ï¼ˆå¯é€‰ï¼šéªŒè¯ã€å¼•ç”¨ï¼‰        return self._postprocess(answer, docs)        def _build_prompt(self, question, context):        if context:            return f\"\"\"Based on the following context, answer the question.Context:{context}Question: {question}Answer:\"\"\"        else:            return f\"Question: {question}\\nAnswer:\"\n\nå¤šè·³æ¨ç†class MultiHopReasoner:    def __init__(self, retriever, llm, max_hops=3):        self.retriever = retriever        self.llm = llm        self.max_hops = max_hops        def reason(self, question):        reasoning_chain = []        current_query = question                for hop in range(self.max_hops):            # æ£€ç´¢            docs = self.retriever.retrieve(current_query)                        # ç”Ÿæˆä¸­é—´æ¨ç†            intermediate = self.llm.generate(                f\"Based on: {docs}\\nQuestion: {current_query}\\n\"                f\"Provide intermediate reasoning or the final answer:\"            )                        reasoning_chain.append({                'query': current_query,                'docs': docs,                'reasoning': intermediate            })                        # æ£€æŸ¥æ˜¯å¦å·²å¾—åˆ°ç­”æ¡ˆ            if self._is_final_answer(intermediate):                break                        # ç”Ÿæˆä¸‹ä¸€è·³æŸ¥è¯¢            current_query = self._generate_next_query(question, reasoning_chain)                return self._synthesize_answer(question, reasoning_chain)\n\nå¯¹è¯ç³»ç»Ÿä¸­çš„ MRCå¯¹è¯å¼é—®ç­”class ConversationalQA:    def __init__(self, mrc_model, history_length=5):        self.mrc_model = mrc_model        self.history = []        self.history_length = history_length        def ask(self, question, context=None):        # å°†å¯¹è¯å†å²çº³å…¥é—®é¢˜        contextualized_question = self._contextualize(question)                # è·å–ç­”æ¡ˆ        answer = self.mrc_model.answer(contextualized_question, context)                # æ›´æ–°å†å²        self.history.append({'q': question, 'a': answer})        if len(self.history) &gt; self.history_length:            self.history.pop(0)                return answer        def _contextualize(self, question):        if not self.history:            return question                history_text = \"\\n\".join([            f\"Q: {turn['q']}\\nA: {turn['a']}\"            for turn in self.history        ])                return f\"Conversation history:\\n{history_text}\\n\\nCurrent question: {question}\"\n\nè¯„ä¼°ä½“ç³»ä¼ ç»ŸæŒ‡æ ‡\n\n\næŒ‡æ ‡\nå®šä¹‰\né€‚ç”¨åœºæ™¯\n\n\n\nEM\nç²¾ç¡®åŒ¹é…\næŠ½å–å¼ QA\n\n\nF1\nToken é‡å \næŠ½å–å¼ QA\n\n\nBLEU\nN-gram é‡å \nç”Ÿæˆå¼ QA\n\n\nROUGE\nå¬å›å¯¼å‘é‡å \næ‘˜è¦ã€é•¿ç­”æ¡ˆ\n\n\nLLM æ—¶ä»£æŒ‡æ ‡# LLM-as-Judgedef llm_evaluate(question, reference, prediction):    prompt = f\"\"\"Evaluate the answer quality on a scale of 1-5:Question: {question}Reference Answer: {reference}Model Answer: {prediction}Criteria:- Correctness: Is the information accurate?- Completeness: Does it fully answer the question?- Conciseness: Is it appropriately brief?Score (1-5):\"\"\"        return llm.generate(prompt)\n\nå»¶ä¼¸é˜…è¯»\nReading Wikipedia to Answer Open-Domain Questions\nRAG Paper\nHotpotQA: Multi-hop Reasoning\nRetrieval-Augmented Generation for Knowledge-Intensive NLP Tasks\n\n\n\nè½¬è½½è¯·æ³¨æ˜å‡ºå¤„\n\n","tags":["LLM","MRC","Deep learning","KBQA"]},{"title":"æœºå™¨é˜…è¯»ç†è§£ï¼šä»ä¼ ç»Ÿæ–¹æ³•åˆ°å¤§è¯­è¨€æ¨¡å‹","url":"/2019/10/03/%E5%BD%93%E6%88%91%E4%BB%AC%E6%8A%8A%E7%9B%AE%E5%85%89%E6%94%BE%E5%9C%A8%E6%9C%BA%E5%99%A8%E9%98%85%E8%AF%BB%E7%90%86%E8%A7%A3%EF%BC%8C%E6%88%91%E4%BB%AC%E7%9A%84%E6%9C%9F%E6%9C%9B%E5%88%B0%E5%BA%95%E6%98%AF%E4%BB%80%E4%B9%88%EF%BC%9F/","content":"\næ ¸å¿ƒé—®é¢˜ï¼šå½“æˆ‘ä»¬æœŸæœ›æœºå™¨â€ç†è§£â€æ–‡æœ¬æ—¶ï¼Œæˆ‘ä»¬çš„æœŸæœ›åˆ°åº•æ˜¯ä»€ä¹ˆï¼Ÿ\n\næœºå™¨é˜…è¯»ç†è§£çš„æ¼”è¿›ä¼ ç»Ÿ MRC (2015-2019)åŸºäº span extraction çš„æ–¹æ³•ï¼š\nè¾“å…¥: Context + Questionè¾“å‡º: (start_idx, end_idx)\n\nä»£è¡¨æ¨¡å‹ï¼šBiDAF, R-Net, QANet, BERT\nLLM æ—¶ä»£çš„ MRC (2020-è‡³ä»Š)ä»â€æŠ½å–â€åˆ°â€ç”Ÿæˆâ€çš„èŒƒå¼è½¬å˜ï¼š\nè¾“å…¥: Context + Question + Instructionè¾“å‡º: è‡ªç”±å½¢å¼çš„ç­”æ¡ˆ\n\nä»»åŠ¡åˆ†ç±»ä¸éš¾åº¦\n\n\nç±»å‹\nä¼ ç»Ÿæ–¹æ³•\nLLM æ–¹æ³•\néš¾åº¦\n\n\n\næŠ½å–å¼\nâœ… æ“…é•¿\nâœ… æ“…é•¿\nâ­\n\n\nå¤šè·³æ¨ç†\nâŒ å›°éš¾\nâš ï¸ æœ‰é™\nâ­â­â­\n\n\næ•°å€¼æ¨ç†\nâŒ å‡ ä¹ä¸èƒ½\nâš ï¸ éœ€è¦ CoT\nâ­â­â­â­\n\n\nå¸¸è¯†æ¨ç†\nâŒ ä¸èƒ½\nâœ… è¾ƒå¥½\nâ­â­â­\n\n\nå¼€æ”¾ç”Ÿæˆ\nâŒ ä¸èƒ½\nâœ… æ“…é•¿\nâ­â­\n\n\nç°ä»£æ–¹æ³•ï¼šRAGæ£€ç´¢å¢å¼ºç”Ÿæˆ (Retrieval-Augmented Generation) ç»“åˆäº†æ£€ç´¢å’Œç”Ÿæˆçš„ä¼˜åŠ¿ï¼š\nclass RAGSystem:    def __init__(self, retriever, generator):        self.retriever = retriever  # e.g., Dense Retriever        self.generator = generator  # e.g., LLM        def answer(self, question: str) -&gt; str:        # 1. æ£€ç´¢ç›¸å…³æ–‡æ¡£        docs = self.retriever.retrieve(question, top_k=5)                # 2. æ„å»ºä¸Šä¸‹æ–‡        context = \"\\n\\n\".join([d.text for d in docs])                # 3. ç”Ÿæˆç­”æ¡ˆ        prompt = f\"\"\"åŸºäºä»¥ä¸‹æ–‡æ¡£å›ç­”é—®é¢˜ï¼š{context}é—®é¢˜ï¼š{question}ç­”æ¡ˆï¼š\"\"\"                return self.generator.generate(prompt)\n\næ£€ç´¢å™¨é€‰æ‹©\n\n\næ£€ç´¢å™¨\nç‰¹ç‚¹\né€‚ç”¨åœºæ™¯\n\n\n\nBM25\nå…³é”®è¯åŒ¹é…ï¼Œå¿«é€Ÿ\nçŸ­æŸ¥è¯¢ï¼Œç²¾ç¡®åŒ¹é…\n\n\nDense Retriever\nè¯­ä¹‰åŒ¹é…\nè¯­ä¹‰ç›¸ä¼¼æŸ¥è¯¢\n\n\nColBERT\nå»¶è¿Ÿäº¤äº’\nå¹³è¡¡æ•ˆç‡ä¸æ•ˆæœ\n\n\nHybrid\nç»“åˆç¨€ç–+ç¨ å¯†\nç”Ÿäº§ç¯å¢ƒ\n\n\nChain-of-Thought æ¨ç†å¯¹äºéœ€è¦æ¨ç†çš„é—®é¢˜ï¼ŒCoT prompting æ˜¾è‘—æå‡æ•ˆæœï¼š\n# æ ‡å‡† Promptingprompt_standard = \"Q: å°æ˜æœ‰5ä¸ªè‹¹æœï¼Œç»™äº†å°çº¢2ä¸ªï¼Œè¿˜å‰©å‡ ä¸ªï¼Ÿ\\nA:\"# Chain-of-Thought Prompting  prompt_cot = \"\"\"Q: å°æ˜æœ‰5ä¸ªè‹¹æœï¼Œç»™äº†å°çº¢2ä¸ªï¼Œè¿˜å‰©å‡ ä¸ªï¼ŸA: è®©æˆ‘ä»¬ä¸€æ­¥æ­¥æ€è€ƒï¼š1. å°æ˜æœ€åˆæœ‰ 5 ä¸ªè‹¹æœ2. ä»–ç»™äº†å°çº¢ 2 ä¸ªè‹¹æœ3. å‰©ä½™è‹¹æœæ•° = 5 - 2 = 3ç­”æ¡ˆæ˜¯ 3 ä¸ªè‹¹æœã€‚\"\"\"\n\nè¯„ä¼°æŒ‡æ ‡ä¼ ç»ŸæŒ‡æ ‡\nğŸ™\nLLM æ—¶ä»£çš„æŒ‡æ ‡# ä½¿ç”¨ LLM ä½œä¸ºè¯„ä¼°å™¨def llm_evaluate(question, gold_answer, pred_answer):    prompt = f\"\"\"è¯„ä¼°é¢„æµ‹ç­”æ¡ˆçš„è´¨é‡ï¼ˆ1-5åˆ†ï¼‰ï¼šé—®é¢˜ï¼š{question}æ ‡å‡†ç­”æ¡ˆï¼š{gold_answer}é¢„æµ‹ç­”æ¡ˆï¼š{pred_answer}è¯„åˆ†æ ‡å‡†ï¼š5åˆ† - å®Œå…¨æ­£ç¡®ä¸”ä¿¡æ¯å®Œæ•´4åˆ† - åŸºæœ¬æ­£ç¡®ï¼Œç•¥æœ‰é—æ¼3åˆ† - éƒ¨åˆ†æ­£ç¡®2åˆ† - æœ‰ç›¸å…³ä¿¡æ¯ä½†ä¸æ­£ç¡®1åˆ† - å®Œå…¨é”™è¯¯åˆ†æ•°ï¼š\"\"\"    return llm.generate(prompt)\n\nå®è·µå»ºè®®ä½•æ—¶ç”¨ä¼ ç»Ÿ MRC\nç­”æ¡ˆæ˜ç¡®åœ¨æ–‡æ¡£ä¸­\néœ€è¦ç²¾ç¡®çš„ä½ç½®æ ‡æ³¨\nä½å»¶è¿Ÿè¦æ±‚\nèµ„æºå—é™\n\nä½•æ—¶ç”¨ RAG + LLM\néœ€è¦æ•´åˆå¤šä¸ªæ–‡æ¡£\nç­”æ¡ˆéœ€è¦æ¨ç†æˆ–æ€»ç»“\nå¼€æ”¾åŸŸé—®ç­”\nç”¨æˆ·æœŸæœ›è‡ªç„¶è¯­è¨€å›ç­”\n\nä»£ç ç¤ºä¾‹ï¼šç°ä»£ RAG ç³»ç»Ÿfrom langchain.vectorstores import FAISSfrom langchain.embeddings import OpenAIEmbeddingsfrom langchain.chat_models import ChatOpenAIfrom langchain.chains import RetrievalQA# åˆå§‹åŒ–ç»„ä»¶embeddings = OpenAIEmbeddings()vectorstore = FAISS.load_local(\"my_index\", embeddings)llm = ChatOpenAI(model=\"gpt-4\", temperature=0)# åˆ›å»º RAG é“¾qa_chain = RetrievalQA.from_chain_type(    llm=llm,    chain_type=\"stuff\",  # æˆ– \"map_reduce\", \"refine\"    retriever=vectorstore.as_retriever(search_kwargs={\"k\": 5}),    return_source_documents=True)# ä½¿ç”¨result = qa_chain({\"query\": \"ä»€ä¹ˆæ˜¯æœºå™¨é˜…è¯»ç†è§£ï¼Ÿ\"})print(result[\"result\"])\n\nå»¶ä¼¸é˜…è¯»\nSQuAD 2.0\nNatural Questions\nRAG Paper\nLangChain Documentation\n\n\n\nè½¬è½½è¯·æ³¨æ˜å‡ºå¤„\n\n","tags":["LLM","MRC","Deep learning","RAG"]},{"title":"BiDAF è®ºæ–‡è§£è¯»ï¼šåŒå‘æ³¨æ„åŠ›æµæœºåˆ¶","url":"/2019/11/19/%E8%AE%BA%E6%96%87%E6%A2%97%E6%A6%82%EF%BC%9ABi-Directional-Attention-Flow-for-Machine-Comprehension/","content":"BiDAF (Bi-Directional Attention Flow) æ˜¯æœºå™¨é˜…è¯»ç†è§£é¢†åŸŸçš„ç»å…¸æ¨¡å‹ï¼Œå…¶åŒå‘æ³¨æ„åŠ›æœºåˆ¶å¯¹åç»­ Transformer æ¶æ„äº§ç”Ÿäº†æ·±è¿œå½±å“ã€‚\næ ¸å¿ƒåˆ›æ–°1. Memory-less Attentionä¼ ç»ŸåŠ¨æ€æ³¨æ„åŠ› vs BiDAF çš„æ— è®°å¿†æ³¨æ„åŠ›ï¼š\n\n\n\nç‰¹æ€§\nDynamic Attention\nMemory-less Attention\n\n\n\nä¾èµ–\nå‰ä¸€æ—¶é—´æ­¥çš„ attended vector\nä»…å½“å‰ query å’Œ context\n\n\nä¼˜åŠ¿\nå¯å»ºæ¨¡æ—¶åºä¾èµ–\né¿å…é”™è¯¯ç´¯ç§¯\n\n\nç¼ºç‚¹\né”™è¯¯ä¼šä¼ æ’­\næ— æ³•å»ºæ¨¡é•¿ç¨‹ä¾èµ–\n\n\n2. åŒå‘æ³¨æ„åŠ›åŒæ—¶è®¡ç®—ï¼š\n\nContext-to-Query (C2Q)ï¼šæ¯ä¸ª context è¯æœ€ç›¸å…³çš„ query è¯\nQuery-to-Context (Q2C)ï¼šå¯¹å›ç­”é—®é¢˜æœ€å…³é”®çš„ context è¯\n\næ¨¡å‹æ¶æ„Input â†’ Embedding â†’ Encoding â†’ Attention â†’ Modeling â†’ Output  â”‚         â”‚           â”‚          â”‚           â”‚         â”‚ è¯å‘é‡    å­—ç¬¦CNN     BiLSTM    åŒå‘æ³¨æ„åŠ›   BiLSTM   Spané¢„æµ‹\n\næ•°å­¦è¡¨è¾¾ç›¸ä¼¼åº¦çŸ©é˜µï¼š\n\nå…¶ä¸­  æ˜¯ context è¡¨ç¤ºï¼Œ æ˜¯ query è¡¨ç¤ºã€‚\nC2Q Attentionï¼š\n$$\\tilde{U}i = \\sum_j a{ij} U_j, \\quad a_i = \\text{softmax}(S_i)$$\nQ2C Attentionï¼š\n\nèåˆè¡¨ç¤ºï¼š\n\nPyTorch å®ç°import torchimport torch.nn as nnclass BiDAFAttention(nn.Module):    def __init__(self, hidden_size):        super().__init__()        self.W = nn.Linear(hidden_size * 3, 1, bias=False)        def forward(self, context, query, c_mask, q_mask):        \"\"\"        Args:            context: (batch, c_len, hidden)            query: (batch, q_len, hidden)            c_mask: (batch, c_len)            q_mask: (batch, q_len)        \"\"\"        batch, c_len, hidden = context.size()        q_len = query.size(1)                # æ‰©å±•ç»´åº¦ä»¥è®¡ç®—æ‰€æœ‰ (i, j) å¯¹        c_expand = context.unsqueeze(2).expand(-1, -1, q_len, -1)        q_expand = query.unsqueeze(1).expand(-1, c_len, -1, -1)                # è®¡ç®—ç›¸ä¼¼åº¦çŸ©é˜µ S        cq = torch.cat([c_expand, q_expand, c_expand * q_expand], dim=-1)        S = self.W(cq).squeeze(-1)  # (batch, c_len, q_len)                # Mask        q_mask_expand = q_mask.unsqueeze(1).expand(-1, c_len, -1)        S = S.masked_fill(~q_mask_expand, -1e9)                # C2Q attention        a = torch.softmax(S, dim=-1)        c2q = torch.bmm(a, query)  # (batch, c_len, hidden)                # Q2C attention        b = torch.softmax(S.max(dim=-1)[0], dim=-1)        q2c = torch.bmm(b.unsqueeze(1), context)  # (batch, 1, hidden)        q2c = q2c.expand(-1, c_len, -1)                # èåˆ        G = torch.cat([context, c2q, context * c2q, context * q2c], dim=-1)                return G\n\nä¸ Transformer çš„å¯¹æ¯”\n\n\nç‰¹æ€§\nBiDAF\nTransformer\n\n\n\næ³¨æ„åŠ›æ–¹å‘\nåŒå‘ï¼ˆC2Q, Q2Cï¼‰\nå…¨æ–¹å‘è‡ªæ³¨æ„åŠ›\n\n\nä½ç½®ç¼–ç \nBiLSTM éšå¼ç¼–ç \næ˜¾å¼ä½ç½®ç¼–ç \n\n\nå¹¶è¡ŒåŒ–\nå—é™äº RNN\nå®Œå…¨å¹¶è¡Œ\n\n\né•¿è·ç¦»ä¾èµ–\nå—é™\nç†è®ºä¸Šæ— é™\n\n\nå‚æ•°é‡\nè¾ƒå°‘\nè¾ƒå¤š\n\n\nç°ä»£æ¼”è¿›BiDAF çš„æ€æƒ³åœ¨ç°ä»£æ¨¡å‹ä¸­çš„ä½“ç°ï¼š\n1. Cross-Attention in Transformerclass CrossAttention(nn.Module):    def __init__(self, d_model, n_heads):        super().__init__()        self.mha = nn.MultiheadAttention(d_model, n_heads)        def forward(self, query, key_value):        # query æ¥è‡ªä¸€ä¸ªåºåˆ—ï¼Œkey/value æ¥è‡ªå¦ä¸€ä¸ªåºåˆ—        return self.mha(query, key_value, key_value)\n\n2. FiD (Fusion-in-Decoder)ç”¨äº RAG çš„æ¶æ„ï¼Œç±»ä¼¼ BiDAF çš„èåˆæ€æƒ³ï¼š\nclass FiD(nn.Module):    def __init__(self, encoder, decoder):        super().__init__()        self.encoder = encoder        self.decoder = decoder        def forward(self, question, passages):        # ç‹¬ç«‹ç¼–ç æ¯ä¸ª passage        encoded = []        for passage in passages:            enc = self.encoder(question + passage)            encoded.append(enc)                # èåˆè§£ç         fused = torch.cat(encoded, dim=1)        return self.decoder(fused)\n\nå®éªŒç»“æœï¼ˆåŸè®ºæ–‡ï¼‰åœ¨ SQuAD 1.1 ä¸Šçš„è¡¨ç°ï¼š\n\n\n\næ¨¡å‹\nEM\nF1\n\n\n\nBiDAF\n67.7\n77.3\n\n\nBiDAF + Self Attention\n72.1\n81.1\n\n\nBERT-base\n80.8\n88.5\n\n\nGPT-4 (few-shot)\n~90\n~95\n\n\nå»¶ä¼¸é˜…è¯»\nBiDAF Paper\nAttention Is All You Need\nBERT for QA\n\n\n\nè½¬è½½è¯·æ³¨æ˜å‡ºå¤„\n\n","tags":["MRC","attention","deep learning"]},{"title":"æ¡ä»¶éšæœºåœºï¼šåŸç†ä¸å®ç°","url":"/2019/11/19/%E6%9D%A1%E4%BB%B6%E9%9A%8F%E6%9C%BA%E5%9C%BA%E7%9A%84%E5%8E%9F%E7%90%86%E4%BB%A5%E5%8F%8A%E4%BB%8E%E9%9B%B6%E5%AE%9E%E7%8E%B0/","content":"æ¡ä»¶éšæœºåœº (CRF) æ˜¯åºåˆ—æ ‡æ³¨çš„ç»å…¸æ¨¡å‹ï¼Œå°½ç®¡æ·±åº¦å­¦ä¹ æ—¶ä»£ BERT ç­‰æ¨¡å‹å¤§æ”¾å¼‚å½©ï¼ŒCRF å±‚ä»ç„¶åœ¨ NERã€è¯æ€§æ ‡æ³¨ç­‰ä»»åŠ¡ä¸­å‘æŒ¥å…³é”®ä½œç”¨ã€‚\nä¸ºä»€ä¹ˆéœ€è¦ CRFï¼Ÿç‹¬ç«‹åˆ†ç±»çš„é—®é¢˜å¦‚æœå¯¹æ¯ä¸ªä½ç½®ç‹¬ç«‹åˆ†ç±»ï¼š\n\nä¼šå¯¼è‡´æ ‡ç­¾ä¸ä¸€è‡´ï¼Œä¾‹å¦‚ï¼š\nè¾“å…¥: \"åŒ— äº¬ æ˜¯ ä¸­ å›½ é¦– éƒ½\"é”™è¯¯: B-LOC I-PER O B-LOC I-LOC I-LOC I-LOCæ­£ç¡®: B-LOC I-LOC O B-LOC I-LOC I-LOC I-LOC\n\nCRF çš„è§£å†³æ–¹æ¡ˆCRF å»ºæ¨¡æ•´ä¸ªåºåˆ—çš„è”åˆæ¦‚ç‡ï¼Œè€ƒè™‘æ ‡ç­¾ä¹‹é—´çš„è½¬ç§»çº¦æŸã€‚\næ•°å­¦åŸç†æ¡ä»¶æ¦‚ç‡\nå…¶ä¸­ï¼š\n\nï¼šå‘å°„åˆ†æ•°ï¼ˆemission scoreï¼‰\nï¼šè½¬ç§»åˆ†æ•°ï¼ˆtransition scoreï¼‰\nï¼šé…åˆ†å‡½æ•°ï¼ˆå½’ä¸€åŒ–é¡¹ï¼‰\n\né…åˆ†å‡½æ•°\nç›´æ¥è®¡ç®—å¤æ‚åº¦ä¸º ï¼Œä½¿ç”¨å‰å‘ç®—æ³•å¯é™è‡³ ã€‚\nPyTorch å®ç°CRF Layerimport torchimport torch.nn as nnclass CRF(nn.Module):    def __init__(self, num_tags, batch_first=True):        super().__init__()        self.num_tags = num_tags        self.batch_first = batch_first                # è½¬ç§»çŸ©é˜µ: transitions[i, j] = ä»æ ‡ç­¾ j è½¬ç§»åˆ°æ ‡ç­¾ i çš„åˆ†æ•°        self.transitions = nn.Parameter(torch.randn(num_tags, num_tags))                # èµ·å§‹å’Œç»“æŸè½¬ç§»        self.start_transitions = nn.Parameter(torch.randn(num_tags))        self.end_transitions = nn.Parameter(torch.randn(num_tags))        def forward(self, emissions, tags, mask=None):        \"\"\"è®¡ç®—è´Ÿå¯¹æ•°ä¼¼ç„¶æŸå¤±\"\"\"        if mask is None:            mask = torch.ones_like(tags, dtype=torch.bool)                if self.batch_first:            emissions = emissions.transpose(0, 1)            tags = tags.transpose(0, 1)            mask = mask.transpose(0, 1)                # è®¡ç®—åˆ†å­ï¼ˆæ­£ç¡®è·¯å¾„çš„åˆ†æ•°ï¼‰        numerator = self._compute_score(emissions, tags, mask)                # è®¡ç®—åˆ†æ¯ï¼ˆé…åˆ†å‡½æ•°ï¼‰        denominator = self._compute_normalizer(emissions, mask)                # è´Ÿå¯¹æ•°ä¼¼ç„¶        return (denominator - numerator).mean()        def _compute_score(self, emissions, tags, mask):        \"\"\"è®¡ç®—ç»™å®šæ ‡ç­¾åºåˆ—çš„åˆ†æ•°\"\"\"        seq_len, batch_size = tags.shape                # èµ·å§‹åˆ†æ•°        score = self.start_transitions[tags[0]]        score += emissions[0, torch.arange(batch_size), tags[0]]                for i in range(1, seq_len):            # è½¬ç§»åˆ†æ•° + å‘å°„åˆ†æ•°            score += self.transitions[tags[i], tags[i-1]] * mask[i]            score += emissions[i, torch.arange(batch_size), tags[i]] * mask[i]                # ç»“æŸåˆ†æ•°        last_tag_idx = mask.sum(dim=0) - 1        last_tags = tags.gather(0, last_tag_idx.unsqueeze(0)).squeeze(0)        score += self.end_transitions[last_tags]                return score        def _compute_normalizer(self, emissions, mask):        \"\"\"å‰å‘ç®—æ³•è®¡ç®—é…åˆ†å‡½æ•°\"\"\"        seq_len, batch_size, num_tags = emissions.shape                # åˆå§‹åŒ–        score = self.start_transitions + emissions[0]                for i in range(1, seq_len):            # broadcast: (batch, num_tags, 1) + (num_tags, num_tags) + (batch, 1, num_tags)            broadcast_score = score.unsqueeze(2)            broadcast_emissions = emissions[i].unsqueeze(1)                        next_score = broadcast_score + self.transitions + broadcast_emissions            next_score = torch.logsumexp(next_score, dim=1)                        # åº”ç”¨ mask            score = torch.where(mask[i].unsqueeze(1), next_score, score)                # æ·»åŠ ç»“æŸåˆ†æ•°        score += self.end_transitions                return torch.logsumexp(score, dim=1)        def decode(self, emissions, mask=None):        \"\"\"Viterbi è§£ç \"\"\"        if mask is None:            mask = torch.ones(emissions.shape[:2], dtype=torch.bool, device=emissions.device)                if self.batch_first:            emissions = emissions.transpose(0, 1)            mask = mask.transpose(0, 1)                return self._viterbi_decode(emissions, mask)        def _viterbi_decode(self, emissions, mask):        \"\"\"Viterbi ç®—æ³•\"\"\"        seq_len, batch_size, num_tags = emissions.shape                # åˆå§‹åŒ–        score = self.start_transitions + emissions[0]        history = []                for i in range(1, seq_len):            broadcast_score = score.unsqueeze(2)            broadcast_emissions = emissions[i].unsqueeze(1)                        next_score = broadcast_score + self.transitions + broadcast_emissions            next_score, indices = next_score.max(dim=1)                        score = torch.where(mask[i].unsqueeze(1), next_score, score)            history.append(indices)                # æ·»åŠ ç»“æŸåˆ†æ•°        score += self.end_transitions                # å›æº¯        best_tags_list = []        _, best_last_tag = score.max(dim=1)                for idx in range(batch_size):            best_tags = [best_last_tag[idx].item()]            seq_length = int(mask[:, idx].sum().item())                        for hist in reversed(history[:seq_length-1]):                best_last_tag_idx = best_tags[-1]                best_tags.append(hist[idx, best_last_tag_idx].item())                        best_tags.reverse()            best_tags_list.append(best_tags)                return best_tags_list\n\nä¸ BiLSTM ç»“åˆclass BiLSTM_CRF(nn.Module):    def __init__(self, vocab_size, embed_dim, hidden_dim, num_tags):        super().__init__()        self.embedding = nn.Embedding(vocab_size, embed_dim)        self.lstm = nn.LSTM(embed_dim, hidden_dim // 2,                            num_layers=2, bidirectional=True, batch_first=True)        self.fc = nn.Linear(hidden_dim, num_tags)        self.crf = CRF(num_tags)        def forward(self, x, tags, mask=None):        embeddings = self.embedding(x)        lstm_out, _ = self.lstm(embeddings)        emissions = self.fc(lstm_out)                return self.crf(emissions, tags, mask)        def predict(self, x, mask=None):        embeddings = self.embedding(x)        lstm_out, _ = self.lstm(embeddings)        emissions = self.fc(lstm_out)                return self.crf.decode(emissions, mask)\n\nç°ä»£åº”ç”¨ï¼šBERT + CRFå°½ç®¡ BERT å·²ç»å¾ˆå¼ºå¤§ï¼Œä½† CRF å±‚ä»èƒ½å¸¦æ¥ä¸€è‡´æ€§æå‡ï¼š\nfrom transformers import BertModelclass BERT_CRF(nn.Module):    def __init__(self, bert_name, num_tags):        super().__init__()        self.bert = BertModel.from_pretrained(bert_name)        self.dropout = nn.Dropout(0.1)        self.fc = nn.Linear(self.bert.config.hidden_size, num_tags)        self.crf = CRF(num_tags)        def forward(self, input_ids, attention_mask, tags=None):        outputs = self.bert(input_ids, attention_mask=attention_mask)        sequence_output = self.dropout(outputs.last_hidden_state)        emissions = self.fc(sequence_output)                if tags is not None:            return self.crf(emissions, tags, attention_mask.bool())        else:            return self.crf.decode(emissions, attention_mask.bool())\n\næ€§èƒ½å¯¹æ¯”ï¼ˆCoNLL-2003 NERï¼‰\n\n\næ¨¡å‹\nF1\n\n\n\nBiLSTM\n88.2\n\n\nBiLSTM + CRF\n90.1\n\n\nBERT\n92.4\n\n\nBERT + CRF\n92.8\n\n\nRoBERTa + CRF\n93.2\n\n\nè®­ç»ƒæŠ€å·§1. æ ‡ç­¾å¹³æ»‘def label_smoothing_loss(crf, emissions, tags, mask, epsilon=0.1):    \"\"\"å¸¦æ ‡ç­¾å¹³æ»‘çš„ CRF æŸå¤±\"\"\"    nll_loss = crf(emissions, tags, mask)        # å‡åŒ€åˆ†å¸ƒçš„æŸå¤±    uniform_loss = -torch.logsumexp(emissions, dim=-1).mean()        return (1 - epsilon) * nll_loss + epsilon * uniform_loss\n\n2. çº¦æŸè§£ç # æ·»åŠ ç¡¬çº¦æŸï¼šB-X åé¢åªèƒ½æ¥ I-X æˆ– Odef add_constraints(transitions, tag2idx):    for tag_from, idx_from in tag2idx.items():        for tag_to, idx_to in tag2idx.items():            if tag_from.startswith('B-') or tag_from.startswith('I-'):                entity = tag_from[2:]                if tag_to.startswith('I-') and tag_to[2:] != entity:                    transitions.data[idx_to, idx_from] = -1e9\n\nå»¶ä¼¸é˜…è¯»\nLafferty et al., Conditional Random Fields (2001)\nHuang et al., Bidirectional LSTM-CRF Models for Sequence Tagging (2015)\npytorch-crf Documentation\n\n\n\nè½¬è½½è¯·æ³¨æ˜å‡ºå¤„\n\n","tags":["NLP","machine learning","CRF"]},{"title":"çŸ©é˜µåˆ†è§£ï¼šä» SVD åˆ°ç°ä»£ AI åº”ç”¨","url":"/2019/10/03/%E7%9F%A9%E9%98%B5%E5%88%86%E8%A7%A3%E4%B9%8B%E4%B8%80%EF%BC%9ATruncate-SVD-%E5%92%8Crandom-SVD/","content":"çŸ©é˜µåˆ†è§£æ˜¯æœºå™¨å­¦ä¹ çš„åŸºçŸ³æŠ€æœ¯ï¼Œä»ä¼ ç»Ÿçš„æ¨èç³»ç»Ÿåˆ°ç°ä»£å¤§è¯­è¨€æ¨¡å‹çš„å‚æ•°é«˜æ•ˆå¾®è°ƒï¼ˆLoRAï¼‰ï¼Œéƒ½ç¦»ä¸å¼€çŸ©é˜µåˆ†è§£çš„æ€æƒ³ã€‚\nå¥‡å¼‚å€¼åˆ†è§£ (SVD)åŸºæœ¬å½¢å¼ä»»æ„çŸ©é˜µ  å¯ä»¥åˆ†è§£ä¸ºï¼š\n\nå…¶ä¸­ï¼š\n\nï¼šå·¦å¥‡å¼‚å‘é‡ï¼ˆæ­£äº¤çŸ©é˜µï¼‰\nï¼šå¥‡å¼‚å€¼å¯¹è§’çŸ©é˜µ\nï¼šå³å¥‡å¼‚å‘é‡ï¼ˆæ­£äº¤çŸ©é˜µï¼‰\n\nTruncated SVDä¿ç•™å‰  ä¸ªæœ€å¤§å¥‡å¼‚å€¼ï¼š\n\nè¿™æ˜¯æœ€ä¼˜çš„ç§©  è¿‘ä¼¼ï¼ˆEckart-Young å®šç†ï¼‰ï¼š\n\nRandomized SVDå½“çŸ©é˜µè§„æ¨¡å·¨å¤§æ—¶ï¼Œç²¾ç¡® SVD è®¡ç®—ä»£ä»·è¿‡é«˜ã€‚Randomized SVD æä¾›äº†é«˜æ•ˆçš„è¿‘ä¼¼æ–¹æ³•ã€‚\nç®—æ³•å®ç°import numpy as npfrom scipy import linalgdef randomized_svd(A, n_components, n_oversamples=10, n_iter=4):    \"\"\"    Randomized SVD for large matrices.        Args:        A: Input matrix (m x n)        n_components: Number of singular values to compute        n_oversamples: Additional random vectors for accuracy        n_iter: Number of power iterations        Returns:        U, s, Vt: Truncated SVD components    \"\"\"    m, n = A.shape    n_random = n_components + n_oversamples        # Step 1: Random projection    Q = np.random.randn(n, n_random)        # Step 2: Power iteration for accuracy    for _ in range(n_iter):        Q, _ = linalg.lu(A @ Q, permute_l=True)        Q, _ = linalg.lu(A.T @ Q, permute_l=True)        Q, _ = linalg.qr(A @ Q, mode='economic')        # Step 3: Project and compute SVD    B = Q.T @ A    Uhat, s, Vt = linalg.svd(B, full_matrices=False)    U = Q @ Uhat        return U[:, :n_components], s[:n_components], Vt[:n_components, :]\n\nå¤æ‚åº¦å¯¹æ¯”\n\n\næ–¹æ³•\næ—¶é—´å¤æ‚åº¦\nç©ºé—´å¤æ‚åº¦\n\n\n\nç²¾ç¡® SVD\n\n\n\n\nRandomized SVD\n\n\n\n\nTruncated SVD (Lanczos)\n\n\n\n\nç°ä»£åº”ç”¨ï¼šLoRALoRA (Low-Rank Adaptation) æ˜¯å¤§è¯­è¨€æ¨¡å‹å‚æ•°é«˜æ•ˆå¾®è°ƒçš„æ ¸å¿ƒæŠ€æœ¯ï¼Œç›´æ¥åˆ©ç”¨äº†ä½ç§©åˆ†è§£çš„æ€æƒ³ã€‚\nLoRA åŸç†é¢„è®­ç»ƒæƒé‡  å›ºå®šï¼Œåªè®­ç»ƒä½ç§©å¢é‡ï¼š\n\nå…¶ä¸­ ï¼Œï¼Œã€‚\nå®ç°ç¤ºä¾‹import torchimport torch.nn as nnclass LoRALayer(nn.Module):    def __init__(self, in_features, out_features, rank=4, alpha=1.0):        super().__init__()        self.rank = rank        self.alpha = alpha                # åŸå§‹æƒé‡ï¼ˆå†»ç»“ï¼‰        self.W = nn.Linear(in_features, out_features, bias=False)        self.W.weight.requires_grad = False                # ä½ç§©åˆ†è§£        self.A = nn.Linear(in_features, rank, bias=False)        self.B = nn.Linear(rank, out_features, bias=False)                # åˆå§‹åŒ–        nn.init.kaiming_uniform_(self.A.weight)        nn.init.zeros_(self.B.weight)                self.scaling = alpha / rank        def forward(self, x):        # W(x) + scaling * B(A(x))        return self.W(x) + self.scaling * self.B(self.A(x))\n\nå‚æ•°æ•ˆç‡å¯¹äº LLaMA-7Bï¼š\n\n\n\næ–¹æ³•\nå¯è®­ç»ƒå‚æ•°\næ˜¾å­˜å ç”¨\n\n\n\nå…¨é‡å¾®è°ƒ\n7B (100%)\n~140GB\n\n\nLoRA (r=8)\n4.7M (0.07%)\n~14GB\n\n\nLoRA (r=16)\n9.4M (0.13%)\n~16GB\n\n\nå…¶ä»–åº”ç”¨1. æ¨èç³»ç»ŸçŸ©é˜µåˆ†è§£ç”¨äºååŒè¿‡æ»¤ï¼š\n\n# ä½¿ç”¨ surprise åº“from surprise import SVD, Dataset, Readerreader = Reader(rating_scale=(1, 5))data = Dataset.load_from_df(df[['user', 'item', 'rating']], reader)model = SVD(n_factors=100)model.fit(trainset)\n\n2. æ–‡æœ¬è¡¨ç¤º (LSA)æ½œåœ¨è¯­ä¹‰åˆ†æï¼š\nfrom sklearn.decomposition import TruncatedSVDfrom sklearn.feature_extraction.text import TfidfVectorizervectorizer = TfidfVectorizer(max_features=10000)X = vectorizer.fit_transform(documents)svd = TruncatedSVD(n_components=100)X_reduced = svd.fit_transform(X)\n\n3. å›¾åƒå‹ç¼©from PIL import Imageimport numpy as npdef compress_image(image_path, n_components=50):    img = np.array(Image.open(image_path).convert('L'))    U, s, Vt = np.linalg.svd(img, full_matrices=False)        # ä¿ç•™å‰ n_components ä¸ªå¥‡å¼‚å€¼    compressed = U[:, :n_components] @ np.diag(s[:n_components]) @ Vt[:n_components, :]        return compressed.astype(np.uint8)\n\næ•°å€¼ç¨³å®šæ€§æ¡ä»¶æ•°\næ¡ä»¶æ•°è¿‡å¤§ä¼šå¯¼è‡´æ•°å€¼ä¸ç¨³å®šã€‚\næ­£åˆ™åŒ– SVDdef regularized_svd(A, lambda_reg=0.01):    \"\"\"Add regularization for numerical stability.\"\"\"    U, s, Vt = np.linalg.svd(A, full_matrices=False)    s_reg = s / (s**2 + lambda_reg)    return U, s_reg, Vt\n\nå»¶ä¼¸é˜…è¯»\nHalko et al., Finding Structure with Randomness (2011)\nHu et al., LoRA: Low-Rank Adaptation of Large Language Models (2021)\nNumPy SVD Documentation\n\n\n\nè½¬è½½è¯·æ³¨æ˜å‡ºå¤„\n\n","tags":["LLM","machine learning","linear algebra"]}]